[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simulation-Based Population Genomics",
    "section": "",
    "text": "Introduction\nThis workbook contains materials for a work-in-progress course on the fundamentals of population genomics and statistical inference in R, with a strong focus on good practices of reproducible research. The general structure of the final product (to be developed over the course of 2025-2026) will be a set of interlinked tutorials and exercises, which the students will be able to walk through during an interactive course in the classroom and use them as a reference in their own projects later.\nThe git repository containing the sources of all materials for the entire course are available on GitHub at https://github.com/bodkan/simgen.\nThe intended audience are novice researchers who have just started (or are about to start) their careers in population genomics and evolutionary genomics, primarily senior master students or doctoral students in the early parts of their PhD journey. That said, the more advanced latter parts of the book focusing on simulation-based inference of demography and selection will be beneficial even to more seasoned researchers, who are looking for more efficient means to fit models using novel inference tools in the R ecosystem.\n\nThe work-in-progress rendering of the book is available at https://bodkan.github.io/simgen.\n\n\nCurrently planned outline\nA draft of a subset of the planned content is available in the menu on the left. However, there are still many parts missing, even in the chapters already present. That said, here‚Äôs an overview of some of the things the final course will include:\n\nR\n\nIntroduction to R\n\nBasic data types and container types\nData frames, functions, iteration\nAbsolute minimum on manipulation and plotting data with base R\n\nReproducible computing in R\n\nWhat makes a good project structure\nWhat is algorithmic thinking?\nCreating self-contained R command-line scripts\nReproducible reports and presentations with Quarto\n\nData science with tidyverse\n\nFiltering, subsetting, modifying, and manipulating tabular data\nData visualization with ggplot2\nBasics of spatial data science using sf\n\nComputational genomics with R\n\nGenomicRanges and friends\n\n\nslendr\n\nIntroduction to the slendr R package\nBuilding traditional demographic models with slendr\nSimulating genomic data\n\nWhat is a tree sequence?\nVCF files, EIGENSTRAT file format, genotype tables\n\n\nFundamentals of population genetics with slendr\n\nComputing tree sequence summary statistics\ndiversity, divergence, AFS\n\\(f\\)-statistics, \\(f_4\\)-ratio statistics\n\\(F_{st}\\)\nPCA\nIdentity-by-descent (IBD)\nAncestry tracts / chromosome painting\nAdmixture dating\n\nNatural selection with slendr\n\nNatural selection theory\nSimple one-locus simulation\nUseful selection summary statistics\nMore complex epistatic selection\n\nSimulation-based inference with demografr\n\nToy grid-based inference of \\(N_e\\) with AFS\nGrid-based inference with demografr (\\(f_4\\) and \\(f_4\\)-ratio)\nGrid-based admixture tract dating\nApproximate Bayesian Computation (ABC)\n\nIntroducing the workhorses of applied population genetics\n\nMDS / PCA\nADMIXTOOLS - \\(f\\)-statistics, qpAdm\nADMIXTURE / STRUCTURE\nIBD\nSelection scans\n\n\n\nAll content is available under the CC BY-SA 4.0 license.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "r-language.html",
    "href": "r-language.html",
    "title": "R programming language",
    "section": "",
    "text": "Part 1: Basic data types\n‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è This chapter is a work-in-progress! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\nIn a wider programming world, R sometimes has a slightly unfortunate reputation as a badly designed ‚Äúcalculator language‚Äù. A computing environment which is (maybe!) good for working with data frames and creating figures, but that‚Äôs about it. However, while certainly very useful for data science, R is a full-blown programming language which is actually quite powerful even from a purely computer science perspective.\nBut still, this is a book about population genomics and data science in R. Why does this matter how much ‚Äúreal coding‚Äù we do in it?\nWell, although this entire workshop will primarily focus on R primarily as as a statistical and visualization environment, neglecting the aspects of R which make it a ‚Äúproper‚Äù programming language (or even considering data science as ‚Äúnot real programming‚Äù) is a huge problem.\nFirst, even when ‚Äújust‚Äù doing data science and statistics, we still use typical programming constructs, we need to be aware of underlying data types behind our data (mostly contents of tables), and we need to think algorithmically. Neglecting these things makes it easy to introduce bugs into our code, make it hard to find those bugs, and make our programs less efficient even when they do work.\nThis chapter will help you get familiar with some of the less obvious aspects of the R language or programming in general, certainly the parts which are often skipped in undergratuate courses in the life sciences in favor of just teaching plotting and running statistical tests. The good thing is, there isn‚Äôt that much you need to learn. And what you do learn will continue paying dividents for the rest of your research career!\nLet‚Äôs say it again, because people with non-computational backgrounds often feel inadequate when it comes to computational aspects of their work: Even when you‚Äôre ‚Äújust‚Äù writing data analysis scripts, even when you‚Äôre ‚Äújust‚Äù plotting results, you‚Äôre still writing programs. You‚Äôre a programmer. How exciting, right? Exercises in this chapter are designed to make you comfortable with programming and algorithmic thinking.\nCreate the following variables in your R script and then evaluate this code in your R console:\nw1 &lt;- 3.14\nx1 &lt;- 42\ny1 &lt;- \"hello\"\nz1 &lt;- TRUE\nw1\n\n[1] 3.14\n\nx1\n\n[1] 42\n\ny1\n\n[1] \"hello\"\n\nz1\n\n[1] TRUE\nWhat are the data ‚Äútypes‚Äù you get when you apply function mode() on each of these variables?\nYou can test whether or not a specific variable is of a specific type using functions such as is.numeric(), is.integer(), is.character(), is.logical(). See what results you get when you apply these functions on these four variables w1, x1, y1, z1. Pay close attention to the difference (or lack thereof?) between applying is.numeric() and is.integer() on variables containing ‚Äúnumbers‚Äù.\nTo summarize (and oversimplify a little bit) R allows variables to have several types of data, most importantly:\nWe will also encounter two types of ‚Äúnon-values‚Äù. We will not be discussing them in detail here, but they will be relevant later. For the time being, just remember that there are also:\nWhat do you think is the practical difference between NULL and NA? In other words, when you encounter one or the other in the data, how would you interpret this?",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-language.html#part-1-basic-data-types",
    "href": "r-language.html#part-1-basic-data-types",
    "title": "R programming language",
    "section": "",
    "text": "Hint: I suggest you always write your code in a script in RStudio (click File -&gt; New file -&gt; R script). You can execute the line (or block) of code under cursor in the script window by pressing CTRL+Enter (on Windows or Linux) or CMD+Enter (on a Mac). For quick tests, feel free to type directly in the R console.\n\n\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nmode(w1)\n\n[1] \"numeric\"\n\nmode(x1)\n\n[1] \"numeric\"\n\nmode(y1)\n\n[1] \"character\"\n\nmode(z1)\n\n[1] \"logical\"\n\n\n\n\n\n\n\n\n**Note: This might seem incredibly boring and useless but trust me. In your real data, you will be see, in data frames (discussed below) with thousands of rows, sometimes millions. Being able to make sure that the values you get in your data-frame columns are of the expected type is something you will be doing often.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nis.numeric(w1)\n\n[1] TRUE\n\nis.integer(w1)\n\n[1] FALSE\n\nis.numeric(x1)\n\n[1] TRUE\n\nis.integer(x1)\n\n[1] FALSE\n\nis.character(y1)\n\n[1] TRUE\n\nis.logical(z1)\n\n[1] TRUE\n\nis.numeric(z1)\n\n[1] FALSE\n\nis.integer(z1)\n\n[1] FALSE\n\n\n\n\n\n\n\nintegers (such as 42)\nnumerics (such as 42.13)\ncharacters (such as \"text value\")\nlogicals (TRUE or FALSE)\n\n\n\nundefined values represented by NULL\nmissing values represented by NA",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-language.html#part-2-vectors",
    "href": "r-language.html#part-2-vectors",
    "title": "R programming language",
    "section": "Part 2: Vectors",
    "text": "Part 2: Vectors\nVectors are, roughly speaking, collections of values. We could also say ‚Äúa list‚Äù, but that‚Äôs not entirely precise in the context of R as we‚Äôll see below.\nWe can create a vector by calling the c() function (‚Äúc‚Äù stands for ‚Äúconcatenate‚Äù, or ‚Äújoining together‚Äù). Create the following variables containing these vectors. Then inspect their data types using mode() again.\n\nw2 &lt;- c(1.0, 2.72, 3.14)\nx2 &lt;- c(1, 13, 42)\ny2 &lt;- c(\"hello\", \"folks\", \"!\")\nz2 &lt;- c(TRUE, FALSE)\n\n\nw2\n\n[1] 1.00 2.72 3.14\n\nx2\n\n[1]  1 13 42\n\ny2\n\n[1] \"hello\" \"folks\" \"!\"    \n\nz2\n\n[1]  TRUE FALSE\n\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nmode(w2)\n\n[1] \"numeric\"\n\nmode(x2)\n\n[1] \"numeric\"\n\nmode(y2)\n\n[1] \"character\"\n\nmode(z2)\n\n[1] \"logical\"\n\n\n\n\n\nWe can use the function is.vector() to test that a given object really is a vector. Try this on your vector variables.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nis.vector(w2)\n\n[1] TRUE\n\nis.vector(x2)\n\n[1] TRUE\n\nis.vector(y2)\n\n[1] TRUE\n\nis.vector(z2)\n\n[1] TRUE\n\n\n\n\n\nWhat happens when you call is.vector() on the variables x1, y1, etc. from the previous part (i.e., those which contain single values)?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nis.vector(42)\n\n[1] TRUE\n\n\nYes, even scalars (i.e., singular values) are formally vectors!\nThis is why we see the [1] index when we type a single number:\n\n1\n\n[1] 1\n\n\nIn fact, even when we create a vector of length 1, we still get a scalar result:\n\nc(1)\n\n[1] 1\n\n\nThe conclusion is, R doesn‚Äôt actually distinguish between scalars and vectors! A scalar (a single value) is simply a vector of length 1. Think of it this way: in a strange mathematically-focused way, even a single tree is a forest. üôÉ\n\n\n\nDo elements of vectors need to be homogeneous (i.e., of the same data type)? Try creating a vector with values 1, \"42\", and \"hello\". Can you do it? What happens when you try? Inspect the result in the R console (take a close look at how the result is presented in text and the quotes that you will see), or use the mode() function again.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nmixed_vector &lt;- c(1, \"42\", \"hello\")\nmixed_vector\n\n[1] \"1\"     \"42\"    \"hello\"\n\n\n\nmode(mixed_vector)\n\n[1] \"character\"\n\n\n\n\n\nAs you could see, vectors must carry values of just one type. If they don‚Äôt, they are converted by a straightforward cascade of so-called ‚Äúcoercions‚Äù. A vector defined with a mixture of different values (i.e., the four atomic types we discussed in the first part) will be coreced to be only one of those types, given certain rules.\nTry to figure out some of these coercion rules. Make a couple of vectors with mixed values of different types using the function c(), and observe what type of vector you get in return.\nHint: Try creating a vector which has integers and strings, integers and floats, integers and logicals, floats and logicals, floats and strings, and logicals and strings. Observe the format of the result that you get, and build your intuition by calling mode() on each vector object to verify this.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nv1 &lt;- c(1, \"42\", \"hello\")\nv1\n\n[1] \"1\"     \"42\"    \"hello\"\n\nmode(v1)\n\n[1] \"character\"\n\nv2 &lt;- c(1, 42.13, 123)\nv2\n\n[1]   1.00  42.13 123.00\n\nmode(v2)\n\n[1] \"numeric\"\n\nv3 &lt;- c(1, 42, TRUE)\nv3\n\n[1]  1 42  1\n\nmode(v3)\n\n[1] \"numeric\"\n\nv4 &lt;- c(1.12, 42.13, FALSE)\nv4\n\n[1]  1.12 42.13  0.00\n\nmode(v4)\n\n[1] \"numeric\"\n\nv5 &lt;- c(42.13, \"hello\")\nv5\n\n[1] \"42.13\" \"hello\"\n\nmode(v5)\n\n[1] \"character\"\n\nv6 &lt;- c(TRUE, \"hello\")\nv6\n\n[1] \"TRUE\"  \"hello\"\n\nmode(v6)\n\n[1] \"character\"\n\n\n\n\n\nOut of all these data type exploration, this part is probably the most crucial for any kind of data science work. Why is that? Think about what can happen when someone does manual data entry in Excel.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nImagine what kinds of trouble can happen if you just load a table data from somewhere, if the values are not properly formatted. For instance, if a ‚Äúnumeric‚Äù column of your table has accidentally some characters (which can very easily happen when manually entering data in Excel, etc.). This will be much clearer when we get to data frames below.\n\n\n\nYou can create vector of consecutive values of certain forms using everal approaches. Try these options:\n\nCreate a sequence of values from i to j as i:j. Create a vector of numbers 1:20\n**Do the same using the function seq(). Read ?seq to find out what parameters you should specify (and how) to get the same result as the i:j shortcut.\nModify the arguments given to seq() so that you create a vector of numbers from 20 to 1.\nUse the by = argument of seq() to create a vector of only odd values starting from 1.\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# 1\n1:20\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n# another option is this (\"give me sequence of the length N)\nseq_len(20)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n# 2\nseq(from = 1, to = 20)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n# 3\nseq(from = 20, to = 1)\n\n [1] 20 19 18 17 16 15 14 13 12 11 10  9  8  7  6  5  4  3  2  1\n\n# 4\nseq(1, 20, by = 2)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\nThis might look boring, but these functions are super useful to generate indices for data, adding indices as columns to tabular data, etc.**\n\n\n\nAnother very useful built-in helper function (especially when we get to the iteration part below) is seq_along(). What does it give you when you run it on this vector, for instance?\n\nv &lt;- c(1, \"42\", \"hello\", 3.1416)\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nseq_along(v)\n\n[1] 1 2 3 4\n\n\nThis function allows you to quickly iterate over elements of a vector (or a list) using indices into that vector (or a list).",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-language.html#part-3-lists",
    "href": "r-language.html#part-3-lists",
    "title": "R programming language",
    "section": "Part 3: Lists",
    "text": "Part 3: Lists\nLists are a little similar to vectors but very different in a couple of important respects. Remember how we tested what happens when we put different types of values in a vector (reminder: vectors must be ‚Äúhomogeneous‚Äù in terms of the data types of their elements!)? What happens when you create lists with different types of values using the code in the following chunk? Use mode() on the resulting objects and compare your results to those you got on ‚Äúmixed value‚Äù vectors above.\n\nw3 &lt;- list(1.0, \"2.72\", 3.14)\nx3 &lt;- list(1, 13, 42, \"billion\")\ny3 &lt;- list(\"hello\", \"folks\", \"!\", 123, \"wow a number follows again\", 42)\nz3 &lt;- list(TRUE, FALSE, 13, \"string\")\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nWhen we type the list variable in the R console, we no longer see the ‚Äúcoercion‚Äù we observed for vectors (numbers remain numbers even though the list contains strings):\n\ny3\n\n[[1]]\n[1] \"hello\"\n\n[[2]]\n[1] \"folks\"\n\n[[3]]\n[1] \"!\"\n\n[[4]]\n[1] 123\n\n[[5]]\n[1] \"wow a number follows again\"\n\n[[6]]\n[1] 42\n\n\nCalling mode() will (disappointingly) not tell us much about the data types of each individual element. Why is that?\n\nmode(y3)\n\n[1] \"list\"\n\n\n\n\n\nTry also a different function called for str() (for ‚Äústructure‚Äù) and apply it on one of those lists. Is mode() or str() more useful to inspect what kind of data is stored in a list (str will be very useful when we get to data frames for ‚Äì spoiler alert! ‚Äì exactly this reason). Why?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nstr(y3)\n\nList of 6\n $ : chr \"hello\"\n $ : chr \"folks\"\n $ : chr \"!\"\n $ : num 123\n $ : chr \"wow a number follows again\"\n $ : num 42\n\n\n\n\n\n\nis.list(w3)\n\n[1] TRUE\n\n\nUse is.vector() and is.list() on one of the lists above (like w3 perhaps). Why do you get the result that you got? Then run both functions on one of the vectors you created above (like w2). What does this mean?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nLet‚Äôs take this list:\n\n\nw3\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"2.72\"\n\n[[3]]\n[1] 3.14\n\n\nLists are vectors!\n\nis.vector(w3)\n\n[1] TRUE\n\n\nLists are lists (obviously!):\n\nis.list(w3)\n\n[1] TRUE\n\n\n\nNow let‚Äôs take this vector:\n\n\nw2\n\n[1] 1.00 2.72 3.14\n\n\nVectors are not lists!\n\nis.list(w2)\n\n[1] FALSE\n\n\nSo:\n\nEvery list is also a vector.\nBut vectors are not lists.\n\nThis makes sense because lists can (but don‚Äôt have to) contain values\n\n\n\nNot only can lists contain arbitrary values of mixed types (atomic data types from Part 1 of this exercise), they can also contain non-atomic data as well, such as other lists! In fact, you can, in principle, create lists of lists of lists of‚Ä¶ lists! Try creating a list() which, in addition to a couple of normal values (numbers, strings, doesn‚Äôt matter) also contains one or two other lists (we call them ‚Äúnested‚Äù). Don‚Äôt think about this too much, just create something arbitrary to get a bit of practice. Save this in a variable called weird_list and type it back in your R console, just to see how R presents such data back to you. In the next part, we will learn how to explore this type of data better.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nHere‚Äôs an example of such ‚Äúnested list‚Äù:\n\nweird_list &lt;- list(\n  1,\n  \"two\",\n  list(\n    \"three\",\n    4,\n    list(5, \"six\", 7)\n  )\n)\n\nWhen we type it out in the R console, we see that R tries to lay out the structure of this data with numerical indices (we‚Äôll talk about indices below!) indicating the ‚Äúdepth‚Äù of each nested pieces of data (either a plain number or character, or another list!)\n\nweird_list\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"two\"\n\n[[3]]\n[[3]][[1]]\n[1] \"three\"\n\n[[3]][[2]]\n[1] 4\n\n[[3]][[3]]\n[[3]][[3]][[1]]\n[1] 5\n\n[[3]][[3]][[2]]\n[1] \"six\"\n\n[[3]][[3]][[3]]\n[1] 7\n\n\n\n\n\nNote: If you are confused (or even annoyed) why we are even doing this, in the later discussion of data frames and spatial data structures, it will become much clearer why putting lists into other lists allows a whole another level of data science work. Please bear with me for now! This is just laying the groundwork for some very cool things later down the line.",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-language.html#part-4-indexing-into-vectors-and-lists",
    "href": "r-language.html#part-4-indexing-into-vectors-and-lists",
    "title": "R programming language",
    "section": "Part 4: Indexing into vectors and lists",
    "text": "Part 4: Indexing into vectors and lists\nTo extract a specific element(s) of a vector or a list (or to assign its given position(s)), we use a so-called ‚Äúindexing‚Äù operation. Generally speaking, we can do indexing in three ways:\n\nnumerical-based indexing (by specifying a set of integer numbers),\nlogical-based indexing (by specifying a vector of TRUE / FALSE values of the same length as the vector we‚Äôre indexing into)\nname-based indexing (by specifying names of elements to index)\n\nLet‚Äôs practice those for vectors and lists separately. Later, when we introduce data frames, we will return to the topic of indexing again.\n\nVectors\n\n1. Numerical-based indexing\nTo extract an i-th element of a vector xyz, we can use the [] operator like this: xyz[i]. For instance, we can take the 13-th element of this vector as xyz[13].\nFamiliarize yourselves with the [] operator by taking out some specific values from this vector, let‚Äôs say its 5-th element.\n\nv &lt;- c(\"hi\", \"folks\", \"what's\", \"up\", \"folks\")\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nv[5]\n\n[1] \"folks\"\n\n\n\n\n\nThe [] operator is ‚Äúvectorized‚Äù, meaning that it can actually accept multiple values given as a vector themselves (i.e, something like v[c(1, 3, 4)] will extract the first, third, and fourth element of the vector v. In this way, extract the first and fifth element of the vector v. What happens if you try to extract a tenth element from v?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nv[c(1, 5)]\n\n[1] \"hi\"    \"folks\"\n\n\nAccessing a non-existent element gives us a ‚Äúnot available‚Äù or ‚Äúmissing‚Äù value.\n\nv[10]\n\n[1] NA\n\n\n\n\n\n\n\n2. Logical-based indexing\nRather than giving the [] operator a specific set of integer numbers, we can provide a vector of TRUE / FALSE values which specify which element of the input vector do we want to ‚Äúextract‚Äù. Note that this TRUE / FALSE indexing vector must have the same length as our original vector!\nCreate variable containing a vector of five TRUE or FALSE values (i.e., with something like index &lt;- c(TRUE, FALSE, ...) but with five TRUE or FALSE values total, and use that index variable in a v[index] indexing operation.\n\nindex &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE)\nv[index]\n\n[1] \"hi\"     \"what's\" \"up\"    \n\n\nUsually we never want to create this ‚Äúindexing vector‚Äù manually (imagine doing this for a vector of million values ‚Äì impossible!). Instead, we create this indexing vector ‚Äúprogrammatically‚Äù, based on a certain condition, like this:\n\nindex &lt;- v == \"up\"\n\nThis checks which values of v are equal to ‚Äúthree‚Äù, creating a logical TRUE / FALSE vector in the process, storing it in the variable index:\n\nindex\n\n[1] FALSE FALSE FALSE  TRUE FALSE\n\n\nUse the same principle to extract the elements of the vector matching the value ‚Äúfolks‚Äù.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nindex &lt;- v == \"folks\"\nindex\n\n[1] FALSE  TRUE FALSE FALSE  TRUE\n\n\nA nice trick is that summing a logical vector using sum() gives you the number of TRUE matches:\n\nsum(index)\n\n[1] 2\n\n\nThis is actually why we do this indexing operation on vectors in the first places, most of the time ‚Äì when we want to count how many data points match a certain criterion.\nLet‚Äôs extract our matching values:\n\nv[index]\n\n[1] \"folks\" \"folks\"\n\n\n\n\n\n\n\n\nLists\nThis section will be a repetition on the previous exercises about vectors. Don‚Äôt forget ‚Äì lists are just vectors, except that they can contain values of heterogeneous types (numbers, characters, anything). As a result, everything that applies to vectors above applies also here.\nBut practice makes perfect, so let‚Äôs go through a couple of examples anyway:\n\nl &lt;- list(\"hello\", \"folks\", \"!\", 123, \"wow a number follows again\", 42)\nl\n\n[[1]]\n[1] \"hello\"\n\n[[2]]\n[1] \"folks\"\n\n[[3]]\n[1] \"!\"\n\n[[4]]\n[1] 123\n\n[[5]]\n[1] \"wow a number follows again\"\n\n[[6]]\n[1] 42\n\n\n\n1. Numerical-based indexing\nThe same applies to numerical-based indexing as what we‚Äôve shown for vectors.\nExtract the second and fourth elements from l.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nl[c(2, 4)]\n\n[[1]]\n[1] \"folks\"\n\n[[2]]\n[1] 123\n\n\n\n\n\n\n\n2. Logical-based indexing\nSimilarly, you can do the same with TRUE / FALSE indexing vectors for lists as what we did with normal (single-type) vectors. Rather than go through the variation of the same exercises, let‚Äôs introduce another very useful pattern related to logical-based indexing and that‚Äôs removing invalid elements.\nConsider this vector:\n\nv &lt;- c(\"hello\", \"folks\", \"!\", NA, \"wow another NAs are coming\", NA, NA, \"42\")\n\nv\n\n[1] \"hello\"                      \"folks\"                     \n[3] \"!\"                          NA                          \n[5] \"wow another NAs are coming\" NA                          \n[7] NA                           \"42\"                        \n\n\nNotice the NA values. One operation we have to do very often (particularly in data frames, whose columns are vectors as we will see below!) is to remove those invalid elements, using the function is.na().\nThis function returns a TRUE / FALSE vector which, as you now already know, can be used for logical-based indexing!\n\nis.na(v)\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE\n\n\nA very useful trick in programming is negation (using the ! operator), which flips the TRUE / FALSE states. In other words, prefixing with ! returns a vector saying which elements of the input vector are not NA:\n\n!is.na(v)\n\n[1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE\n\n\nUse is.na(v) and the negation operator ! to remove the NA elements of the vector v!\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nv[!is.na(v)]\n\n[1] \"hello\"                      \"folks\"                     \n[3] \"!\"                          \"wow another NAs are coming\"\n[5] \"42\"                        \n\n\n\n\n\n\n\n[] vs [[]] operators\nLet‚Äôs move to a more interesting topic. There‚Äôs another operator useful for lists, and that‚Äôs [[ ]] (not [ ]!). Extract the third element of the list l using l[4] and l[[4]]]. What‚Äôs the difference between the results? If you‚Äôre unsure, use the mode() function on l[3] and l[[3]] to help you.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nStrange, isn‚Äôt it? The [ ] operator seems to return a list, even though we expect the result 123?\n\nl[4]\n\n[[1]]\n[1] 123\n\nmode(l[4])\n\n[1] \"list\"\n\n\nOn the other hand, l[[4]] gives us just a number!\n\nl[[4]]\n\n[1] 123\n\nmode(l[[4]])\n\n[1] \"numeric\"\n\n\nI simply cannot not link to this brilliant figure, which explains this result in a very fun way. The left picture shows our list l, the middle picture shows l[4], the right picture shows l[[4]]. Spend some time experimenting with the behavior of [ ] and [[ ]] on our list l! This will come in handy many times in your R carreer!\n\n\n\n\n\n\nTraversing nested lists\nRemember our nested list from earlier? Here‚Äôs it again:\n\nweird_list &lt;- list(\n  1,\n  \"two\",\n  list(\n    \"three\",\n    4,\n    list(\n      5, \"six\",\n      list(\"seven\", 8)\n    )\n  )\n)\n\nWhat do you get when you run weird_list[[1]]? How about weird_list[[3]]? And how about weird_list[[3]][[2]]? Things are getting a little complicated (or interesting, depending on how nerdy you are :)).\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nThis takes out the first value of the list:\n\nweird_list[[1]]\n\n[1] 1\n\n\nNote the [[]] operator. Here‚Äôs what we would get with the [] operator (basically, a ‚Äúsublist‚Äù):\n\nweird_list[1]\n\n[[1]]\n[1] 1\n\nmode(weird_list[1])\n\n[1] \"list\"\n\n\nThis extracts the 3rd value, which is itself a list!\n\nweird_list[[3]]\n\n[[1]]\n[1] \"three\"\n\n[[2]]\n[1] 4\n\n[[3]]\n[[3]][[1]]\n[1] 5\n\n[[3]][[2]]\n[1] \"six\"\n\n[[3]][[3]]\n[[3]][[3]][[1]]\n[1] \"seven\"\n\n[[3]][[3]][[2]]\n[1] 8\n\n\nAnd because this is just any other list (just nested), we can also index into that list! Glancing at the result of weird_list[[3]] just above, we see that the 2nd value of that list is a number 4. Let‚Äôs verify that:\n\nweird_list[[3]][[2]]\n\n[1] 4\n\n\n\n\n\nWhat‚Äôs the sequence of this ‚Äúchaining‚Äù of indexing operators to extract the number 8?\nHint: You can leverage the interactive nature of evaluating intermediate results in the R console, adding things to the expression (i.e., a chunk of code) in sequence.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nLet‚Äôs take it step by step, interactively:\n\nWe know that the nested list sits at the 3rd position of the whole list:\n\n\nweird_list[[3]]\n\n[[1]]\n[1] \"three\"\n\n[[2]]\n[1] 4\n\n[[3]]\n[[3]][[1]]\n[1] 5\n\n[[3]][[2]]\n[1] \"six\"\n\n[[3]][[3]]\n[[3]][[3]][[1]]\n[1] \"seven\"\n\n[[3]][[3]][[2]]\n[1] 8\n\n\n\nThe other nested list is at index number 3 again:\n\n\nweird_list[[3]][[3]]\n\n[[1]]\n[1] 5\n\n[[2]]\n[1] \"six\"\n\n[[3]]\n[[3]][[1]]\n[1] \"seven\"\n\n[[3]][[2]]\n[1] 8\n\n\n\nAnd the final list, the one carrying the number 8, is again in the 3rd position:\n\n\nweird_list[[3]][[3]][[3]]\n\n[[1]]\n[1] \"seven\"\n\n[[2]]\n[1] 8\n\n\n\nFinally, we can extract the number 8 from the index at the second position:\n\n\nweird_list[[3]][[3]][[3]][[2]]\n\n[1] 8\n\n\nWhew! That was something, wasn‚Äôt it. Kind of annoying, if you ask me.\nLuckily, you will not have to do these kind of complex shenanigans in R very often (maybe even never). Still, nested lists are sometimes used in capturing more complex types of data than just lists of numbers or tables (for instance, nested lists capture tree-like structures). In any case, using names instead of just integers as indices makes the whole process much easier, as we will see below.\nIn data you encounter in practice, the most extreme case of data indexing you will have to do probably won‚Äôt be more complex than two nested indexing operators in a row (i.e., the equivalent of doing data[[2]][[3]]).\nParticularly when we discuss some very convenient tidyverse operations later, having an idea about what a nested list even is will be very useful, so bear with me please!\n\n\n\n\n\nNamed indexing for vectors and lists\nHere‚Äôs a neat thing we can do with vectors and lists. They don‚Äôt have to contain just values themselves (which can be then extracted using integer or logical indices as we‚Äôve done above), but those values can be assigned names too.\nConsider this vector and list:\n\nv &lt;- c(1, 2, 3, 4, 5)\nv\n\n[1] 1 2 3 4 5\n\nl &lt;- list(1, 2, 3, 4, 5)\nl\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\n[[4]]\n[1] 4\n\n[[5]]\n[1] 5\n\n\nAs a recap, we can index into them in the usual manner like this:\n\nv[c(1, 3, 5)]\n\n[1] 1 3 5\n\nl[c(1, 3)]\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 3\n\n\nBut we can also name the values like this (note that the names appear in the print out you get from R in the console):\n\nv &lt;- c(one = 1, two = 2, three = 3, four = 4, five = 5)\nv\n\n  one   two three  four  five \n    1     2     3     4     5 \n\nl &lt;- list(one = 1, two = 2, three = 3, four = 4, five = 5)\nl\n\n$one\n[1] 1\n\n$two\n[1] 2\n\n$three\n[1] 3\n\n$four\n[1] 4\n\n$five\n[1] 5\n\n\nWhen you have a named data structure like this, you can index into it using those names as well, which can be very convenient. Imagine having data described not by indices but actualy readable names (such as names of people, or excavation sites!):\n\nl[[\"three\"]]\n\n[1] 3\n\nl[c(\"two\", \"five\")]\n\n$two\n[1] 2\n\n$five\n[1] 5\n\n\n‚Äì\nSpoiler alert: this is exactly what data frames are, under the hood (named lists!), as we‚Äôll see in the next section.\n‚Äì\nLet‚Äôs return (one last time, I promise!) to our nested list example, this time presenting it in a more convenient way.\n\nweird_list &lt;- list(\n  1,\n  \"two\",\n  nested1 = list(\n    \"three\",\n    4,\n    nested2 = list(\n      5, \"six\",\n      nested3 = list(\"seven\", 8)\n    )\n  )\n)\n\nWith a list like that, when we previously had to extract the element 8 like this:\n\nweird_list[[3]][[3]][[3]][[2]]\n\n[1] 8\n\n\nwe can now do this:\n\nweird_list[[\"nested1\"]][[\"nested2\"]][[\"nested3\"]][[2]]\n\n[1] 8\n\n\nMuch more readable!\n\n\nNegative indexing\nConsider this vector again:\n\nv &lt;- c(\"hi\", \"folks\", \"what's\", \"up\", \"folks\")\n\nWhat happens when you index into v using the [] operator but give it a negative number between 1 and 5?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nNegative indices remove elements!\n\nv[-1]\n\n[1] \"folks\"  \"what's\" \"up\"     \"folks\" \n\n\nWhen we exclude all indices 1:5, we remove everything, oops!\n\nv[-(1:5)]\n\ncharacter(0)\n\n\n\n\n\nA very useful function is length(), which gives the length of a given vector (or a list ‚Äì remember, lists are vectors!). Use it to remove the last element of v. How would you remove both the first and last element of a vector or a list (assuming you don‚Äôt know the length beforehand, i.e., you can‚Äôt put a fixed number as the index of the last element)?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nv[-length(v)]\n\n[1] \"hi\"     \"folks\"  \"what's\" \"up\"    \n\n\n\n# this gives us the index of the first and last element\nc(1, length(v))\n\n[1] 1 5\n\n# then we can prefix this with the minus sign to remove them\nv[-c(1, length(v))]\n\n[1] \"folks\"  \"what's\" \"up\"",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-language.html#part-5-data-frames",
    "href": "r-language.html#part-5-data-frames",
    "title": "R programming language",
    "section": "Part 5: Data frames",
    "text": "Part 5: Data frames\nEvery scientists works with tables of data, in one way or another. R provides first class support for working with tables, which are formally called ‚Äúdata frames‚Äù. We will be spending most of our time of this workshop learning to manipulate, filter, modify, and plot data frames, often times with data that is too big to look at all at once. For simplicity, just to get started and to explain the basic fundamentals, let‚Äôs begin with something trivially easy, like this little data frame here:\n\ndf &lt;- data.frame(\n  v = c(\"one\", \"two\", \"three\", \"four\", \"five\"),\n  w = c(1.0, 2.72, 3.14, 1000.1, 1e6),\n  x = c(1, 13, 42, NA, NA),\n  y = c(\"folks\", \"hello\", \"from\", \"data frame\", \"!\"),\n  z = c(TRUE, FALSE, FALSE, TRUE, TRUE)\n)\n\ndf\n\n      v          w  x          y     z\n1   one       1.00  1      folks  TRUE\n2   two       2.72 13      hello FALSE\n3 three       3.14 42       from FALSE\n4  four    1000.10 NA data frame  TRUE\n5  five 1000000.00 NA          !  TRUE\n\n\nFirst, here‚Äôs the first killer bit of information: data frames are normal lists!\n\nis.list(df)\n\n[1] TRUE\n\n\nHow is this even possible? And why is this even the case? Explaining this in full would be too much detail, even for a course which tries to go beyond ‚ÄúR only as a plotting tool‚Äù as I promised you in the introduction. Still, for now let‚Äôs say that R objects can store so called ‚Äúattributes‚Äù, which ‚Äì in the case of data frame objects ‚Äì makes them behave as ‚Äúsomething more than just a list‚Äù. These attributes are called ‚Äúclasses‚Äù.\nYou can poke into these internals but ‚Äúunclassing‚Äù an object. Call unclass(df) in your R console and observe what result you get (just to convince yourself that data frames really are lists under the hood).\n\n\nNote: Honest admission ‚Äì you will never need this unclass() stuff in practice, ever. I‚Äôm really showing you to demonstrate what ‚Äúdata frame‚Äù actually is on a lower-level of R programming. If you‚Äôre confused, don‚Äôt worry. The fact that data frames are lists matters infinitely more than knowing exactly how is that accomplished inside R.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nThis is what a normal data frame looks like to us:\n\ndf\n\n      v          w  x          y     z\n1   one       1.00  1      folks  TRUE\n2   two       2.72 13      hello FALSE\n3 three       3.14 42       from FALSE\n4  four    1000.10 NA data frame  TRUE\n5  five 1000000.00 NA          !  TRUE\n\n\nHere is how a data frame is represented under the hood:\n\nunclass(df)\n\n$v\n[1] \"one\"   \"two\"   \"three\" \"four\"  \"five\" \n\n$w\n[1]       1.00       2.72       3.14    1000.10 1000000.00\n\n$x\n[1]  1 13 42 NA NA\n\n$y\n[1] \"folks\"      \"hello\"      \"from\"       \"data frame\" \"!\"         \n\n$z\n[1]  TRUE FALSE FALSE  TRUE  TRUE\n\nattr(,\"row.names\")\n[1] 1 2 3 4 5\n\n\nIt really is just a list!\n\n\n\nRemember how we talked about ‚Äúnamed lists‚Äù in the previous section! Yes, data frames really are just normal named lists with extra bit of behavior added to them (namely the fact that these lists are printed in a nice, readable, tabular form).\n\nSelecting columns\nQuite often we need to extract values of an entire column of a data frame. In the Part about indexing, you have learned about the [] operator (for vectors and lists), and also about the $ and [[]] operator (for lists). Now that you‚Äôve learned that data frames are (on a lower level) just lists, what does it mean for wanting to extract a column from a data frame?\nTry to use the three indexing options to extract the column named \"z\" from your data frame df. How do the results differ depending on the indexing method chosen? Is the indexing (and its result) different to indexing a plain list?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nWe can extract a given column with‚Ä¶\n\nthe $ operator (column name as a symbol), which gives us a vector:\n\n\ndf$z\n\n[1]  TRUE FALSE FALSE  TRUE  TRUE\n\n\n\nthe [ operator (column name as a string), which gives us a (single-column) data frame:\n\n\ndf[\"z\"]\n\n      z\n1  TRUE\n2 FALSE\n3 FALSE\n4  TRUE\n5  TRUE\n\n\n\nthe [[ operator (column name as a string), which gives us vector again:\n\n\ndf[[\"w\"]]\n\n[1]       1.00       2.72       3.14    1000.10 1000000.00\n\n\nLet‚Äôs create a list-version of this data frame:\n\ndf_list &lt;- as.list(df)\ndf_list\n\n$v\n[1] \"one\"   \"two\"   \"three\" \"four\"  \"five\" \n\n$w\n[1]       1.00       2.72       3.14    1000.10 1000000.00\n\n$x\n[1]  1 13 42 NA NA\n\n$y\n[1] \"folks\"      \"hello\"      \"from\"       \"data frame\" \"!\"         \n\n$z\n[1]  TRUE FALSE FALSE  TRUE  TRUE\n\n\nThe indexing results match what we get for the data frame. After all, a data frame really is just list (with some very convenient behavior, such as presenting the data in a tabular form). The only exception is the result of df_list[\"v\"] which results a data frame but only returns a list when applied on a list:\n\ndf_list$v\n\n[1] \"one\"   \"two\"   \"three\" \"four\"  \"five\" \n\ndf_list[\"v\"]\n\n$v\n[1] \"one\"   \"two\"   \"three\" \"four\"  \"five\" \n\ndf_list[[\"v\"]]\n\n[1] \"one\"   \"two\"   \"three\" \"four\"  \"five\" \n\n\n\n\n\n\nThe tidyverse approach\nIn the chapter on tidyverse, we will learn much more powerful and easier tools to do these types of data-frame operations, particularly the select() function. That said, even when you use tidyverse exclusively, you will still encounter code in the wild which uses this base R way of doing things. Additionally, for certain trivial actions, doing ‚Äúthe base R thing‚Äù is just quicker to types. This is why knowing the basics of $, [], and [[]] will always be useful.\n\n\n\nSelecting rows (‚Äúfiltering‚Äù)\nOf course, we often need to refer not just to specific columns of data frames, but also to given rows. Let‚Äôs consider our data frame again:\n\ndf\n\n      v          w  x          y     z\n1   one       1.00  1      folks  TRUE\n2   two       2.72 13      hello FALSE\n3 three       3.14 42       from FALSE\n4  four    1000.10 NA data frame  TRUE\n5  five 1000000.00 NA          !  TRUE\n\n\nIn the section on indexing into vectors and lists above, we learned primarily about two means of indexing into vectors. Let‚Äôs revisit them in the context of data frames:\n\nInteger-based indexing\n\n**What happens when you use the [1:3] index into the df data frame, just as you would do by extracting the first three elements of a vector?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nSomewhat curiously, you get the first three columns, not rows!\n\ndf[1:3]\n\n      v          w  x\n1   one       1.00  1\n2   two       2.72 13\n3 three       3.14 42\n4  four    1000.10 NA\n5  five 1000000.00 NA\n\n\n\n\n\nWhen indexing into a data frame (or even a matrix, although we won‚Äôt be getting into those in our course), you need to distinguish the dimension along which you‚Äôre indexing: either a row, or a column dimension. Just like in referring to a cell coordinate in Excel, for example.\nThe way you do this for data frames in R is to separate the dimensions into which you‚Äôre indexing with a comma in this way: [row-index, column-name-or-index]. Try to extract the first three elements (1:3) of the data frame df by df[1:3, ]. Note the empty space after the comma ,! Then try to select a subset of the df data frame to only show the row #1 and #4 for columns \"x\" and \"z\".\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nExtract the first three rows of df:\n\ndf[1:3, ]\n\n      v    w  x     y     z\n1   one 1.00  1 folks  TRUE\n2   two 2.72 13 hello FALSE\n3 three 3.14 42  from FALSE\n\n\nExtract the rows number 1 and 4 for columns ‚Äúx‚Äù and ‚Äúz‚Äù:\n\ndf[c(1, 4), c(\"x\", \"z\")]\n\n   x    z\n1  1 TRUE\n4 NA TRUE\n\n\nOf course, the actual indexing dimensions can be (and often is) specified in variables. For instance, we often have code which firsts computes the indexes, and then we access them into the data frames. The equivalent of this here would be:\n\nrow_indices &lt;- 1:3\n\ndf[row_indices, ]\n\n      v    w  x     y     z\n1   one 1.00  1 folks  TRUE\n2   two 2.72 13 hello FALSE\n3 three 3.14 42  from FALSE\n\n\nExtract the rows number 1 and 4 for columns ‚Äúx‚Äù and ‚Äúz‚Äù:\n\nrow_indices &lt;- c(1, 4)\ncol_indices &lt;- c(\"x\", \"z\")\n\ndf[row_indices, col_indices]\n\n   x    z\n1  1 TRUE\n4 NA TRUE\n\n\n\nLogical-based indexing\n\nSimilarly to indexing into vectors, you can also specify which rows should be extracted ‚Äúat once‚Äù, using a single logical vector (you can also do this for columns but I honestly don‚Äôt remember the last time I had to do this).\nThe most frequent use for this is to select all rows of a data frame for which a given column (or multiple columns) carry a certain value. Select only those rows for which the column ‚Äúy‚Äù has a value ‚Äúhello‚Äù:\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nLet‚Äôs first use a vectorized comparison to get a TRUE / FALSE vector indicating which values of the ‚Äúv‚Äù column contain the string ‚Äúhello‚Äù. Remember, that if you take a vector (of arbitrary length) and compare it to some value, you will get a TRUE / FALSE vector of the same length:\n\n# this is what the column (vector, really) contains\ndf$y\n\n[1] \"folks\"      \"hello\"      \"from\"       \"data frame\" \"!\"         \n\n\n\n# this is how we can find out, which element(s) of the vector match\ndf$y == \"hello\"\n\n[1] FALSE  TRUE FALSE FALSE FALSE\n\n\n\n# let's save the result to a new variable\nrow_indices &lt;- df$y == \"hello\"\nrow_indices\n\n[1] FALSE  TRUE FALSE FALSE FALSE\n\n\n\n\n\nNow we can use this vector as a row index into our data frame (don‚Äôt forget the comma ,, without which you‚Äôd be indexing into the column-dimension, not the row-dimension!).\n\ndf[row_indices, ]\n\n    v    w  x     y     z\n2 two 2.72 13 hello FALSE\n\n\nOf course, you can also both filter (remember this word) for a subset of rows and also, at the same time, select (remember this word too) a subset of columns at the same time:\n\ndf[row_indices, c(\"v\", \"y\", \"z\")]\n\n    v     y     z\n2 two hello FALSE\n\n\n\n\n\nNow instead of filtering rows where column y matches ‚Äúhello‚Äù, filter for rows where w column is less than 1000.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nWe can again store the filtered rows in a separate variable, and then use that variable to index into the data frame:\n\nrow_indices &lt;- df$w &lt; 1000\nrow_indices\n\n[1]  TRUE  TRUE  TRUE FALSE FALSE\n\ndf[row_indices, ]\n\n      v    w  x     y     z\n1   one 1.00  1 folks  TRUE\n2   two 2.72 13 hello FALSE\n3 three 3.14 42  from FALSE\n\n\nOften, we want to be more consise and do everything in one go:\n\ndf[df$w &lt; 1000, ]\n\n      v    w  x     y     z\n1   one 1.00  1 folks  TRUE\n2   two 2.72 13 hello FALSE\n3 three 3.14 42  from FALSE\n\n\n\n\n\nRemember how we used to filter out elements of a vector using the !is.na(...) operation? You can see that df contains some NA values in the x column. Use the fact that you can filter rows of a data frame using logical-based vectors (as demonstrated above) to filter out rows of df at which the x column contains NA values.\nHint: You can get indices of the rows of df we you want to retain with !is.na(df$x).\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nThis gives us indices of the rows we want to keep:\n\n!is.na(df$x)\n\n[1]  TRUE  TRUE  TRUE FALSE FALSE\n\n\nThis is how we can filter out unwanted rows:\n\ndf[!is.na(df$x), ]\n\n      v    w  x     y     z\n1   one 1.00  1 folks  TRUE\n2   two 2.72 13 hello FALSE\n3 three 3.14 42  from FALSE\n\n\n\n\n\n\nCreating (and deleting) columns\nThe $ and [] operators can be used to create new columns. For instance, the paste() function in R can be used to combine a pair of values into one. Try running paste(df$v, df$y) to see what the result of this operation is.\nThe general pattern to do this is:\n\ndf$&lt;name of the new column&gt; &lt;- &lt;vector of values to assign to it&gt;\n\nCreate a new column called \"new_col\" and assign to it the result of paste(df$v, df$y).\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\ndf[\"new_col\"] &lt;- paste(df$v, df$y)\n\n# new column appears!\ndf\n\n      v          w  x          y     z         new_col\n1   one       1.00  1      folks  TRUE       one folks\n2   two       2.72 13      hello FALSE       two hello\n3 three       3.14 42       from FALSE      three from\n4  four    1000.10 NA data frame  TRUE four data frame\n5  five 1000000.00 NA          !  TRUE          five !\n\n\n\n\n\nWhen we want to remove a column from a data frame (for instance, we only used it to store some temporary result in a script), we actually do the same thing, except we assign to it the value NULL.\nRemove the column new_col\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\ndf$new_col &lt;- NULL\n\n# and the column is gone\ndf\n\n      v          w  x          y     z\n1   one       1.00  1      folks  TRUE\n2   two       2.72 13      hello FALSE\n3 three       3.14 42       from FALSE\n4  four    1000.10 NA data frame  TRUE\n5  five 1000000.00 NA          !  TRUE\n\n\n\n\n\n\n\n‚ÄúImproper‚Äù column names\nMost column names you will be using in your own script will (well, should!) follow the same rules as apply for variable names ‚Äì they can‚Äôt start with a number, have to compose of alphanumeric characters, and can‚Äôt contain any other characters except for underscores (and occasionally dots). To quote from the venerable R language reference:\n\nIdentifiers consist of a sequence of letters, digits, the period (‚Äò.‚Äô) and the underscore. They must not start with a digit or an underscore, or with a period followed by a digit.\n\nFor instance, these are examples of proper identifiers which can serve as variable names, column names and (later) function names:\n\nvariable1\na_longer_var_42\nanotherVariableName\n\nUnfortunately, when you encounter data in the wild, especially in tables you get from other people or download as supplementary information from the internet, they are rarely this perfect. Here‚Äôs a little example of such data frame:\n\nweird_df\n\n  v with spaces          w y with % sign\n1           one       1.00         folks\n2           two       2.72         hello\n3         three       3.14          from\n4          four    1000.10    data frame\n5          five 1000000.00             !\n\n\nIf you look closely, you see that some columns have spaces \" \" and also strange characters % which are not allowed? Which of the $, [] and [[]] operators can you use to extract v with spaces and y with % sign columns as vectors?**\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n[] and [[]] work just as before, because they accept a string by default anyway, so spaces and other characters are not a problem:\n\nweird_df[\"v with spaces\"]\n\n  v with spaces\n1           one\n2           two\n3         three\n4          four\n5          five\n\nweird_df[[\"y with % sign\"]]\n\n[1] \"folks\"      \"hello\"      \"from\"       \"data frame\" \"!\"         \n\n\nThe $ operator needs bit more work. When you encounter an ‚Äúimproper‚Äù column name in a data frame, you have to enclose the whole ‚Äúsymbol‚Äù or ‚Äúidentifier‚Äù in ‚Äúback ticks‚Äù like this:\n\nweird_df$`y with % sign`\n\n[1] \"folks\"      \"hello\"      \"from\"       \"data frame\" \"!\"         \n\n\nThis is super useful when working with tabular data you get from someone else, especially if they prepared it in Excel. But you should never create data frames with these weird column names yourself. Always use names that would be appropriate as normal standard R identifiers on their own (just alphanumeric symbols or underscores).\n\n\n\n\n\nThe tidyverse approach\nSimilarly to previous section on column selection, there‚Äôs a much more convenient and faster-to-type way of doing filtering, using the tidyverse function filter(). Still, as with the column selection, sometimes doing the quick and easy thing is just more convenient. The minimum on filtering rows of data frames introduced in this section will be enough for you, even in the long run!",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-language.html#part-6-inspecting-column-types",
    "href": "r-language.html#part-6-inspecting-column-types",
    "title": "R programming language",
    "section": "Part 6: Inspecting column types",
    "text": "Part 6: Inspecting column types\nLet‚Äôs go back to our example data frame:\n\ndf1 &lt;- data.frame(\n  w = c(1.0, 2.72, 3.14),\n  x = c(1, 13, 42),\n  y = c(\"hello\", \"folks\", \"!\"),\n  z = c(TRUE, FALSE, FALSE)\n)\n\ndf1\n\n     w  x     y     z\n1 1.00  1 hello  TRUE\n2 2.72 13 folks FALSE\n3 3.14 42     ! FALSE\n\n\nUse the function str() and by calling str(df1), inspect the types of columns in the table.\n\nstr(df1)\n\n'data.frame':   3 obs. of  4 variables:\n $ w: num  1 2.72 3.14\n $ x: num  1 13 42\n $ y: chr  \"hello\" \"folks\" \"!\"\n $ z: logi  TRUE FALSE FALSE\n\n\nSometimes (usually when we read data from disk, like from another software), a data point sneaks in which makes a column apparently non numeric. Consider this new table called df2:\n\ndf2 &lt;- data.frame(\n  w = c(1.0, 2.72, 3.14),\n  x = c(1, \"13\", 42),\n  y = c(\"hello\", \"folks\", \"!\"),\n  z = c(TRUE, FALSE, FALSE)\n)\n\ndf2\n\n     w  x     y     z\n1 1.00  1 hello  TRUE\n2 2.72 13 folks FALSE\n3 3.14 42     ! FALSE\n\n\nJust by looking at this, the table looks the same as df1 above. Use str() again to see where the problem is.\n\nstr(df2)\n\n'data.frame':   3 obs. of  4 variables:\n $ w: num  1 2.72 3.14\n $ x: chr  \"1\" \"13\" \"42\"\n $ y: chr  \"hello\" \"folks\" \"!\"\n $ z: logi  TRUE FALSE FALSE",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-language.html#part-7-functions",
    "href": "r-language.html#part-7-functions",
    "title": "R programming language",
    "section": "Part 7: Functions",
    "text": "Part 7: Functions\nThe motivation for this part could be summarized by an ancient motto of programming: Don‚Äôt repeat yourself (DRY): ‚Äú[‚Ä¶] a modification of any single element of a system does not require a change in other logically unrelated elements.‚Äù.\nLet‚Äôs demonstrate this idea in practice.\nLet‚Äôs say you have the following numeric vector (these could be base qualities, genotype qualities, \\(f\\)-statistics, sequencing coverage, anything):\n\nvec &lt;- c(0.32, 0.78, 0.68, 0.28, 1.96, 0.21, 0.07, 1.01, 0.06, 0.74,\n         0.37, 0.6, 0.08, 1.81, 0.65, 1.23, 1.28, 0.11, 1.74,  1.68)\n\nWith numeric vectors, we often need to compute some summary statistics (mean, median, quartile, minimum, maximum, etc.). What‚Äôs more, in a given project, we often have to do this computation multiple times in a number of places.\n\n\nIn R, we have a very useful built-in function summary(), which does exactly that. But let‚Äôs ignore this for the moment, for learning purposes.\nHere is how we can compute those summary statistics individually:\n\nmin(vec)\n\n[1] 0.06\n\n# first quartile (a value which is higher than the bottom 25% of the data)\nquantile(vec, probs = 0.25)\n\n   25% \n0.2625 \n\nmedian(vec)\n\n[1] 0.665\n\nmean(vec)\n\n[1] 0.783\n\n# third quartile (a value which is higher than the bottom 75% of the data)\nquantile(vec, probs = 0.75)\n\n   75% \n1.2425 \n\nmax(vec)\n\n[1] 1.96\n\n\nNow, you can imagine that you have many more of such vectors (results for different sequenced samples, different computed population genetic metrics, etc.). Having to type out all of these commands for every single one of those vectors would very quickly get extremely tiresome. Worse still, when we would do this, we would certainly resort to copy-pasting, which is guaranteed to lead to errors.\nWrite a custom function called my_summary, which will accept a single input named values, and returns a list which binds all the six summary statistics together. Name the elements of that list as \"min\", \"quartile_1\", \"median\", \"mean\", \"quartile_3\", and \"max\".\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nHere is how we could write the function:\n\nmy_summary &lt;- function(values) {\n  a &lt;- min(vec)\n  b &lt;- quantile(vec, probs = 0.25)\n  c &lt;- median(vec)\n  d &lt;- mean(vec)\n  e &lt;- quantile(vec, probs = 0.75)\n  f &lt;- max(vec)\n  \n  result &lt;- list(min = a, quartile_1 = b, median = c, mean = d, quartile_3 = e, max = f)\n  \n  return(result)\n}\n\nAlthough I would probably prefer to write it a bit more tersely like this:\n\nmy_summary &lt;- function(values) {\n  result &lt;- list(\n    min = min(vec),\n    quartile_1 = quantile(vec, probs = 0.25),\n    median = median(vec),\n    mean = mean(vec),\n    quartile_3 = quantile(vec, probs = 0.75),\n    max = max(vec)\n  )\n  \n  return(result)\n}\n\n\n\n\nLet‚Äôs acknowledge one thing straight away: yes, we had to write the code anyway, we even had to do the extra work of wrapping it inside other code (the function body, name the one input argument values, which could be multiple arguments for more complex function). So, one could argue that we didn‚Äôt actually save any time. However, that code is now ‚Äúencapsulated‚Äù in a fully self-contained form and can be called repeatably, without any copy-pasting.\nIn other words, if you now create these three vectors of numeric values:\n\nvec1 &lt;- runif(10)\nvec2 &lt;- runif(10)\nvec3 &lt;- runif(10)\n\nYou can now compute our summary statistics by calling our function my_summary() on these vectors, without any code repetition:\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nmy_summary(vec1)\n\n$min\n[1] 0.06\n\n$quartile_1\n   25% \n0.2625 \n\n$median\n[1] 0.665\n\n$mean\n[1] 0.783\n\n$quartile_3\n   75% \n1.2425 \n\n$max\n[1] 1.96\n\nmy_summary(vec2)\n\n$min\n[1] 0.06\n\n$quartile_1\n   25% \n0.2625 \n\n$median\n[1] 0.665\n\n$mean\n[1] 0.783\n\n$quartile_3\n   75% \n1.2425 \n\n$max\n[1] 1.96\n\nmy_summary(vec3)\n\n$min\n[1] 0.06\n\n$quartile_1\n   25% \n0.2625 \n\n$median\n[1] 0.665\n\n$mean\n[1] 0.783\n\n$quartile_3\n   75% \n1.2425 \n\n$max\n[1] 1.96\n\n\nAnd, surprise! This is what the incredibly useful built-in function summary() provided with every R installation does!\n\nsummary(vec1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0122  0.5311  0.6336  0.5594  0.6780  0.8835 \n\nsummary(vec2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.08785 0.27314 0.47802 0.50048 0.69614 0.92772 \n\nsummary(vec3)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.07824 0.24565 0.43793 0.45245 0.50205 0.95731 \n\n\n\n\n\nThe punchline is this: if we ever need to modify how are summary statistics are computed, we only have to make a single change in the function code instead of having to modify multiple copies of the code in multiple locations in our project.",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-language.html#part-8-iteration-and-loops",
    "href": "r-language.html#part-8-iteration-and-loops",
    "title": "R programming language",
    "section": "Part 8: Iteration and loops",
    "text": "Part 8: Iteration and loops\nFunctions help us take pieces of code and generalize them to reduce the amount of code needed to do similar things, repeatedly, multiple times. You could think of iteration as generalizing those repetitions.\nThis is very vague and abstract",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-language.html#part-9-base-r-plotting",
    "href": "r-language.html#part-9-base-r-plotting",
    "title": "R programming language",
    "section": "Part 9: Base R plotting",
    "text": "Part 9: Base R plotting\nAs a final short section, it‚Äôs worth pointing out some very basic base R plotting functions. We won‚Äôt be getting into detail because tidyverse provides a much more powerful and more convenient set of functionality for visualizing data. Still, base R is often convenient for quick troubleshooting or quick plotting of data at least in the initial phases of data exploration.\nSo far we‚Äôve worked with a really oversimplified data frame. For more interesting demonstration, R bundles with a realistic data frame of penguin data:\n\nhead(penguins)\n\n  species    island bill_len bill_dep flipper_len body_mass    sex year\n1  Adelie Torgersen     39.1     18.7         181      3750   male 2007\n2  Adelie Torgersen     39.5     17.4         186      3800 female 2007\n3  Adelie Torgersen     40.3     18.0         195      3250 female 2007\n4  Adelie Torgersen       NA       NA          NA        NA   &lt;NA&gt; 2007\n5  Adelie Torgersen     36.7     19.3         193      3450 female 2007\n6  Adelie Torgersen     39.3     20.6         190      3650   male 2007\n\n\nUse the function hist() to plot a histogram of the body mass of the entire penguins data set.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nhist(penguins$body_mass)\n\n\n\n\n\n\n\n\nSometimes it is convenient to adjust the bin width:\n\nhist(penguins$body_mass, breaks = 50)\n\n\n\n\n\n\n\n\n\n\n\nThe dataset also contains the measure of bill length. Use the function plot() to visualize a scatter plot of two vectors: penguins$flipper_len against penguins$body_mass. Is there an indication of a relationship between the two metrics?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nplot(penguins$flipper_len, penguins$body_mass)\n\n# we can also overlay a linear fit (first computed with the `lm()` function,\n# then visualized as a red dashed line)\nlm_fit &lt;- lm(body_mass ~ flipper_len, data = penguins)\nabline(lm_fit, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\nWe can also see that we have data for three different species of penguins. We can therefore partition the visualization for each species individually:\n\nplot(penguins$flipper_len, penguins$body_mass, col = penguins$species)\n\n\n\n\n\n\n\n\n\n\n\nBase R plotting is very convenient for quick and dirty data summaries, particularly immediately after reading unknown data. However, for anything more complex (and anything more pretty), ggplot2 is unbeatable. We will be looking at ggplot2 visualization in the session on tidyverse but as a sneakpeak, you can take a look at the beautiful figures you‚Äôll learn how to make later.\n\n\n\n\n\n\nSee the sneakpeak\n\n\n\n\n\nLook how comparatively little code we need to make beautiful informative figures which immediately tell a clear story! Stay tuned for later! :)\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nggplot(penguins) +\n  geom_histogram(aes(flipper_len, fill = species), alpha = 0.5) +\n  theme_minimal() +\n  ggtitle(\"Distribution of flipper lengths across species\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(flipper_len, body_mass, shape = sex, color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~ species) +\n  theme_minimal() +\n  ggtitle(\"Body mass as a function of flipper length across penguin species\")\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R programming language</span>"
    ]
  },
  {
    "objectID": "r-thinking.html",
    "href": "r-thinking.html",
    "title": "Algorithmic thinking",
    "section": "",
    "text": "Part XYZ: Generalizing code as a function\n‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è This chapter is a work-in-progress! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\nYou now have all the individual pieces to construct a vector of allele frequency trajectories of a given length (one number in that vector corresponding to one generation of a simulation). Write a function simulate_trajectory(), which will accept the following three parameters and returns the trajectory vector as its output.\nThen simulate three trajectories with the same parameters (p_init = 0.5, generations = 1000, Ne = 1000 ‚Äì save them in variables traj1, traj2, traj3) and visualize them on a single plot using the functions plot() and lines() just as we did earlier.\nYes, this basically involves taking the code you have already written and just wrapping it up in a self-contained function!",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algorithmic thinking</span>"
    ]
  },
  {
    "objectID": "r-thinking.html#part-xyz-generalizing-code-as-a-function",
    "href": "r-thinking.html#part-xyz-generalizing-code-as-a-function",
    "title": "Algorithmic thinking",
    "section": "",
    "text": "p_init: initial allele frequency\ngenerations: number of generations to simulate\nNe: effective population size\n\n\n\n\n\n\n\n\n\nClick here if you need a hint\n\n\n\n\n\nIf you need a little help, you can start with this ‚Äútemplate‚Äù of the function structure, and just fill in the details.\nThis is the structure of your function:\n\nsimulate_trajectory &lt;- function(p_init, Ne, generatinos) {\n  # ...\n  # here is where you will put your code\n  # ...\n}\n\nAnd this is how you then call it:\n\ntraj &lt;- simulate_trajectory(p_init = 0.5, Ne = 1000, generations = 1000)\n\nOf course, you should inspect the result traj and plot it too.\n\n\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nsimulate_trajectory &lt;- function(p_init, Ne, generations) {\n  trajectory &lt;- c(p_init)\n\n  # for each generation...\n  for (gen in seq_len(generations - 1)) {\n    # ... based on the allele frequency in the current generation...\n    p_current &lt;- trajectory[gen]\n    # ... compute the frequency in the next generation...\n    n_next &lt;- rbinom(Ne, 1, p_current)\n    p_next &lt;- sum(n_next) / Ne\n    # ... and save it in the trajectory vector\n    trajectory[gen + 1] &lt;- p_next\n  }\n  \n  return(trajectory)\n}\n\ntraj1 &lt;- simulate_trajectory(p_init = 0.5, Ne = 1000, generations = 1000)\ntraj2 &lt;- simulate_trajectory(p_init = 0.5, Ne = 1000, generations = 1000)\ntraj3 &lt;- simulate_trajectory(p_init = 0.5, Ne = 1000, generations = 1000)\n\nplot(traj1, type = \"l\", xlim = c(1, 1000), ylim = c(0, 1), xlab = \"generations\", ylab = \"allele frequency\")\nlines(traj2)\nlines(traj3)\n\n\n\n\n\n\n\n\nNote: The lines() function will not do anything on its own. You use it to add elements to an already exiting figure.",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algorithmic thinking</span>"
    ]
  },
  {
    "objectID": "r-thinking.html#part-xyz-return-result-as-a-data-frame",
    "href": "r-thinking.html#part-xyz-return-result-as-a-data-frame",
    "title": "Algorithmic thinking",
    "section": "Part XYZ: Return result as a data frame",
    "text": "Part XYZ: Return result as a data frame\nNow, this one will probably not make much sense now but let‚Äôs do this as a practice, for the time being. Modify the simulate_trajectory() function to return a data frame with the following format (this shows just the first five rows). In other words:\n\nthe column time gives the time at which the frequency was simulated\nthe column frequency contains the simulated vector, (basically, the index of the for loop iteration),\np_init_ and Ne indicate the parameters of the simulation run (and are, therefore, constant for all rows).\n\n\n\n\n\n\np_init\nNe\ntime\nfrequency\n\n\n\n\n0.5\n1000\n1\n0.500\n\n\n0.5\n1000\n2\n0.495\n\n\n0.5\n1000\n3\n0.498\n\n\n0.5\n1000\n4\n0.527\n\n\n0.5\n1000\n5\n0.519\n\n\n\n\n\nHint: Remember to use the tibble() function to create your data frame (you will need to first load the tibble R package with library(tibble)!), not the default data.frame() function. This will make your life significantly easier.\nNote: It might seem super redundant to drag the repeated p_init and Ne, columns in the table, compared to the previous solution of just returning the numeric vector. Of course, which option is better depends on the concrete situation. In this case, the reason for tracking all this ‚Äúmetadata‚Äù along with the frequency vector will become clearer later.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nsimulate_trajectory &lt;- function(p_init, Ne, generations) {\n  trajectory &lt;- c(p_init)\n\n  # for each generation...\n  for (gen in seq_len(generations - 1)) {\n    # ... based on the allele frequency in the current generation...\n    p_current &lt;- trajectory[gen]\n    # ... compute the frequency in the next generation...\n    n_next &lt;- rbinom(Ne, 1, p_current)\n    p_next &lt;- sum(n_next) / Ne\n    # ... and save it in the trajectory vector\n    trajectory[gen + 1] &lt;- p_next\n  }\n  \n  df &lt;- tibble(\n    p_init = p_init,\n    Ne = Ne,\n    time = generations,\n    frequency = trajectory\n  )\n  \n  df\n}\n\nsimulate_trajectory(p_init = 0.5, Ne = 1000, generations = 1000)\n\n# A tibble: 1,000 √ó 4\n   p_init    Ne  time frequency\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1    0.5  1000  1000     0.5  \n 2    0.5  1000  1000     0.494\n 3    0.5  1000  1000     0.515\n 4    0.5  1000  1000     0.521\n 5    0.5  1000  1000     0.531\n 6    0.5  1000  1000     0.512\n 7    0.5  1000  1000     0.507\n 8    0.5  1000  1000     0.508\n 9    0.5  1000  1000     0.488\n10    0.5  1000  1000     0.476\n# ‚Ñπ 990 more rows",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algorithmic thinking</span>"
    ]
  },
  {
    "objectID": "r-thinking.html#part-xyz-running-simulations-in-a-loop",
    "href": "r-thinking.html#part-xyz-running-simulations-in-a-loop",
    "title": "Algorithmic thinking",
    "section": "Part XYZ: Running simulations in a loop",
    "text": "Part XYZ: Running simulations in a loop\nYou have now generalized your code so that it is much more flexible by accepting parameters as function inputs. Let‚Äôs utilize this self-contained function to run 20 simulations using the function lapply (getting 20 vectors saved in a list in a variable traj_list) and then plot the results by looping over each vector of traj_list in a for loop.\nHint: You can first initialize an empty plot by calling this bit of code:\n\nplot(NULL, type = \"l\", xlim = c(1, 1000), ylim = c(0, 1),\n     xlab = \"generations\", ylab = \"allele frequency\")\n\nThis basically sets up the context for all trajectories, which you can then plot in the for loop by calling something like lines(&lt;variable&gt;) in the loop body.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# run 20 replicates of the simulation\nreplicates &lt;- 20\n\nsimulations &lt;- lapply(\n  1:replicates,\n  function(i) simulate_trajectory(p_init = 0.5, generations = 1000, Ne = 1000)\n)\n\n# create an empty plot (we have to specify the boundaries and other parameters!)\nplot(NULL, type = \"l\", xlim = c(1, 1000), ylim = c(0, 1), xlab = \"generations\", ylab = \"allele frequency\")\n\n# then overlay all trajectories in a loop\nfor (df in simulations) {\n  lines(df$frequency)\n}",
    "crumbs": [
      "R programming",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Algorithmic thinking</span>"
    ]
  },
  {
    "objectID": "repro-cli.html",
    "href": "repro-cli.html",
    "title": "Command-line scripts",
    "section": "",
    "text": "Part XYZ: Building a command-line script\nIn the previous chapter, you generalized an R script for simulating genetic drift into a dedicated function. In this way, you have taken an important step towards reproducibility of your code. In situations in which you need to run a number of simulations for a (potentially very large) set of parameter combinations, a naive approach would‚Äôve been to copy-paste bits of code, one copy for one batch of simulations. This would work, but it would be very annoying and boring to do, and it would be significantly error-prone.\nFinding a mistake in a very long R script which contains repeated copies of very similar bits of code is a disaster. Instead of this repetition, you can now have all the logic of your simulation in one single place (a function) and reduce the repetition to only calling the function with specific parameter values as needed. In fact, you later went even one step further, and reduced even that repetition to calling a single for loop!",
    "crumbs": [
      "Reproducible computing",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Command-line scripts</span>"
    ]
  },
  {
    "objectID": "repro-cli.html#part-xyz-add-a-help-message",
    "href": "repro-cli.html#part-xyz-add-a-help-message",
    "title": "Command-line scripts",
    "section": "Part XYZ: Add a help message",
    "text": "Part XYZ: Add a help message",
    "crumbs": [
      "Reproducible computing",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Command-line scripts</span>"
    ]
  },
  {
    "objectID": "tidy-tables.html",
    "href": "tidy-tables.html",
    "title": "Tidyverse introduction",
    "section": "",
    "text": "Part XYZ:\nBefore we begin, let‚Äôs introduce the two stars of the tidyverse ecosystem, which we will be using here:\nEvery single script you will be writing in this session will begin with these two lines of code.\nLet‚Äôs also introduce a second star in this session, our example data set. This commands reads a metadata table from a recent huge aDNA paper on the history or the Holocene in West Eurasia, dubbed ‚ÄúMesoNeo‚Äù (reference). You can read it like this, which will save it to a variable df. Everything in the section on tidyverse will revolve around this data.",
    "crumbs": [
      "Welcome to tidyverse",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Tidyverse introduction</span>"
    ]
  },
  {
    "objectID": "tidy-tables.html#part-xyz-filtering-rows",
    "href": "tidy-tables.html#part-xyz-filtering-rows",
    "title": "Tidyverse introduction",
    "section": "Part XYZ: Filtering rows",
    "text": "Part XYZ: Filtering rows\nBase R indexing recap",
    "crumbs": [
      "Welcome to tidyverse",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Tidyverse introduction</span>"
    ]
  },
  {
    "objectID": "tidy-tables.html#part-xyz-selecting-columns",
    "href": "tidy-tables.html#part-xyz-selecting-columns",
    "title": "Tidyverse introduction",
    "section": "Part XYZ: Selecting columns",
    "text": "Part XYZ: Selecting columns",
    "crumbs": [
      "Welcome to tidyverse",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Tidyverse introduction</span>"
    ]
  },
  {
    "objectID": "tidy-tables.html#part-xyz-summarizing-data",
    "href": "tidy-tables.html#part-xyz-summarizing-data",
    "title": "Tidyverse introduction",
    "section": "Part XYZ: Summarizing data",
    "text": "Part XYZ: Summarizing data",
    "crumbs": [
      "Welcome to tidyverse",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Tidyverse introduction</span>"
    ]
  },
  {
    "objectID": "tidy-ggplot.html",
    "href": "tidy-ggplot.html",
    "title": "Data visualization with ggplot2",
    "section": "",
    "text": "library(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf &lt;- read_tsv(\"https://tinyurl.com/qwe-asd-zxc\")\n\nRows: 4172 Columns: 32\n\n\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \"\\t\"\nchr (22): sampleId, popId, site, country, region, groupLabel, groupAge, flag...\ndbl (10): shapeA, latitude, longitude, age14C, ageHigh, ageLow, ageAverage, ...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "Welcome to tidyverse",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Data visualization with ggplot2</span>"
    ]
  },
  {
    "objectID": "popgen-models.html",
    "href": "popgen-models.html",
    "title": "Demographic models",
    "section": "",
    "text": "Part 1: Building a demographic model in slendr\nIn this exercise, you will practice building demographic models from scratch using the programmable interface provided by the slendr R package. In this context, you can understand ‚Äúdemographic model‚Äù as ‚Äúa tree-like topological structure encoding the relationships between populations and gene flows between them‚Äù. For the time being, these models will be always neutral and will conform to Wright-Fisher assumptions.\nUse functions such as population(), gene_flow(), and compile_model(), which we discussed in ‚ÄúIntroduction to slendr‚Äù, to program the following toy model of human demographic history in slendr. (Apologies for my bad handwriting and the lack of any artistic skill.)\nHint: Create a new script models.R in your RStudio session using the following ‚Äútemplate‚Äù. Then add a sequence of appropriate population() calls using the syntax from the introductory slides (using the parent = &lt;pop&gt; argument for programming splits of daughter populations ‚Äì which will be all except the CHIMP lineage in our example), etc.\nlibrary(slendr)\ninit_env()\n\n# &lt;replace this with `population()` definitions like in the slides&gt;\n# &lt;replace this with your gene-flow definition in variable `gf`&gt;\n\nmodel &lt;- compile_model(\n  populations = list(...), # &lt;put your list of populations here&gt;\n  gene_flow = gf,\n  generation_time = 30\n)\nHint: Remember that slendr is designed with interactivity in mind! When you write a chunk of code (such as a command to create a population through a population split, or model compilation to create a model object), execute that bit of code in the R console and inspect the summary information printed by evaluating the respective R object you just created. You can either copy-pasted stuff from your script to the R console, or use a convenient RStudio shortcut like Ctrl+Enter (Linux and Windows), or Cmd+Enter (Mac).",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Demographic models</span>"
    ]
  },
  {
    "objectID": "popgen-models.html#part-1-building-a-demographic-model-in-slendr",
    "href": "popgen-models.html#part-1-building-a-demographic-model-in-slendr",
    "title": "Demographic models",
    "section": "",
    "text": "Note: You could easily program the model so that different ancestral populations are represented by separate population() commands (i.e., your model would start with a population called ‚Äúhuman_chimp_ancestor‚Äù from which a ‚ÄúCHIMP‚Äù and ‚Äúhominin_ancestor‚Äù populations would split at 6 Mya, etc.) but generally this is too annoying to do and requires too much code.\nFeel free to write the model so that ‚ÄúCHIMP‚Äù is the first population, then ‚ÄúAFR‚Äù population splits from it at 6 Mya, etc‚Ä¶ Although it probably isn‚Äôt the most accurate way to describe the real evolutionary history, it simplifies the coding significantly.\n [Mya = million years ago; kya = thousand years ago]\n\n\n\n\nNote: With slendr you can specify time in whatever format is more convenient or readable for your model. For instance here, because we‚Äôre dealing with historical events which are commonly expressed in times given as‚Äùyears ago‚Äù, we can write them in a decreasing order ‚Äì i.e.¬†7Mya ‚Üí 6Mya ‚Üí ‚Ä¶, as shown above ‚Äì or, in terms of R code, 7e6 (or 7000000), 6e6 (6000000), etc.\nIn a later example, you will see that you can also encode the events in the time direction going ‚Äúforward‚Äù (i.e., the first event starting in generation 1, a following event in generation 42, and so on).\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nlibrary(slendr)\ninit_env()\n## The interface to all required Python modules has been activated.\n\ndir.create(\"files/popgen/introgression\", recursive = TRUE, showWarnings = FALSE)\n\n# Chimpanzee outgroup\nchimp &lt;- population(\"CHIMP\", time = 7e6, N = 5000)\n\n# Two populations of anatomically modern humans: Africans and Europeans\nafr &lt;- population(\"AFR\", parent = chimp, time = 6e6, N = 15000)\neur &lt;- population(\"EUR\", parent = afr, time = 60e3, N = 3000)\n\n# Neanderthal population splitting at 600 ky ago from modern humans\n# (becomes extinct by 40 ky ago)\nnea &lt;- population(\"NEA\", parent = afr, time = 600e3, N = 1000, remove = 40e3)\n\n# Neanderthal introgression event (3% admixture between 55-50 kya)\ngf &lt;- gene_flow(from = nea, to = eur, rate = 0.03, start = 55000, end = 50000)\n\n# Compile the entire model into a single slendr R object\nmodel &lt;- compile_model(\n  populations = list(chimp, nea, afr, eur),\n  gene_flow = gf,\n  generation_time = 30,\n  path = \"files/popgen/introgression\",     # &lt;--- don't worry about these two\n  overwrite = TRUE, force = TRUE   # &lt;--- lines of code (ask me if interested)\n)",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Demographic models</span>"
    ]
  },
  {
    "objectID": "popgen-models.html#part-2-inspecting-the-model-visually",
    "href": "popgen-models.html#part-2-inspecting-the-model-visually",
    "title": "Demographic models",
    "section": "Part 2: Inspecting the model visually",
    "text": "Part 2: Inspecting the model visually\nTo visualize a slendr model, you use the function plot_model(). Plot your compiled model to make sure you programmed it correctly! Your figure should roughly correspond to my doodle above.\n\n\nNote: Plotting of models in slendr can be sometimes a little wonky, especially if many things are happening at once. When plotting your model, experiment with arguments log = TRUE, proportions = TRUE, gene_flow = TRUE. Check ?plot_model for more information on these.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nplot_model(model)\n\n\n\n\n\n\n\nplot_model(model, sizes = FALSE)\n\n\n\n\n\n\n\nplot_model(model, sizes = FALSE, log = TRUE)\n\n\n\n\n\n\n\nplot_model(model, log = TRUE, proportions = TRUE)",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Demographic models</span>"
    ]
  },
  {
    "objectID": "popgen-models.html#part-3-simulating-genomic-data",
    "href": "popgen-models.html#part-3-simulating-genomic-data",
    "title": "Demographic models",
    "section": "Part 3: Simulating genomic data",
    "text": "Part 3: Simulating genomic data\nOnce you have a compiled slendr model stored in an R variable (from now on, model will always mean a variable containing a compiled slendr model object relevant for the given exercise, for simplicity), we can simulate data from it. By default, slendr models always produce a tree sequence.\n\n\nNote: Tree sequence provides an extremely efficient means to store and work with genomic data at a massive scale. However, you can always get simulated data even in traditional file formats, such as VCF, EIGENSTRAT, or a plain old table of ancestral/derived genotypes.\nIn this activity we will be only working with tree sequences, because it‚Äôs much easier and faster to get interesting statistics from it directly in R.\nThere are two simulation engines built into slendr implemented by functions msprime() and slim(). For traditional, non-spatial, neutral demographic models, the engine provided by the msprime() function is much more efficient, so we‚Äôll be using that for the time being. However, from a popgen theoretical perspective, both simulation functions will give you the same results for any given compiled slendr model (up to some level of stochastic noise, of course).\n\n\nNote: Yes, this means you don‚Äôt have to write any msprime (or SLiM) code to simulate data from a slendr model!\nHere‚Äôs how you can use the function to simulate a tree sequence from the model you‚Äôve just created using compile_model() in your script:\n\nts &lt;- msprime(\n  model,\n  sequence_length = &lt;length of sequence to simulate [as bp]&gt;,\n  recombination_rate = &lt;uniform recombination rate [per bp per generation]&gt;\n)\n\nYou will be seeing this kind of pattern over and over again in this exercise, so it‚Äôs a good idea to keep it in mind.\nHint: The msprime() function has also arguments debug and run which can be extremely useful for debugging.\nSimulate a tree sequence from your compiled model using the msprime() engine, storing it to a variable ts as shown right above. Use sequence_length = 1e6 (so 1 Mb of sequence) and recombination_rate = 1e-8 (crossover events per base pair per generation). Then experiment with setting debug = TRUE (this prints out msprime‚Äôs own debugging summary which you might already be familiar with from your previous activity?) and then run = FALSE (this prints out a raw command-line which can run a slendr simulation in the shell).\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# This simulates a tskit tree sequence from a slendr model. Note that you didn't have\n# to write any msprime or tskit Python code!\nts &lt;- msprime(model, sequence_length = 1e6, recombination_rate = 1e-8)\n\n# Setting `debug = TRUE` instructs slendr's built-in msprime script to print\n# out msprime's own debugger information. This can be very useful for debugging,\n# in addition to the visualization of the model as shown above.\nts &lt;- msprime(model, sequence_length = 1e6, recombination_rate = 1e-8, debug = TRUE)\n## DemographyDebugger\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n## ‚ïë Epoch[0]: [0, 1.67e+03) generations ‚ïë\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n## ‚ïü    Populations (total=4 active=4)\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ       ‚îÇ     start‚îÇ       end‚îÇgrowth_rate  ‚îÇ CHIMP ‚îÇ AFR ‚îÇ NEA ‚îÇ EUR ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  CHIMP‚îÇ    5000.0‚îÇ    5000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    AFR‚îÇ   15000.0‚îÇ   15000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    NEA‚îÇ    1000.0‚îÇ    1000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    EUR‚îÇ    3000.0‚îÇ    3000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ïü    Events @ generation 1.67e+03\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ  time‚îÇtype            ‚îÇparameters              ‚îÇeffect                                  ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  1666‚îÇMigration rate  ‚îÇsource=EUR, dest=NEA,   ‚îÇBackwards-time migration rate from EUR  ‚îÇ\n## ‚ïë    ‚îÇ      ‚îÇchange          ‚îÇrate=0.000179640718562  ‚îÇto NEA ‚Üí 0.00017964071856287425         ‚îÇ\n## ‚ïë    ‚îÇ      ‚îÇ                ‚îÇ87425                   ‚îÇ                                        ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n## ‚ïë Epoch[1]: [1.67e+03, 1.83e+03) generations ‚ïë\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n## ‚ïü    Populations (total=4 active=4)\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ       ‚îÇ     start‚îÇ       end‚îÇgrowth_rate  ‚îÇ CHIMP ‚îÇ AFR ‚îÇ    NEA    ‚îÇ EUR ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  CHIMP‚îÇ    5000.0‚îÇ    5000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ     0     ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    AFR‚îÇ   15000.0‚îÇ   15000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ     0     ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    NEA‚îÇ    1000.0‚îÇ    1000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ     0     ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    EUR‚îÇ    3000.0‚îÇ    3000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ 0.0001796 ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ïü    Events @ generation 1.83e+03\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ  time‚îÇtype            ‚îÇparameters             ‚îÇeffect                                  ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  1833‚îÇMigration rate  ‚îÇsource=EUR, dest=NEA,  ‚îÇBackwards-time migration rate from EUR  ‚îÇ\n## ‚ïë    ‚îÇ      ‚îÇchange          ‚îÇrate=0                 ‚îÇto NEA ‚Üí 0                              ‚îÇ\n## ‚ïë    ‚îÇ‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îÇ\n## ‚ïë    ‚îÇ  1833‚îÇCensus          ‚îÇ                       ‚îÇInsert census nodes to record the       ‚îÇ\n## ‚ïë    ‚îÇ      ‚îÇ                ‚îÇ                       ‚îÇlocation of all lineages                ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n## ‚ïë Epoch[2]: [1.83e+03, 2e+03) generations ‚ïë\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n## ‚ïü    Populations (total=4 active=4)\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ       ‚îÇ     start‚îÇ       end‚îÇgrowth_rate  ‚îÇ CHIMP ‚îÇ AFR ‚îÇ NEA ‚îÇ EUR ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  CHIMP‚îÇ    5000.0‚îÇ    5000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    AFR‚îÇ   15000.0‚îÇ   15000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    NEA‚îÇ    1000.0‚îÇ    1000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    EUR‚îÇ    3000.0‚îÇ    3000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ïü    Events @ generation 2e+03\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ  time‚îÇtype        ‚îÇparameters      ‚îÇeffect                                ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  2000‚îÇPopulation  ‚îÇderived=[EUR],  ‚îÇMoves all lineages from the 'EUR'     ‚îÇ\n## ‚ïë    ‚îÇ      ‚îÇSplit       ‚îÇancestral=AFR   ‚îÇderived population to the ancestral   ‚îÇ\n## ‚ïë    ‚îÇ      ‚îÇ            ‚îÇ                ‚îÇ'AFR' population. Also set 'EUR' to   ‚îÇ\n## ‚ïë    ‚îÇ      ‚îÇ            ‚îÇ                ‚îÇinactive, and all migration rates to  ‚îÇ\n## ‚ïë    ‚îÇ      ‚îÇ            ‚îÇ                ‚îÇand from the derived population to    ‚îÇ\n## ‚ïë    ‚îÇ      ‚îÇ            ‚îÇ                ‚îÇzero.                                 ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n## ‚ïë Epoch[3]: [2e+03, 2e+04) generations ‚ïë\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n## ‚ïü    Populations (total=4 active=3)\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ       ‚îÇ     start‚îÇ       end‚îÇgrowth_rate  ‚îÇ CHIMP ‚îÇ AFR ‚îÇ NEA ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  CHIMP‚îÇ    5000.0‚îÇ    5000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    AFR‚îÇ   15000.0‚îÇ   15000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    NEA‚îÇ    1000.0‚îÇ    1000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ïü    Events @ generation 2e+04\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ   time‚îÇtype        ‚îÇparameters      ‚îÇeffect                                ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  2e+04‚îÇPopulation  ‚îÇderived=[NEA],  ‚îÇMoves all lineages from the 'NEA'     ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇSplit       ‚îÇancestral=AFR   ‚îÇderived population to the ancestral   ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇ            ‚îÇ                ‚îÇ'AFR' population. Also set 'NEA' to   ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇ            ‚îÇ                ‚îÇinactive, and all migration rates to  ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇ            ‚îÇ                ‚îÇand from the derived population to    ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇ            ‚îÇ                ‚îÇzero.                                 ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n## ‚ïë Epoch[4]: [2e+04, 2e+05) generations ‚ïë\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n## ‚ïü    Populations (total=4 active=2)\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ       ‚îÇ     start‚îÇ       end‚îÇgrowth_rate  ‚îÇ CHIMP ‚îÇ AFR ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  CHIMP‚îÇ    5000.0‚îÇ    5000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îÇ    AFR‚îÇ   15000.0‚îÇ   15000.0‚îÇ 0           ‚îÇ   0   ‚îÇ  0  ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ïü    Events @ generation 2e+05\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ   time‚îÇtype        ‚îÇparameters       ‚îÇeffect                                 ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  2e+05‚îÇPopulation  ‚îÇderived=[AFR],   ‚îÇMoves all lineages from the 'AFR'      ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇSplit       ‚îÇancestral=CHIMP  ‚îÇderived population to the ancestral    ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇ            ‚îÇ                 ‚îÇ'CHIMP' population. Also set 'AFR' to  ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇ            ‚îÇ                 ‚îÇinactive, and all migration rates to   ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇ            ‚îÇ                 ‚îÇand from the derived population to     ‚îÇ\n## ‚ïë    ‚îÇ       ‚îÇ            ‚îÇ                 ‚îÇzero.                                  ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n## ‚ïë Epoch[5]: [2e+05, inf) generations ‚ïë\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n## ‚ïü    Populations (total=4 active=1)\n## ‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n## ‚ïë    ‚îÇ       ‚îÇ    start‚îÇ      end‚îÇgrowth_rate  ‚îÇ\n## ‚ïë    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n## ‚ïë    ‚îÇ  CHIMP‚îÇ   5000.0‚îÇ   5000.0‚îÇ 0           ‚îÇ\n## ‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n# For debugging of technical issues (with msprime, with slendr, or both), it is\n# very useful to have the `msprime` function dump the \"raw\" command-line to\n# run the simulation on the terminal using plain Python interpreter\nmsprime(model, sequence_length = 1e6, recombination_rate = 1e-8, run = FALSE)\n## /Users/mp/Library/r-miniconda-arm64/envs/Python-3.12_msprime-1.3.4_tskit-0.6.4_pyslim-1.0.4_tspop-0.0.2/bin/python /Users/mp/Code/simgen/files/popgen/introgression/script.py --seed 484205524 --model /Users/mp/Code/simgen/files/popgen/introgression --sequence-length 1000000 --recombination-rate 1e-08    --coalescent_only --path path_to_a_trees_file.trees",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Demographic models</span>"
    ]
  },
  {
    "objectID": "popgen-models.html#part-4-inspecting-the-tree-sequence-object",
    "href": "popgen-models.html#part-4-inspecting-the-tree-sequence-object",
    "title": "Demographic models",
    "section": "Part 4: Inspecting the tree-sequence object",
    "text": "Part 4: Inspecting the tree-sequence object\nAs we will see later, slendr provides an R-friendly interface to accessing a subset of tskit‚Äôs functionality for working with tree sequences and for computing various popgen statistics.\nFor now, type out the ts object in the terminal ‚Äì what do you see? You should get a summary of a tree-sequence object that you‚Äôre familiar with from your msprime and tskit activity earlier in the day.\n\n\nNote: This is a very important feature of slendr ‚Äì when a simulation is concluded (doesn‚Äôt matter if it was a slim() or msprime() simulation), you will get a normal tskit object. In fact, the fact that slendr supports (so far, and likely always) only a ‚Äúsubset‚Äù of all of tskit‚Äôs functionality isn‚Äôt stopping you to write custom Python/tskit processing code of a tree sequence generated from a slendr model. Under the hood, a slendr simulation really is just an msprime (or SLiM) simulation! It‚Äôs just executed through a simplified interface.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# Typing out the object with the result shows that it's a good old tskit\n# tree-sequence object\nts\n\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïëTreeSequence               ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïëTrees          ‚îÇ      9,804‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSequence Length‚îÇ  1,000,000‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëTime Units     ‚îÇgenerations‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSample Nodes   ‚îÇ     48,000‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëTotal Size     ‚îÇ    8.9 MiB‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïëTable      ‚îÇRows   ‚îÇSize     ‚îÇHas Metadata‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïëEdges      ‚îÇ134,914‚îÇ  4.1 MiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëIndividuals‚îÇ 24,000‚îÇ656.3 KiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëMigrations ‚îÇ      0‚îÇ  8 Bytes‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëMutations  ‚îÇ      0‚îÇ 16 Bytes‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëNodes      ‚îÇ105,030‚îÇ  2.8 MiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëPopulations‚îÇ      4‚îÇ341 Bytes‚îÇ         Yes‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëProvenances‚îÇ      1‚îÇ  2.7 KiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSites      ‚îÇ      0‚îÇ 16 Bytes‚îÇ          No‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\n\n\n\n\nThe brilliance of the tree-sequence data structure rests on its elegant table-based implementation (much more information on that is here). slendr isn‚Äôt really designed to run very complex low-level manipulations of tree-sequence data (its strength lies in the convenient interface to popgen statistical functions implemented by tskit), but it does contain a couple of functions which can be useful for inspecting the lower-level nature of a tree sequence. Let‚Äôs look at a couple of them now.\nUse the ts_table function to inspect the low-level table-based representation of a tree sequence. For instance, you can get the table of nodes with ts_table(ts, \"nodes\"), edges with ts_table(ts, \"edges\"), and do the same thing for ‚Äúindividuals‚Äù, ‚Äúmutations‚Äù, and ‚Äúsites‚Äù. Does your tree sequence contain any mutations? If not, why, and how can we even do any popgen with data without any mutations? As you‚Äôre doing this, take a look at at the following figure (this was made from a different tree sequence than you have, but that‚Äôs OK) to help you relate the information in the tables to a tree sequence which those tables (particularly tables of nodes and edges) implicitly encode.\nThis should convince you that the final product of a slendr simulation really is the same kind of tree-sequence object that you learned about in the previous activities today. You don‚Äôt have to study these tables in detail!\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# slendr provides a helper function which allows access to all the low-level\n# components of every tree-sequence object\nts_table(ts, \"nodes\")\n\n# A tibble: 105,030 √ó 5\n   node_id    ind_id pop_id  time time_tskit\n     &lt;int&gt; &lt;int[1d]&gt;  &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1       0         0      0     0          0\n 2       1         0      0     0          0\n 3       2         1      0     0          0\n 4       3         1      0     0          0\n 5       4         2      0     0          0\n 6       5         2      0     0          0\n 7       6         3      0     0          0\n 8       7         3      0     0          0\n 9       8         4      0     0          0\n10       9         4      0     0          0\n# ‚Ñπ 105,020 more rows\n\nts_table(ts, \"edges\")\n\n# A tibble: 134,914 √ó 5\n      id child parent  left   right\n   &lt;dbl&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     0  8385  48000     0 1000000\n 2     1  9754  48000     0 1000000\n 3     2  7264  48001     0 1000000\n 4     3  8005  48001     0 1000000\n 5     4 15046  48002     0 1000000\n 6     5 35886  48002     0 1000000\n 7     6 11036  48003     0 1000000\n 8     7 22510  48003     0 1000000\n 9     8 32508  48004     0 1000000\n10     9 36731  48004     0 1000000\n# ‚Ñπ 134,904 more rows\n\nts_table(ts, \"individuals\")\n\n# A tibble: 24,000 √ó 5\n   ind_id  time    pop_id sampled   time_tskit\n    &lt;dbl&gt; &lt;dbl&gt; &lt;int[1d]&gt; &lt;lgl[1d]&gt;  &lt;dbl[1d]&gt;\n 1      0     0         0 TRUE               0\n 2      1     0         0 TRUE               0\n 3      2     0         0 TRUE               0\n 4      3     0         0 TRUE               0\n 5      4     0         0 TRUE               0\n 6      5     0         0 TRUE               0\n 7      6     0         0 TRUE               0\n 8      7     0         0 TRUE               0\n 9      8     0         0 TRUE               0\n10      9     0         0 TRUE               0\n# ‚Ñπ 23,990 more rows\n\n# We didn't simulate any mutations, so we only have genealogies for now.\nts_table(ts, \"mutations\")\n\n# A tibble: 0 √ó 5\n# ‚Ñπ 5 variables: id &lt;dbl&gt;, site &lt;int&gt;, node &lt;int&gt;, time &lt;dbl&gt;, time_tskit &lt;dbl&gt;\n\nts_table(ts, \"sites\")\n\n# A tibble: 0 √ó 2\n# ‚Ñπ 2 variables: id &lt;dbl&gt;, position &lt;dbl&gt;\n\n\n\n\n\nThere are also two slendr-specific functions called ts_samples() (which retrieves the ‚Äúsymbolic names‚Äù and dates of all recorded individuals at the end of a simulation) and ts_nodes(). You can run them simply as ts_samples(ts) and ts_nodes(ts). How many individuals (samples) are in your tree sequence as you simulated it? How is the result of ts_nodes() different from ts_samples()?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# slendr provides a convenient function `ts_samples()` which allows us to\n# inspect the contents of a simulated tree sequence in a more human-readable,\n# simplified way. We can see that our tree sequence contains a massive number\n# of individuals. Too many, in fact -- we recorded every single individual alive\n# at the end of our simulation, which is something we're unlikely to be ever lucky\n# enough to have, regardless of which species we study.\nts_samples(ts)\n\n# A tibble: 24,000 √ó 3\n   name      time pop  \n   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;\n 1 CHIMP_1      0 AFR  \n 2 CHIMP_2      0 AFR  \n 3 CHIMP_3      0 AFR  \n 4 CHIMP_4      0 AFR  \n 5 CHIMP_5      0 AFR  \n 6 CHIMP_6      0 AFR  \n 7 CHIMP_7      0 AFR  \n 8 CHIMP_8      0 AFR  \n 9 CHIMP_9      0 AFR  \n10 CHIMP_10     0 AFR  \n# ‚Ñπ 23,990 more rows\n\nts_samples(ts) %&gt;% nrow()\n\n[1] 24000\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nts_samples(ts) %&gt;% group_by(pop) %&gt;% tally\n\n# A tibble: 4 √ó 2\n  pop       n\n  &lt;chr&gt; &lt;int&gt;\n1 AFR   15000\n2 CHIMP  5000\n3 EUR    3000\n4 NEA    1000\n\n# This function returns a table similar to the one produced by `ts_table(ts, \"nodes\")`\n# above, except that it contains additional slendr metadata (names of individuals\n# belonging to each node, spatial coordinates of nodes for spatial models, etc.).\n# It's a bit more useful for analyzing tree-sequence data than the \"low-level\" functions.\nts_nodes(ts) %&gt;% head(5)\n\n# A tibble: 5 √ó 8\n  name    pop   ind_id node_id  time time_tskit sampled pop_id\n  &lt;chr&gt;   &lt;fct&gt;  &lt;dbl&gt;   &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;    &lt;int&gt;\n1 CHIMP_1 AFR     5000   10000     0          0 TRUE         1\n2 CHIMP_1 AFR     5000   10001     0          0 TRUE         1\n3 CHIMP_2 AFR     5001   10002     0          0 TRUE         1\n4 CHIMP_2 AFR     5001   10003     0          0 TRUE         1\n5 CHIMP_3 AFR     5002   10004     0          0 TRUE         1\n\nts_nodes(ts) %&gt;% tail(5)\n\n# A tibble: 5 √ó 8\n  name  pop   ind_id node_id     time time_tskit sampled pop_id\n  &lt;chr&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;lgl&gt;    &lt;int&gt;\n1 &lt;NA&gt;  CHIMP     NA  105025 7501790.    250060. FALSE        0\n2 &lt;NA&gt;  CHIMP     NA  105026 7646989.    254900. FALSE        0\n3 &lt;NA&gt;  CHIMP     NA  105027 7655469.    255182. FALSE        0\n4 &lt;NA&gt;  CHIMP     NA  105028 7857064.    261902. FALSE        0\n5 &lt;NA&gt;  CHIMP     NA  105029 8218614.    273954. FALSE        0",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Demographic models</span>"
    ]
  },
  {
    "objectID": "popgen-models.html#part-6-more-complex-sampling-events",
    "href": "popgen-models.html#part-6-more-complex-sampling-events",
    "title": "Demographic models",
    "section": "Part 6: More complex sampling events",
    "text": "Part 6: More complex sampling events\nIn the table produced by the ts_samples() function you saw that the tree sequence we simulated recorded everyone. It‚Äôs very unlikely, unless we‚Äôre extremely lucky, that we‚Äôll ever have a sequence of every single individual in a population that we study. To get a little closer to the scale of the genomic data that we usually work with on a day-to-day basis, we can restrict our simulation to only record a subset of individuals.\nWe can precisely define which individuals (from which populations, and at which times) should be recorded in a tree sequence using the slendr function schedule_sampling(). For instance, if we have a model with some slendr populations in variables eur and afr, we can schedule the recording of 5 individuals from each at times 10000 (years ago) and 0 (present-day) (using the ‚Äúyears before present‚Äù direction of time in our current model of Neanderthal introgression) with the following code:\n\npop_schedule &lt;- schedule_sampling(model, times = c(10000, 0), list(eur, 5), list(afr, 5))\n\nThis function simply returns a data frame. As such, we can create multiple of such schedules (of arbitrary complexity and granularity), and then bind them together into a single sampling schedule with a single line of code, like this:\n\n# Note that the `times =` argument of the `schedule_sampling()` function can be\n# a vector of times like here...\nancient_times &lt;- c(40000, 30000, 20000, 10000)\neur_samples &lt;- schedule_sampling(model, times = ancient_times, list(eur, 1))\n\n# ... but also just a single number like here\nafr_samples &lt;- schedule_sampling(model, times = 0, list(afr, 1))\nnea_samples &lt;- schedule_sampling(model, time = 60000, list(nea, 1))\n\n# But whatever the means you create the individual sampling schedules with,\n# you can always bind them all to a single table with the `rbind()` function\nschedule &lt;- rbind(eur_samples, afr_samples, nea_samples)\nschedule\n\nUsing the function schedule_sampling (and with the help of rbind as shown in the previous code chunk), program the sampling of the following sample sets at given times, saving it to variable called schedule:\n\n\n\ntime\npopulation\n# individuals\n\n\n\n\n70000\nnea\n1\n\n\n40000\nnea\n1\n\n\n0\nchimp\n1\n\n\n0\nafr\n5\n\n\n0\neur\n10\n\n\n\nAdditionally, schedule the sampling of a single eur individual at the following times:\n\nt &lt;- seq(40000, 2000, by = -2000)\n\n\n\nNote: You can provide a vector variable (such as t in this example) as the times = argument of schedule_sampling().\nIn total, you should schedule the recording of 38 individuals.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# Here we scheduled the sampling of two Neanderthals at 70kya and 40kya\nnea_samples &lt;- schedule_sampling(model, times = c(70000, 40000), list(nea, 1))\nnea_samples # (this function produces a plain old data frame!)\n\n# A tibble: 2 √ó 8\n   time pop       n name  y_orig x_orig y     x    \n  &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;lgl&gt; &lt;lgl&gt;  &lt;lgl&gt;  &lt;lgl&gt; &lt;lgl&gt;\n1 40000 NEA       1 NA    NA     NA     NA    NA   \n2 70000 NEA       1 NA    NA     NA     NA    NA   \n\n# Here we schedule one Chimpanzee sample, 5 African samples, and 10 European samples\npresent_samples &lt;- schedule_sampling(model, times = 0, list(chimp, 1), list(afr, 5), list(eur, 10))\n\n# We also schedule the recording of one European sample between 50kya and 2kya,\n# every 2000 years\ntimes &lt;- seq(40000, 2000, by = -2000)\nemh_samples &lt;- schedule_sampling(model, times, list(eur, 1))\n\n# Because those functions produce nothing but a data frame, we can bind\n# individual sampling schedules together\nschedule &lt;- rbind(nea_samples, present_samples, emh_samples)\nschedule\n\n# A tibble: 25 √ó 8\n    time pop       n name  y_orig x_orig y     x    \n   &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;lgl&gt; &lt;lgl&gt;  &lt;lgl&gt;  &lt;lgl&gt; &lt;lgl&gt;\n 1 40000 NEA       1 NA    NA     NA     NA    NA   \n 2 70000 NEA       1 NA    NA     NA     NA    NA   \n 3     0 CHIMP     1 NA    NA     NA     NA    NA   \n 4     0 AFR       5 NA    NA     NA     NA    NA   \n 5     0 EUR      10 NA    NA     NA     NA    NA   \n 6  2000 EUR       1 NA    NA     NA     NA    NA   \n 7  4000 EUR       1 NA    NA     NA     NA    NA   \n 8  6000 EUR       1 NA    NA     NA     NA    NA   \n 9  8000 EUR       1 NA    NA     NA     NA    NA   \n10 10000 EUR       1 NA    NA     NA     NA    NA   \n# ‚Ñπ 15 more rows\n\n\n\n\n\nThen, verify the correctness of your overall sampling schedule by visualizing it together with your model like this:\n\n\nNote: As you‚Äôve seen above, the visualization is often a bit wonky and convoluted with overlapping elements and it can be even worse with samples added, but try to experiment with arguments to plot_model described above to make the plot a bit more helpful for sanity checking.\n\nplot_model(model, samples = schedule)\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nplot_model(model, sizes = FALSE, samples = schedule)\n\n\n\n\n\n\n\n\n\nplot_model(model, sizes = FALSE, log = TRUE, samples = schedule)",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Demographic models</span>"
    ]
  },
  {
    "objectID": "popgen-models.html#part-7-simulating-a-defined-set-of-individuals",
    "href": "popgen-models.html#part-7-simulating-a-defined-set-of-individuals",
    "title": "Demographic models",
    "section": "Part 7: Simulating a defined set of individuals",
    "text": "Part 7: Simulating a defined set of individuals\nYou have now both a compiled slendr model and a well-defined sampling schedule.\nUse your combined sampling schedule stored in the schedule variable to run a new tree-sequence simulation from your model (again using the msprime() function), this time restricted to just those individuals scheduled for recording. You can do this by providing the combined sampling schedule as the samples = schedule argument of the function msprime you used above. Just replace the line(s) with your first msprime() from the previous part of this exercise with the new one, which uses the schedule for customized sampling.\nAlso, while you‚Äôre doing this, use the ts_mutate() function to overlay neutral mutations on the simulated tree sequence right after the msprime() call. (Take a look at the handounts for a reminder of the %&gt;% pipe patterns I showed you.)\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nThe command below will likely take a few minutes to run, so feel free to go down from 100 Mb sequence_length to even 10Mb (it doesn‚Äôt matter much). (The random_seed = argument is there for reproducibility purposes.)\n\nts &lt;-\n  msprime(model, sequence_length = 100e6, recombination_rate = 1e-8, samples = schedule, random_seed = 1269258439) %&gt;%\n  ts_mutate(mutation_rate = 1e-8, random_seed = 1269258439)\n# Time difference of 2.141642 mins\n\nIf you‚Äôre bothered by how long the simulation takes, feel free to call these two lines to 100% reproduce my results without any expensive computation:\n\nurl_path &lt;- \"https://raw.githubusercontent.com/bodkan/simgen/refs/heads/main/files/popgen/introgression.trees\"\nts_path &lt;- tempfile()\ndownload.file(url_path, destfile = ts_path, mode = \"wb\")\nts &lt;- ts_read(file = ts_path, model = model)\n\n\n\n\nInspect the tree-sequence object saved in the ts variable by typing it into the R console again (this interactivity really helps with catching nasty bugs early during the programming of your script). You can also do a similar thing via the table produced by the ts_samples() function. You should see a much smaller number of individuals being recorded, indicating that the simulation was much more efficient and produced genomic data for only the individuals of interest.\n\n\nNote: When you think about it, it‚Äôs actually quite astonishing how fast msprime and tskit are when dealing with such a huge amount of sequence data from tens of thousands of individuals on a simple laptop!\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# Inspect the (tskit/Python-based) summary of the new tree sequence\n# (note the much smaller number of \"sample nodes\"!)\nts\n\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïëTreeSequence               ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïëTrees          ‚îÇ      9,804‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSequence Length‚îÇ  1,000,000‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëTime Units     ‚îÇgenerations‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSample Nodes   ‚îÇ     48,000‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëTotal Size     ‚îÇ    8.9 MiB‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïëTable      ‚îÇRows   ‚îÇSize     ‚îÇHas Metadata‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïëEdges      ‚îÇ134,914‚îÇ  4.1 MiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëIndividuals‚îÇ 24,000‚îÇ656.3 KiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëMigrations ‚îÇ      0‚îÇ  8 Bytes‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëMutations  ‚îÇ      0‚îÇ 16 Bytes‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëNodes      ‚îÇ105,030‚îÇ  2.8 MiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëPopulations‚îÇ      4‚îÇ341 Bytes‚îÇ         Yes‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëProvenances‚îÇ      1‚îÇ  2.7 KiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSites      ‚îÇ      0‚îÇ 16 Bytes‚îÇ          No‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\n# Get the table of all recorded samples in the tree sequence\nts_samples(ts)\n\n# A tibble: 24,000 √ó 3\n   name      time pop  \n   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;\n 1 CHIMP_1      0 AFR  \n 2 CHIMP_2      0 AFR  \n 3 CHIMP_3      0 AFR  \n 4 CHIMP_4      0 AFR  \n 5 CHIMP_5      0 AFR  \n 6 CHIMP_6      0 AFR  \n 7 CHIMP_7      0 AFR  \n 8 CHIMP_8      0 AFR  \n 9 CHIMP_9      0 AFR  \n10 CHIMP_10     0 AFR  \n# ‚Ñπ 23,990 more rows\n\n# Compute the count of individuals in different time points\nlibrary(dplyr)\n\nts_samples(ts) %&gt;% group_by(pop, present_day = time == 0) %&gt;% tally %&gt;% select(present_day, pop, n)\n\n# A tibble: 4 √ó 3\n# Groups:   pop [4]\n  present_day pop       n\n  &lt;lgl&gt;       &lt;chr&gt; &lt;int&gt;\n1 TRUE        AFR   15000\n2 TRUE        CHIMP  5000\n3 TRUE        EUR    3000\n4 TRUE        NEA    1000",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Demographic models</span>"
    ]
  },
  {
    "objectID": "popgen-stats.html",
    "href": "popgen-stats.html",
    "title": "Tree-sequence statistics",
    "section": "",
    "text": "Part 1: Computing nucleotide diversity\nIn this exercise, you will build on top of the results from the exercise on programming demographic models. Specifically, we will learn how to compute popgen statistics on slendr-simulated tree sequences using slendr‚Äôs interface to the tskit Python module.\nFirst, create a new R script stats.R and paste in the following code. This is one of the possible solutions to the Exercise 1, and it‚Äôs easier if we all use it to be on the same page from now on, starting from the same model and the same simulated tree sequence:\nAs a sanity check, let‚Äôs use a couple of tidyverse table-munging tricks to make sure the tree sequence does contain a set of sample which matches our intended sampling schedule (particularly the time series of European individuals and the two Neanderthals):\nEverything looks good! Having made sure that the ts object contains the individuals we want, let‚Äôs move to the exercise.\nThe toy model of ancient human history plotted above makes a fairly clear prediction of what would be the nucleotide diversity expected in the simulated populations. Compute the nucleotide diversity in all populations using the slendr function ts_diversity() in your tree sequence ts. Do you get numbers that (relatively between all populations) match what would expect from the model given the \\(N_e\\) that you programmed for each?\nHint: Nearly every slendr statistic function interfacing with tskit accepts a ts tree-sequence object as its first argument, with further arguments being either a vector of individual names representing a group of samples to compute a statistic on, or a (named) list of such vectors (each element of that list for a group of samples) ‚Äì these lists are intended to be equivalent to the sample_sets = argument of many tskit Python methods (which you‚Äôve learned about in your activity on tskit), except that they allow symbolic names of individuals, rather then integer indices of nodes in a tree sequence.\nAlthough you can get all the above information by processing the table produced by the ts_samples() function, slendr provides a useful helper function ts_names() which only returns the names of individuals as a vector (or a named list of such vectors, one vector per population as shown below).\nWhen you call it directly, you get a plain vector of individual names:\nts_names(ts)\n\n [1] \"NEA_1\"   \"EUR_1\"   \"NEA_2\"   \"EUR_2\"   \"EUR_3\"   \"EUR_4\"   \"EUR_5\"  \n [8] \"EUR_6\"   \"EUR_7\"   \"EUR_8\"   \"EUR_9\"   \"EUR_10\"  \"EUR_11\"  \"EUR_12\" \n[15] \"EUR_13\"  \"EUR_14\"  \"EUR_15\"  \"EUR_16\"  \"EUR_17\"  \"EUR_18\"  \"EUR_19\" \n[22] \"EUR_20\"  \"AFR_1\"   \"AFR_2\"   \"AFR_3\"   \"AFR_4\"   \"AFR_5\"   \"CHIMP_1\"\n[29] \"EUR_21\"  \"EUR_22\"  \"EUR_23\"  \"EUR_24\"  \"EUR_25\"  \"EUR_26\"  \"EUR_27\" \n[36] \"EUR_28\"  \"EUR_29\"  \"EUR_30\"\nThis is not super helpful, unless we want to compute some statistic for everyone in the tree sequence, regardless of their population assignment. Perhaps a bit more useful is to call the function like this, because it will produce a result which can be immediately used as the sample_sets = argument mentioned in the Hint above:\nts_names(ts, split = \"pop\")\n\n$AFR\n[1] \"AFR_1\" \"AFR_2\" \"AFR_3\" \"AFR_4\" \"AFR_5\"\n\n$CHIMP\n[1] \"CHIMP_1\"\n\n$EUR\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\"\n\n$NEA\n[1] \"NEA_1\" \"NEA_2\"\nAs you can see, this gave us a normal R list, with each element containing a vector of individual names in a population. Note that we can use standard R list indexing to get subsets of individuals:\nnames &lt;- ts_names(ts, split = \"pop\")\n\nnames[\"NEA\"]\n\n$NEA\n[1] \"NEA_1\" \"NEA_2\"\n\nnames[c(\"EUR\", \"NEA\")]\n\n$EUR\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\"\n\n$NEA\n[1] \"NEA_1\" \"NEA_2\"\netc.\nMany of the following exercises will use these kinds of tricks to instruct various slendr / tskit functions to compute statistics on subsets of all individuals sub-sampled in this way.\nAfter you computed nucleotide diversity per-population, compute it for each individual separately using the same function ts_diversity() (which, in this setting, gives you effectively the heterozygosity for each individual). If you are familiar with plotting in R, visualize the individual-based heterozygosities across all populations.\nHint: You can do this by giving a vector of names as sample_sets = (so not an R list of vectors). You could also use the data frame produced by ts_samples(ts) to get the names, just adding the heterozygosities to that data frame as a new column.",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Tree-sequence statistics</span>"
    ]
  },
  {
    "objectID": "popgen-stats.html#part-1-computing-nucleotide-diversity",
    "href": "popgen-stats.html#part-1-computing-nucleotide-diversity",
    "title": "Tree-sequence statistics",
    "section": "",
    "text": "Click to see the solution\n\n\n\n\n\nPopulation-based nucleotide diversity:\nLet‚Äôs first get a named list of individuals in each group we want to be working with (slendr tree-sequence statistic functions generally operate with this kind of structure):\n\nsample_sets &lt;- ts_names(ts, split = \"pop\")\nsample_sets\n\n$AFR\n[1] \"AFR_1\" \"AFR_2\" \"AFR_3\" \"AFR_4\" \"AFR_5\"\n\n$CHIMP\n[1] \"CHIMP_1\"\n\n$EUR\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\"\n\n$NEA\n[1] \"NEA_1\" \"NEA_2\"\n\n\nWe can use such sample_sets object to compute nucleotide diversity (pi)\nin each population, in a bit of a similar manner to how we would do it with the standard tskit in Python:\n\npi_pop &lt;- ts_diversity(ts, sample_sets = sample_sets)\narrange(pi_pop, diversity)\n\n# A tibble: 4 √ó 2\n  set   diversity\n  &lt;chr&gt;     &lt;dbl&gt;\n1 NEA   0.0000481\n2 CHIMP 0.000189 \n3 EUR   0.000543 \n4 AFR   0.000593 \n\n\nYou can see that this simple computation fits the extreme differences in long-term \\(N_e\\) encoded by your slendr demografr model.\nPer-individual heterozygosity:\nWe can do this by passing the vector of individual names directory as the sample_sets = argument, rather than in a list of groups as we did above.\nFor convenience, we first get a table of all individuals (which of course contains also their names) and in the next step, we‚Äôll just add their heterozygosities as a new column:\n\npi_df &lt;- ts_samples(ts)\npi_df$name\n\n [1] \"NEA_1\"   \"EUR_1\"   \"NEA_2\"   \"EUR_2\"   \"EUR_3\"   \"EUR_4\"   \"EUR_5\"  \n [8] \"EUR_6\"   \"EUR_7\"   \"EUR_8\"   \"EUR_9\"   \"EUR_10\"  \"EUR_11\"  \"EUR_12\" \n[15] \"EUR_13\"  \"EUR_14\"  \"EUR_15\"  \"EUR_16\"  \"EUR_17\"  \"EUR_18\"  \"EUR_19\" \n[22] \"EUR_20\"  \"AFR_1\"   \"AFR_2\"   \"AFR_3\"   \"AFR_4\"   \"AFR_5\"   \"CHIMP_1\"\n[29] \"EUR_21\"  \"EUR_22\"  \"EUR_23\"  \"EUR_24\"  \"EUR_25\"  \"EUR_26\"  \"EUR_27\" \n[36] \"EUR_28\"  \"EUR_29\"  \"EUR_30\" \n\npi_df$diversity &lt;- ts_diversity(ts, sample_sets = pi_df$name)$diversity\npi_df\n\n# A tibble: 38 √ó 4\n   name   time pop   diversity\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 NEA_1 70000 NEA   0.0000446\n 2 EUR_1 40000 EUR   0.000594 \n 3 NEA_2 40000 NEA   0.0000416\n 4 EUR_2 38000 EUR   0.000488 \n 5 EUR_3 36000 EUR   0.000631 \n 6 EUR_4 34000 EUR   0.000544 \n 7 EUR_5 32000 EUR   0.000541 \n 8 EUR_6 30000 EUR   0.000555 \n 9 EUR_7 28000 EUR   0.000594 \n10 EUR_8 26000 EUR   0.000555 \n# ‚Ñπ 28 more rows\n\n\nLet‚Äôs plot the results using the ggplot2 package (because a picture is worth a thousand numbers!)\n\nlibrary(ggplot2)\n\nggplot(pi_df, aes(pop, diversity, color = pop, group = pop)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter() +\n  theme_bw()",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Tree-sequence statistics</span>"
    ]
  },
  {
    "objectID": "popgen-stats.html#part-2-computing-pairwise-divergence",
    "href": "popgen-stats.html#part-2-computing-pairwise-divergence",
    "title": "Tree-sequence statistics",
    "section": "Part 2: Computing pairwise divergence",
    "text": "Part 2: Computing pairwise divergence\nUse the function ts_divergence() to compute genetic divergence between all pairs of populations. Again, do you get results compatible with our demographic model in terms of expectation given the split times between populations as you programmed them for your model?\nHint: Again, you can use the same concept of sample_sets = we discussed in the previous part. In this case, the function computes pairwise divergence between each element of the list given as sample_sets = (i.e., for each vector of individual names).\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nsample_sets &lt;- ts_names(ts, split = \"pop\")\n\ndiv_df &lt;- ts_divergence(ts, sample_sets)\narrange(div_df, divergence)\n\n# A tibble: 6 √ó 3\n  x     y     divergence\n  &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 AFR   EUR     0.000651\n2 EUR   NEA     0.000931\n3 AFR   NEA     0.000978\n4 CHIMP NEA     0.00416 \n5 CHIMP EUR     0.00416 \n6 AFR   CHIMP   0.00417 \n\n\nWe can see that the pairwise nucleotide divergences between populations recapitulate the known population/species relationships we would expect from our model.",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Tree-sequence statistics</span>"
    ]
  },
  {
    "objectID": "popgen-stats.html#part-3-detecting-neanderthal-admixture-in-europeans",
    "href": "popgen-stats.html#part-3-detecting-neanderthal-admixture-in-europeans",
    "title": "Tree-sequence statistics",
    "section": "Part 3: Detecting Neanderthal admixture in Europeans",
    "text": "Part 3: Detecting Neanderthal admixture in Europeans\nLet‚Äôs now pretend its about 2008, we‚Äôve sequenced the first Neanderthal genome, and we are working on a project that will change human evolution research forever. We also have the genomes of a couple of people from Africa and Europe, which we want to use to answer the most burning question of all evolutionary anthropology: ‚ÄúDo some people living today carry Neanderthal ancestry?‚Äù\nEarlier you‚Äôve learned about \\(f\\)-statistics of various kinds. You have also heard that an \\(f_4\\) statistic (or its equivalent \\(D\\) statistic) can be used as a test of ‚Äútreeness‚Äù. Simply speaking, for some ‚Äúquartet‚Äù of individuals or population samples, they can be used as a hypothesis test of whether the history of those samples is compatible with there not having been an introgression.\nCompute the \\(f_4\\) test of Neanderthal introgression in EUR individuals using the slendr function ts_f4(). When you‚Äôre running it, you will have to provide individuals to compute the statistic using a slightly different format. Take a look at the help page available as ?ts_f4 for more information. When you‚Äôre computing the \\(f_4\\), make sure to set mode = \"branch\" argument of the ts_f4() function (we will get to why a bit later).\n\n\nNote: By default, each slendr / tskit statistic function operates on mutations, and this will switch them to use branch length (as you might know, \\(f\\)-statistics are mathematically defined using branch lengths in trees and mode = \"branch\" does exactly that).\nHint: If you haven‚Äôt learned this in your \\(f\\)-statistics lecture, you want to compute (and compare) the values of these two statistics using the slendr function ts_f4():\n\n\\(f_4\\)(&lt;some African&gt;, &lt;another African&gt;; &lt;Neanderthal&gt;, &lt;Chimp&gt;)\n\\(f_4\\)(&lt;some African&gt;, &lt;a test European&gt;; &lt;Neanderthal&gt;, &lt;Chimp&gt;),\n\nhere &lt;individual&gt; can be the name of any individual recorded in your tree sequence, such as names you saw as name column in the table returned by ts_samples(ts) (i.e.¬†\"NEA_1\" could be used as a ‚Äúrepresentative‚Äù &lt;Neanderthal&gt; in those equations, similarly for \"CHIMP_1\" as the fourth sample in the \\(f_4\\) quarted representing the outgroup).\nTo simplify things a lot, we can understand the above equations as comparing the counts of so-called BABA and ABBA allele patterns between the quarted of samples specified in the statistics:\n\\[\nf_4(AFR, X; NEA, CHIMP) = \\frac{\\#BABA - \\#ABBA}{\\#SNPs}\n\\]\nThe first \\(f_4\\) statistic above is not expected to give values ‚Äútoo different‚Äù from 0 (even in case of Neanderthal introgression into Europeans) because we don‚Äôt expect two African individuals to differ ‚Äúsignificantly‚Äù in terms of how much alleles they share with a Neanderthal (because their ancestors never met Neanderthals!). The other should ‚Äì if there was a Neanderthal introgression into Europeans some time in their history ‚Äì be ‚Äúsignificantly negative‚Äù.\nIs the second of those two statistics ‚Äúmuch more negative‚Äù than the first, as expected assuming introgression from Neanderthals into Europeans?\nWhy am I putting ‚Äúsignificantly‚Äù and ‚Äúmuch more negative‚Äù in quotes in the previous sentence? What are we missing here for this being a true hypothesis test as you might be accustomed to from computing \\(f\\)-statistics using a tool such as ADMIXTOOLS? (We will get to this again in the following part of this exercise.)\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nCompute the difference in the amount of allele sharing between two African individuals and a Neanderthal:\n\nf4_null &lt;- ts_f4(ts, W = \"AFR_1\", X = \"AFR_2\", Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\nf4_null\n\n# A tibble: 1 √ó 5\n  W     X     Y     Z          f4\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 AFR_1 AFR_2 NEA_1 CHIMP_1 -157.\n\n\nCompute the difference in the amount of allele sharing between an African individual vs European individual and a Neanderthal:\n\nf4_alt &lt;- ts_f4(ts, W = \"AFR_1\", X = \"EUR_1\", Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\nf4_alt\n\n# A tibble: 1 √ó 5\n  W     X     Y     Z           f4\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n1 AFR_1 EUR_1 NEA_1 CHIMP_1 -3351.\n\n\nWe can see that the second test resulted in an f4 value about ~20 times more negative than the first test, indicating that a European in our test carries ‚Äúsignificantly more‚Äù Neanderthal alleles compared to the baseline expectation of no introgression established by the comparison to an African ‚Ä¶\n\nabs(f4_alt$f4 / f4_null$f4)\n\n[1] 21.36632\n\n\n‚Ä¶ although this is not a real test of significance (we have no Z-score or standard error which would give us something like a p-value for the hypothesis test, as we get by jackknife procedure in ADMIXTOOLS)",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Tree-sequence statistics</span>"
    ]
  },
  {
    "objectID": "popgen-stats.html#part-4-detecting-neanderthal-admixture-in-europeans-v2.0",
    "href": "popgen-stats.html#part-4-detecting-neanderthal-admixture-in-europeans-v2.0",
    "title": "Tree-sequence statistics",
    "section": "Part 4: Detecting Neanderthal admixture in Europeans v2.0",
    "text": "Part 4: Detecting Neanderthal admixture in Europeans v2.0\nThe fact that we don‚Äôt get something equivalent to a p-value in these kinds of simulations is generally not a problem, because we‚Äôre often interested in establishing a trend of a statistic under various conditions, and understanding when and how its expected value behaves in a certain way. If statistical noise is a problem, we work around this by computing a statistic on multiple simulation replicates or even increasing the sample sizes.\n\n\nNote: To see this in practice, you can check out a paper in which I used this approach quite successfully on a related problem.\nOn top of that, p-value of something like an \\(f\\)-statistic (whether it‚Äôs significantly different from zero) is also strongly affected by quality of the data, sequencing errors, coverage, etc. (which can certainly be examined using simulations!). However, these are aspects of modeling which are quite orthogonal to the problem of investigating the expectations and trends of statistics given some underlying evolutionary model, which is what we‚Äôre after in these exercises.\nThat said, even in perfect simulated data, what exactly does ‚Äúsignificantly different from zero compared to some baseline expectation‚Äù mean can be blurred by noise with simple single-individual comparisons that we did above. Let‚Äôs increase the sample size a bit to see if a statistical pattern expected in \\(f_4\\) statistic from our Neanderthal introgression model becomes more apparent.\nCompute the first \\(f_4\\) statistic (the baseline expectation between a pair of Africans) and the second \\(f_4\\) statistic (comparing an African and a European), but this time on all recorded Africans and all recorded Europeans, respectively. Plot the distributions of those two sets of statistics. This should remove lots of the uncertainty and make a statistical trend stand out much more clearly.\nHint: Whenever you need to compute something for many things in sequence, looping is very useful. One way to do compute, say, an \\(f_4\\) statistic over many individuals is by using this kind of pattern using R‚Äôs looping function lapply():\n\n# Loop over vector of individual names (variable x) and apply a given ts_f4()\n# expression on each individual (note the ts_f4(..., X = x, ...) in the code)\nlist_f4 &lt;- lapply(\n  c(\"ind_1\", \"ind_2\", ...),\n  function(x) ts_f4(ts, W = \"AFR_1\", X = x, Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\n)\n\n# The above gives us a list of data frames, so we need to bind them all into a\n# single table for easier interpretation and visualization\ndf_f4 &lt;- do.call(rbind, list_f4)\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nThis gives us list of vectors of the names of all individuals in each population‚Ä¶\n\nsample_sets &lt;- ts_names(ts, split = \"pop\")\n# ... which we can then access like this\nsample_sets$AFR # all Africans\n\n[1] \"AFR_1\" \"AFR_2\" \"AFR_3\" \"AFR_4\" \"AFR_5\"\n\nsample_sets$EUR # all Europeans\n\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\"\n\n\nLet‚Äôs compute the f4 statistic for all Africans‚Ä¶\n\nf4_afr_list &lt;- lapply(\n  sample_sets$AFR,\n  function(x) ts_f4(ts, W = \"AFR_1\", X = x, Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\n)\n# ... and Europeans\nf4_eur_list &lt;- lapply(\n  sample_sets$EUR,\n  function(x) ts_f4(ts, W = \"AFR_1\", X = x, Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\n)\n\nBind each list of data frames into a single data frame:\n\nf4_afr &lt;- do.call(rbind, f4_afr_list)\nf4_eur &lt;- do.call(rbind, f4_eur_list)\n\n# add population columns to each of the two results for easier plotting\nf4_afr$pop &lt;- \"AFR\"\nf4_eur$pop &lt;- \"EUR\"\n\n# bind both tables together\nf4_results &lt;- rbind(f4_afr, f4_eur)\n\nNow we can visualize the results:\n\nf4_results %&gt;%\n  ggplot(aes(pop, f4, color = pop)) +\n  geom_boxplot() +\n  geom_jitter() +\n  geom_hline(yintercept = 0, linetype = 2) +\n  ggtitle(\"f4(AFR, EUR; NEA, CHIMP)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can see that the \\(f_4\\) statistic test of Neanderthal introgression in Europeans indeed does give a much more negative distribution of values compared to the baseline expectation which compares two Africans to each other.",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Tree-sequence statistics</span>"
    ]
  },
  {
    "objectID": "popgen-stats.html#bonus-exercises",
    "href": "popgen-stats.html#bonus-exercises",
    "title": "Tree-sequence statistics",
    "section": "Bonus exercises",
    "text": "Bonus exercises\n\n\n\n\n\n\nBonus exercises\n\n\n\n\n\n\nBonus 1: mode = \"branch\" vs mode = \"site\"\nRepeat the previous part of the exercise by setting mode = \"site\" in the ts_f4() function calls (this is actually the default behavior of all slendr tree-sequence based tskit functions). This will switch the tskit computation to using mutation counts along each branch of the tree sequence, rather than using branch length themselves. Why might the branch-based computation be a bit better if what we‚Äôre after is investigating the expected values of statistics under some model?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nSee this tutorial (and particularly the directly linked section) for explanation.\n\n\n\n\n\nBonus 2: Outgroup \\(f_3\\) statistic\nUse the function ts_f3() to compute the outgroup \\(f_3\\) statistic between pairs of African-European, African-Neanderthal, and European-Neanderthal and a Chimpanzee outgroup.\nHint: The \\(f_3\\) statistic is traditionally expressed as \\(f_3(A, B; C)\\), where C represents the outgroup. Unfortunately, in tskit the outgroup is named A, with B and C being the pair of samples from which we trace the length of branches towards the outgroup, so the statistic is interpreted as \\(f_3(B, C; A)\\).\nHow do the outgroup f3 results compare to your expectation based on simple population relationships (and to the divergence computation above)?\nDo you see any impact of introgression on the \\(f_3\\) value when a Neanderthal is included in the computation?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# Standard formalism is this:\n#    f3(A, B; C) = E[ (A - C) * (B - C) ]\n# But in tskit, A is the outgroup (different from ADMIXTOOLS!), see below...\n\n# We can compute f3 for individuals...\nts_f3(ts, B = \"AFR_1\", C = \"EUR_1\", A = \"CHIMP_1\")\n\n# A tibble: 1 √ó 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 AFR_1 EUR_1 0.00375\n\n# ... but also whole populations (or population samples)\nts_f3(ts, B = sample_sets[\"AFR\"], C = sample_sets[\"EUR\"], A = \"CHIMP_1\")\n\n# A tibble: 1 √ó 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 AFR   EUR   0.00375\n\nts_f3(ts, B = sample_sets[\"AFR\"], C = sample_sets[\"NEA\"], A = \"CHIMP_1\")\n\n# A tibble: 1 √ó 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 AFR   NEA   0.00358\n\nts_f3(ts, B = sample_sets[\"EUR\"], C = sample_sets[\"NEA\"], A = \"CHIMP_1\")\n\n# A tibble: 1 √ó 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 EUR   NEA   0.00360\n\n\n\n\n\n\n\nBonus 3: Outgroup \\(f_3\\) statistic as a linear combination of \\(f_2\\) statistics\nYou might have learned that any complex \\(f\\)-statistic can be expressed as a linear combination of multiple \\(f_2\\) statistics (which represent simple branch length separating two lineages). Verify that this is the case by looking up equation (20b) in this amazing paper and compute an \\(f_3\\) statistic for any arbitrary trio of individuals of your choosing using this linear combination of \\(f_2\\) statistics.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# standard f3\nts_f3(ts, B = \"AFR_1\", C = \"AFR_2\", A = \"CHIMP_1\")\n\n# A tibble: 1 √ó 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 AFR_1 AFR_2 0.00378\n\n# a \"homemade\" f3 statistic as a linear combination of f2 statistics\n# f3(A, B; C) = f2(A, C) + f2(B, C) - f2(A, B) / 2\nhomemade_f3 &lt;- (\n  ts_f2(ts, A = \"AFR_1\", B = \"CHIMP_1\")$f2 +\n  ts_f2(ts, A = \"AFR_2\", B = \"CHIMP_1\")$f2 -\n  ts_f2(ts, A = \"AFR_1\", B = \"AFR_2\")$f2\n) / 2\n\nhomemade_f3\n\n[1] 0.003779369\n\n\n\n\n\n\n\nBonus 4: Trajectory of Neanderthal ancestry in Europe over time\nThere used to be a lot of controversy about the question of whether or not did Neanderthal ancestry proportion in Europeans decline or not over the past 40 thousand years (see figure 1 in this paper figure 2 in this paper).\nYour simulated tree sequence contains a time-series of European individuals over time. Use the slendr function ts_f4ratio() to compute (and then plot) the proportion (commonly designated as alpha) of Neanderthal ancestry in Europe over time. Use \\(f_4\\)-ratio statistic of the following form:\n\nts_f4ratio(ts, X = &lt;vector of ind. names&gt;, A = \"NEA_1\", B = \"NEA_2\", C = \"AFR_1\", O = \"CHIMP_1\")\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# Extract table with names and times of sampled Europeans (ancient and present day)\neur_inds &lt;- ts_samples(ts) %&gt;% filter(pop == \"EUR\")\neur_inds\n\n# A tibble: 30 √ó 3\n   name    time pop  \n   &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;\n 1 EUR_1  40000 EUR  \n 2 EUR_2  38000 EUR  \n 3 EUR_3  36000 EUR  \n 4 EUR_4  34000 EUR  \n 5 EUR_5  32000 EUR  \n 6 EUR_6  30000 EUR  \n 7 EUR_7  28000 EUR  \n 8 EUR_8  26000 EUR  \n 9 EUR_9  24000 EUR  \n10 EUR_10 22000 EUR  \n# ‚Ñπ 20 more rows\n\n# Compute f4-ration statistic (this will take ~30s) -- note that we can provide\n# a vector of names for the X sample set to the `ts_f4ratio()` function\nnea_ancestry &lt;- ts_f4ratio(ts, X = eur_inds$name, A = \"NEA_1\", B = \"NEA_2\", C = \"AFR_1\", O = \"CHIMP_1\")\n\n# Add the age of each sample to the table of proportions\nnea_ancestry$time &lt;- eur_inds$time\nnea_ancestry\n\n# A tibble: 30 √ó 7\n   X      A     B     C     O        alpha  time\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 EUR_1  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0741 40000\n 2 EUR_2  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0202 38000\n 3 EUR_3  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0731 36000\n 4 EUR_4  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0354 34000\n 5 EUR_5  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0132 32000\n 6 EUR_6  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0401 30000\n 7 EUR_7  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0295 28000\n 8 EUR_8  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0476 26000\n 9 EUR_9  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0261 24000\n10 EUR_10 NEA_1 NEA_2 AFR_1 CHIMP_1 0.0350 22000\n# ‚Ñπ 20 more rows\n\nnea_ancestry %&gt;%\n  ggplot(aes(time, alpha)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", linetype = 2, color = \"red\", linewidth = 0.5) +\n  xlim(40000, 0) +\n  coord_cartesian(ylim = c(0, 0.1)) +\n  labs(x = \"time [years ago]\", y = \"Neanderthal ancestry proportion\") +\n  theme_bw() +\n  ggtitle(\"Neanderthal ancestry proportion in Europeans over time\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# For good measure, let's test the significance of the decline using a linear model\nsummary(lm(alpha ~ time, data = nea_ancestry))\n\n\nCall:\nlm(formula = alpha ~ time, data = nea_ancestry)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.027358 -0.011309 -0.002650  0.007912  0.034803 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.569e-02  4.153e-03  11.001 1.13e-11 ***\ntime        -1.588e-07  2.123e-07  -0.748    0.461    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.01589 on 28 degrees of freedom\nMultiple R-squared:  0.0196,    Adjusted R-squared:  -0.01541 \nF-statistic: 0.5598 on 1 and 28 DF,  p-value: 0.4606\n\n\n\n\n\n\n\nBonus 5: How many unique f4 quartets are there?\nIn your lecture about \\(f\\)-statistics, you‚Äôve probably learned about various symmetries in \\(f_4\\) (but also other \\(f\\)-statistics) depending on the arrangement of the ‚Äúquartet‚Äù. As a trivial example, an \\(f_3(A; B, C)\\) and \\(f_3(A; C, B)\\) will give you exactly the same value, and the same thing applies even to more complex \\(f\\)-statistics like \\(f_4\\).\nUse simulations to compute how manu unique \\(f_4\\) values involving a single quartet are there.\nHint: Draw some trees to figure out why could that be true. Also, when computing ts_f4(), set mode = \"branch\" to avoid the effect of statistical noise due to mutations.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# # install a combinatorics R package\n# install.packages(\"combinat\")\n\nlibrary(combinat)\n\n\nAttaching package: 'combinat'\n\n\nThe following object is masked from 'package:utils':\n\n    combn\n\n# These are the four samples we can create quartet combinations from\nquartet &lt;- c(\"AFR_1\", \"EUR_1\", \"NEA_1\", \"CHIMP_1\")\nquartets &lt;- permn(quartet)\nquartets\n\n[[1]]\n[1] \"AFR_1\"   \"EUR_1\"   \"NEA_1\"   \"CHIMP_1\"\n\n[[2]]\n[1] \"AFR_1\"   \"EUR_1\"   \"CHIMP_1\" \"NEA_1\"  \n\n[[3]]\n[1] \"AFR_1\"   \"CHIMP_1\" \"EUR_1\"   \"NEA_1\"  \n\n[[4]]\n[1] \"CHIMP_1\" \"AFR_1\"   \"EUR_1\"   \"NEA_1\"  \n\n[[5]]\n[1] \"CHIMP_1\" \"AFR_1\"   \"NEA_1\"   \"EUR_1\"  \n\n[[6]]\n[1] \"AFR_1\"   \"CHIMP_1\" \"NEA_1\"   \"EUR_1\"  \n\n[[7]]\n[1] \"AFR_1\"   \"NEA_1\"   \"CHIMP_1\" \"EUR_1\"  \n\n[[8]]\n[1] \"AFR_1\"   \"NEA_1\"   \"EUR_1\"   \"CHIMP_1\"\n\n[[9]]\n[1] \"NEA_1\"   \"AFR_1\"   \"EUR_1\"   \"CHIMP_1\"\n\n[[10]]\n[1] \"NEA_1\"   \"AFR_1\"   \"CHIMP_1\" \"EUR_1\"  \n\n[[11]]\n[1] \"NEA_1\"   \"CHIMP_1\" \"AFR_1\"   \"EUR_1\"  \n\n[[12]]\n[1] \"CHIMP_1\" \"NEA_1\"   \"AFR_1\"   \"EUR_1\"  \n\n[[13]]\n[1] \"CHIMP_1\" \"NEA_1\"   \"EUR_1\"   \"AFR_1\"  \n\n[[14]]\n[1] \"NEA_1\"   \"CHIMP_1\" \"EUR_1\"   \"AFR_1\"  \n\n[[15]]\n[1] \"NEA_1\"   \"EUR_1\"   \"CHIMP_1\" \"AFR_1\"  \n\n[[16]]\n[1] \"NEA_1\"   \"EUR_1\"   \"AFR_1\"   \"CHIMP_1\"\n\n[[17]]\n[1] \"EUR_1\"   \"NEA_1\"   \"AFR_1\"   \"CHIMP_1\"\n\n[[18]]\n[1] \"EUR_1\"   \"NEA_1\"   \"CHIMP_1\" \"AFR_1\"  \n\n[[19]]\n[1] \"EUR_1\"   \"CHIMP_1\" \"NEA_1\"   \"AFR_1\"  \n\n[[20]]\n[1] \"CHIMP_1\" \"EUR_1\"   \"NEA_1\"   \"AFR_1\"  \n\n[[21]]\n[1] \"CHIMP_1\" \"EUR_1\"   \"AFR_1\"   \"NEA_1\"  \n\n[[22]]\n[1] \"EUR_1\"   \"CHIMP_1\" \"AFR_1\"   \"NEA_1\"  \n\n[[23]]\n[1] \"EUR_1\"   \"AFR_1\"   \"CHIMP_1\" \"NEA_1\"  \n\n[[24]]\n[1] \"EUR_1\"   \"AFR_1\"   \"NEA_1\"   \"CHIMP_1\"\n\n# How many permutations there are in total?\n#   4! = 4 * 3 * 2 * 1 = 24\nfactorial(4)\n\n[1] 24\n\n# We should therefore have 24 different quartet combinations of samples\nlength(quartets)\n\n[1] 24\n\n# Loop across all quartets, computing the corresponding f4 statistic (we want\n# to do this using branch lengths, not mutations, as the mutation-based computation\n# would involve statistical noise)\nall_f4s &lt;- lapply(quartets, function(q) ts_f4(ts, q[1], q[2], q[3], q[4], mode = \"branch\"))\n\n# Bind the list of f4 results into a single data frame and inspect the results\nall_f4s &lt;- bind_rows(all_f4s) %&gt;% arrange(abs(f4))\nprint(all_f4s, n = Inf)\n\n# A tibble: 24 √ó 5\n   W       X       Y       Z            f4\n   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n 1 AFR_1   EUR_1   NEA_1   CHIMP_1  -3351.\n 2 AFR_1   EUR_1   CHIMP_1 NEA_1     3351.\n 3 NEA_1   CHIMP_1 AFR_1   EUR_1    -3351.\n 4 CHIMP_1 NEA_1   AFR_1   EUR_1     3351.\n 5 CHIMP_1 NEA_1   EUR_1   AFR_1    -3351.\n 6 NEA_1   CHIMP_1 EUR_1   AFR_1     3351.\n 7 EUR_1   AFR_1   CHIMP_1 NEA_1    -3351.\n 8 EUR_1   AFR_1   NEA_1   CHIMP_1   3351.\n 9 AFR_1   NEA_1   CHIMP_1 EUR_1   -13496.\n10 AFR_1   NEA_1   EUR_1   CHIMP_1  13496.\n11 NEA_1   AFR_1   EUR_1   CHIMP_1 -13496.\n12 NEA_1   AFR_1   CHIMP_1 EUR_1    13496.\n13 EUR_1   CHIMP_1 NEA_1   AFR_1   -13496.\n14 CHIMP_1 EUR_1   NEA_1   AFR_1    13496.\n15 CHIMP_1 EUR_1   AFR_1   NEA_1   -13496.\n16 EUR_1   CHIMP_1 AFR_1   NEA_1    13496.\n17 AFR_1   CHIMP_1 EUR_1   NEA_1    16847.\n18 CHIMP_1 AFR_1   EUR_1   NEA_1   -16847.\n19 CHIMP_1 AFR_1   NEA_1   EUR_1    16847.\n20 AFR_1   CHIMP_1 NEA_1   EUR_1   -16847.\n21 NEA_1   EUR_1   CHIMP_1 AFR_1    16847.\n22 NEA_1   EUR_1   AFR_1   CHIMP_1 -16847.\n23 EUR_1   NEA_1   AFR_1   CHIMP_1  16847.\n24 EUR_1   NEA_1   CHIMP_1 AFR_1   -16847.\n\n# Narrow down the results to only unique f4 values\ndistinct(all_f4s, f4, .keep_all = TRUE)\n\n# A tibble: 6 √ó 5\n  W       X       Y       Z            f4\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 AFR_1   EUR_1   NEA_1   CHIMP_1  -3351.\n2 AFR_1   EUR_1   CHIMP_1 NEA_1     3351.\n3 AFR_1   NEA_1   CHIMP_1 EUR_1   -13496.\n4 AFR_1   NEA_1   EUR_1   CHIMP_1  13496.\n5 AFR_1   CHIMP_1 EUR_1   NEA_1    16847.\n6 CHIMP_1 AFR_1   EUR_1   NEA_1   -16847.\n\ndistinct(all_f4s, abs(f4), .keep_all = TRUE)\n\n# A tibble: 3 √ó 6\n  W     X       Y       Z            f4 `abs(f4)`\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 AFR_1 EUR_1   NEA_1   CHIMP_1  -3351.     3351.\n2 AFR_1 NEA_1   CHIMP_1 EUR_1   -13496.    13496.\n3 AFR_1 CHIMP_1 EUR_1   NEA_1    16847.    16847.",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Tree-sequence statistics</span>"
    ]
  },
  {
    "objectID": "popgen-nonspatial-pca.html",
    "href": "popgen-nonspatial-pca.html",
    "title": "Exploring PCA patterns",
    "section": "",
    "text": "Part 1: Create a model\nNote: We‚Äôre unlikely to make it to this part, so this is extra bonus which can be ignored!\nIn earlier lectures you‚Äôve learned about the Principal Component Analysis, a dimensional-reduction technique that‚Äôs a central piece of many (if not most) papers studying population history of many (hundreds) of individuals genotyped across many (millions) SNPs.\nAlthough incredibly popular, PCA has recently been a topic of controversy, with a highly combative paper criticizing the application of PCA in all of population genetics, almost to a point of claiming that none of the results can be published. As an example, take a look at Figure 5 in the paper, demonstrating that an Indian population can be arbitrarily placed in proximity to Europeans, East Asians, and Africans, simply by wiggling the sample sizes of all groups before they applying PCA on their genotype data.\nThis activity session is not a place to debate the merit of PCA (or any other popgen method for that matter). What we can do (as we‚Äôve done in previous exercises) is to show how slendr can be used in a very easy way to evaluate patterns, expected behavior, and overall dynamics of many popgen metrics in a controlled settings ‚Äì and in this way, verify our intuition and check the robustness of a method in question ‚Äì using PCA as another example. We‚Äôll be specifically looking at patterns which arise in PCA depending on the exact spatio-temporal sampling from a demographic model.\nStart a new script named exercise5.R with the following setup of another toy demographic model:\nlibrary(slendr)\ninit_env(quiet = TRUE)\n\nsource(here::here(\"files/popgen/popgen_utils.R\"))\n\npopA &lt;- population(\"popA\", time = 3000, N = 5000)\npopB &lt;- population(\"popB\", time = 1500, N = 5000, parent = popA)\npopC &lt;- population(\"popC\", time = 1500, N = 5000, parent = popA)\n\nmodel &lt;- compile_model(list(popA, popB, popC), generation_time = 1)\n\nschedule &lt;- schedule_sampling(model, times = seq(3000, 0, by = -200),\n                              list(popA, 10), list(popB, 10), list(popC, 10))\n\nplot_model(model, proportions = TRUE, samples = schedule)\nAs you can see, this model describes the demographic history of three populations: one ancestral population ‚ÄúpopA‚Äù starting at 3000 generations ago, which splits into two populations ‚ÄúpopB‚Äù and ‚ÄúpopC‚Äù the same time at 1500 generations ago. We den instruct slendr to record 10 individuals from each of the three populations starting from 3000 generations ago all the way to 0 generations ago (i.e. the ‚Äúpresent‚Äù), every 200 generations (remeber the seq() R function!).",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Exploring PCA patterns</span>"
    ]
  },
  {
    "objectID": "popgen-nonspatial-pca.html#part-2-simulate-a-mutated-tree-sequence",
    "href": "popgen-nonspatial-pca.html#part-2-simulate-a-mutated-tree-sequence",
    "title": "Exploring PCA patterns",
    "section": "Part 2: Simulate a (mutated!) tree sequence",
    "text": "Part 2: Simulate a (mutated!) tree sequence\nTo be able to run PCA using the smartsnp R package (below), we will need to simulate data in the EIGENSTRAT file format. And to do that, we need our tree sequence with mutations.\nRecall that all of our previous exercises managed to do away with mutations completely, owing to the amazing nature of the succint tree sequence data structure invented by the people behind the tskit project. However, all traditional popgen software and tools still rely on genotype data, which is why we now have to simulate mutations as well. Luckily, this is very easy ‚Äì instead of the traditional\n\nts &lt;- msprime(model, sequence_length = ..., recombination_rate = ..., samples = ...)\n\nwe will run this:\n\n# First run a normal msprime simulation creating a tree-sequence object, then\n# directly pipe it into a function which adds (neutral!) mutations to it\nts &lt;- msprime(model, sequence_length = ..., recombination_rate = ..., samples = ...) %&gt;%\n  ts_mutate(mutation_rate = ...)\n\nwhich is equivalent to running this without the %&gt;% ‚Äúpipe operator‚Äù:\n\n# First run a normal msprime simulation creating a tree-sequence object...\nts_nomuts &lt;- msprime(model, sequence_length = ..., recombination_rate = ..., samples = ...)\n# ... then add (neutral!) mutations to it\nts &lt;- ts_mutate(ts_nomuts, mutation_rate = ...)\n\nWith that out of the way, simulate a tree sequence from the popA/popB/popC model above, which will be 50 Mb (50e6) long, with a recombination rate 1e-8, and overlay mutations on it at a rate 1e-8. Check that it has mutations either by typing out ts in the console and looking for a ‚ÄúMutations‚Äù section of the summary, or by using the function ts_table(ts, \"mutations\"). Then count how many individuals you have recorded for each population using the table produced by ts_samples().\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# First run a normal msprime simulation creating a tree-sequence object, then\n# directly pipe it into a function which adds (neutral!) mutations to it\nts_nomuts &lt;- msprime(model, samples = schedule, sequence_length = 50e6, recombination_rate = 1e-8, random_seed = 1702182272)\n\n# Notice we have no mutations on the tree sequence, just as before...\nts_nomuts\n\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïëTreeSequence               ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïëTrees          ‚îÇ    160,114‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSequence Length‚îÇ 50,000,000‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëTime Units     ‚îÇgenerations‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSample Nodes   ‚îÇ        620‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëTotal Size     ‚îÇ   26.1 MiB‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïëTable      ‚îÇRows   ‚îÇSize     ‚îÇHas Metadata‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïëEdges      ‚îÇ619,886‚îÇ 18.9 MiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëIndividuals‚îÇ    310‚îÇ  8.5 KiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëMigrations ‚îÇ      0‚îÇ  8 Bytes‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëMutations  ‚îÇ      0‚îÇ 16 Bytes‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëNodes      ‚îÇ 92,209‚îÇ  2.5 MiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëPopulations‚îÇ      3‚îÇ303 Bytes‚îÇ         Yes‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëProvenances‚îÇ      1‚îÇ  5.2 KiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSites      ‚îÇ      0‚îÇ 16 Bytes‚îÇ          No‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\nts &lt;- ts_mutate(ts_nomuts, mutation_rate = 1e-8)\n\n# ... but we have them now!\nts\n\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïëTreeSequence               ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïëTrees          ‚îÇ    160,114‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSequence Length‚îÇ 50,000,000‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëTime Units     ‚îÇgenerations‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSample Nodes   ‚îÇ        620‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëTotal Size     ‚îÇ   36.1 MiB‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïëTable      ‚îÇRows   ‚îÇSize     ‚îÇHas Metadata‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïëEdges      ‚îÇ619,886‚îÇ 18.9 MiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëIndividuals‚îÇ    310‚îÇ  8.5 KiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëMigrations ‚îÇ      0‚îÇ  8 Bytes‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëMutations  ‚îÇ168,485‚îÇ  5.9 MiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëNodes      ‚îÇ 92,209‚îÇ  2.5 MiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëPopulations‚îÇ      3‚îÇ303 Bytes‚îÇ         Yes‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëProvenances‚îÇ      2‚îÇ  6.0 KiB‚îÇ          No‚ïë\n‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n‚ïëSites      ‚îÇ168,214‚îÇ  4.0 MiB‚îÇ          No‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\n# Get the table of individuals (and process it a bit for tidier plotting later)\nsamples &lt;- ts_samples(ts) %&gt;% mutate(pop = factor(pop, levels = c(\"popA\", \"popB\", \"popC\")))\n\n# Count how many individuals do we have for each population\nsamples %&gt;% group_by(pop) %&gt;% count()\n\n# A tibble: 3 √ó 2\n# Groups:   pop [3]\n  pop       n\n  &lt;fct&gt; &lt;int&gt;\n1 popA    150\n2 popB     80\n3 popC     80",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Exploring PCA patterns</span>"
    ]
  },
  {
    "objectID": "popgen-nonspatial-pca.html#part-3-converting-a-tree-sequence-into-eigenstrat",
    "href": "popgen-nonspatial-pca.html#part-3-converting-a-tree-sequence-into-eigenstrat",
    "title": "Exploring PCA patterns",
    "section": "Part 3: Converting a tree sequence into EIGENSTRAT",
    "text": "Part 3: Converting a tree sequence into EIGENSTRAT\nThe function to use for converting a tree-sequence object we have in R (in our exercises the thing we usually had in the ts variable) to disk in form of genotypes in the EIGENSTRAT format is called ts_eigenstrat(). The standard way to call it (but see ?ts_eigenstrat for more options) is like this:\n\nts_eigenstrat(ts, prefix = \"path/to/a/desired/EIGENSTRAT/prefix\")\n\nWhich creates three files .ind, .snp, and .geno as: - path/to/a/desired/EIGENSTRAT/prefix.ind, - path/to/a/desired/EIGENSTRAT/prefix.snp, and - path/to/a/desired/EIGENSTRAT/prefix.geno,\njust as you would expect for any EIGENSTRAT file.\nTake your tree sequence ts just just simulated, and convert it to EIGENSTRAT format under the prefix files/popgen/ABC_all.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nts_eigenstrat(ts, \"files/popgen/ABC_all\")\n\n187 multiallelic sites (0.111% out of 168214 total) detected and removed\n\n\nEIGENSTRAT object\n=================\ncomponents:\n  ind file: files/popgen/ABC_all.ind\n  snp file: files/popgen/ABC_all.snp\n  geno file: files/popgen/ABC_all.geno\n\n\n\n\n\nCheck that the EIGENSTRAT files really appeared at the path that you specified (in the terminal).",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Exploring PCA patterns</span>"
    ]
  },
  {
    "objectID": "popgen-nonspatial-pca.html#part-4-inspect-the-eigenstrat-data-produced-by-slendr",
    "href": "popgen-nonspatial-pca.html#part-4-inspect-the-eigenstrat-data-produced-by-slendr",
    "title": "Exploring PCA patterns",
    "section": "Part 4: Inspect the EIGENSTRAT data produced by slendr",
    "text": "Part 4: Inspect the EIGENSTRAT data produced by slendr\nYears ago I developed a small R package to help me with \\(f\\)-statistics based projects using the ADMIXTOOLS software (which operates on data in the EIGENSTRAT file format), called admixr\nUse the following code to examine one of the EIGENSTRAT data sets you‚Äôve just created. Just look at the results and see if they make sense in terms of what you‚Äôve learned about this in earlier lectures.\n\nlibrary(admixr)\n\neigen &lt;- eigenstrat(\"&lt;prefix of a trio of EIGENSTRAT .ind/.snp/.geno files\")\n\n# Print out a summary of the EIGENSTRAT data\neigen\n\n# Read the .ind file as a table into R\nread_ind(eigen)\n# Read the .snp file as a table into R\nread_snp(eigen)\n# Read the .geno file as a table into R\nread_geno(eigen)\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nlibrary(admixr)\n\neigen &lt;- eigenstrat(\"files/popgen/ABC_all\")\n\n# Print out a summary of the EIGENSTRAT data\neigen\n\n# Read the .ind file as a table into R\nread_ind(eigen)\n# Read the .snp file as a table into R\nread_snp(eigen)\n# Read the .geno file as a table into R\nread_geno(eigen)",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Exploring PCA patterns</span>"
    ]
  },
  {
    "objectID": "popgen-nonspatial-pca.html#part-5-principal-component-analysis-on-the-entire-simulated-data-set",
    "href": "popgen-nonspatial-pca.html#part-5-principal-component-analysis-on-the-entire-simulated-data-set",
    "title": "Exploring PCA patterns",
    "section": "Part 5: Principal Component Analysis on the entire simulated data set",
    "text": "Part 5: Principal Component Analysis on the entire simulated data set\nNow, at long last, we have everything we need to be able to run ABC on the data generated by our slendr model. To avoid making this exercise even longer, I provided a helper function for you called plot_pca(). But this function isn‚Äôt doing anything magical ‚Äì it uses the smartsnp R package to compute the principal components and visualize the results using ggplot2. This is something many of you could do given enough time but we want to focus on simulations and PCA, not pure R coding. If you‚Äôre interested, take a look at my implementation of plot_pca() here.\nHere‚Äôs how you can use this function (remeber that you need to put source(here::here(\"files/popgen/popgen_utils.R\")) into your script!):\n\nPlot PCA while coloring each individual by their population assignment:\n\n\nplot_pca(\"path/to/prefix\", &lt;tree sequence used to create EIGENSTRAT&gt;, color_by = \"pop\")\n\n\nPlot PCA while coloring each individual by their time of sampling:\n\n\nplot_pca(\"path/to/prefix\", &lt;tree sequence used to create EIGENSTRAT&gt;, color_by = \"time\")\n\n\nBy default, the function plots PC 1 vs PC 2, but you can customize things by providing an optional argument pc = like this:\n\n\nplot_pca(\"path/to/prefix\", &lt;tree sequence used to create EIGENSTRAT&gt;, color_by = \"pop\", pc = c(2, 3))\n\nUse the provided plot_pca() function to run PCA based on genotypes for all recorded individuals that you just converted as EIGENSTRAT \"files/popgen/ABC_all\" from the ts tree sequence. Visualize PC 1 vs PC 2 by first ccolor each individual by their population label (color_by = \"pop\") then by the time of their sampling (color_by = \"time\").\nDoes the PCA of PC 1 vs PC 2 capture the relationship between all individuals across the populations and across time?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"pop\", pc = c(1, 2))\n\nPCA cache for the given EIGENSTRAT data was not found. Generating it now (this might take a moment)...\n\n\n\n\n\n\n\n\nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"time\", pc = c(1, 2))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\n\nIt looks like the PCA from PC 1 vs 2 cannot ‚Äúpartition out‚Äù the drift along the ancestral ‚ÄúpopA‚Äù lineage prior to the population splits!\n\n\n\nUse plot_pca() to compute the PCAon this exact same data, but examine how does the shape of the PCA scatterplot change when you switch the pairs of PCs plotted (i.e., PC 2 vs PC 3, PC 3 vs PC 4, PC 4 vs PC 6, etc.). Which pair of PCs does the best job at recapitulating the demographic model?\n\n\nNote: We‚Äôre doing this purely for educational purposes and for fun, using an extremely idealistic demographic model which is perfectly known (by definition, because we simulated it) and perfect sampling scheme. The point is to explore what does doing a PCA mean in practice, visually, and to built intuition into it.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n#  We can see that the overall shape of the demographic model tree is now nicely\n# reflected in the PCA shape\nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"pop\", pc = c(2, 3))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"time\", pc = c(2, 3))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"pop\", pc = c(3, 4))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"time\", pc = c(3, 4))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\n# Things are getting progressively wilder! \nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"pop\", pc = c(4, 5))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"time\", pc = c(4, 5))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\n# ...\nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"pop\", pc = c(5, 6))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"files/popgen/ABC_all\", ts, color_by = \"time\", pc = c(5, 6))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBonus exercises\n\n\n\n\nBonus 1: Tree-sequence simplification and EIGENSTRAT conversion\nOne of our goals in this exercise was to investigate how does the shape of a PCA look like based on the sampling of individuals across populations and also across time ‚Äì all of that from the same demographic history. In order to do that, we need to be able to select only a defined subset of individuals from a given tree sequence. Which brings us to the last tree-sequence processing function in slendr callsed ts_simplify(). Implemented on top of the simplify() method in tskit, it has a very simple interface:\n\nts_small &lt;- ts_simplify(ts_big, simplify_to = c(&lt;subset of individuals as a vector&gt;))\n\nThis function call creates a new tree sequence, which is smaller and only contains a those individuals whose names were specified in simplify_to = (again, we‚Äôre talking about the ‚Äúsymbolic names‚Äù of individuals, such as ‚ÄúNEA_1‚Äù, ‚ÄúAFR_42‚Äù, etc., not integer numbers of tskit nodes).\nWhenever you want to create smaller subsets of a large tree sequence, it is often helpful to work with the table of all individuals in the original tree sequence, because it contains every individual‚Äôs name, pop assignment and the time in which it lived, so let‚Äôs save it for further use now:\n\nsamples &lt;- ts_samples(ts)\n\nnrow(samples)\n\n[1] 310\n\n\nFor instance, we can get only individuals from ‚ÄúpopB‚Äù and ‚ÄúpopC‚Äù sampled at the present using this code:\n\nsubset &lt;- filter(samples, pop %in% c(\"popB\", \"popC\"), time == 0)\n\nnrow(subset)\n\n[1] 20\n\n\nYou know that the table of samples contains the name of each individual, which you can access as subset$name. Use the ts_simplify() function to create a new tree sequence called ts_BC0 which contains only this subset of individuals. Check that it really does contain only the defined subset of individuals using ts_samples(ts_BC0).\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nts_BC0 &lt;- ts_simplify(ts, simplify_to = subset$name)\n\nts_samples(ts_BC0)\n\n# A tibble: 20 √ó 3\n   name     time pop  \n   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;\n 1 popB_71     0 popB \n 2 popB_72     0 popB \n 3 popB_73     0 popB \n 4 popB_74     0 popB \n 5 popB_75     0 popB \n 6 popB_76     0 popB \n 7 popB_77     0 popB \n 8 popB_78     0 popB \n 9 popB_79     0 popB \n10 popB_80     0 popB \n11 popC_71     0 popC \n12 popC_72     0 popC \n13 popC_73     0 popC \n14 popC_74     0 popC \n15 popC_75     0 popC \n16 popC_76     0 popC \n17 popC_77     0 popC \n18 popC_78     0 popC \n19 popC_79     0 popC \n20 popC_80     0 popC \n\n\n\n\n\nWhen you have a smaller tree sequence like this, you can convert it to an EIGENSTRAT file format using ts_eigenstrat() just like we did above.\n\n\nPart 2: PCA visualization on subsets of individuals\nTODO: Try to replicate some features of the results discovered for EUR/ASIAN/AFR/Indian populations.",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Exploring PCA patterns</span>"
    ]
  },
  {
    "objectID": "popgen-spatial-pca.html",
    "href": "popgen-spatial-pca.html",
    "title": "Spatial PCA",
    "section": "",
    "text": "WIP: Exploring how (and when) PCA patterns recapitulate geographical history of populations, inspired by this figure by Novembre et al. (2008).\n\n\n\nNovembre et al., 2008\n\n\n\nlibrary(slendr)\ninit_env()\n\nThe interface to all required Python modules has been activated.\n\nlibrary(admixr)\nlibrary(cowplot)\n\nsource(\"files/popgen/popgen_utils.R\")\n\nmodel &lt;- landscape_model(rate = 0.3, Ne = 10000)\n\n# pdf(\"exercise5.pdf\", width = 8, height = 5)\n# for (n in c(50, 25, 10, 5, 2, 1)) {\n  n &lt;- 10\n  schedule &lt;- landscape_sampling(model, n)\n\n  ts &lt;- msprime(model, samples = schedule, sequence_length = 20e6, recombination_rate = 1e-8) %&gt;% ts_mutate(1e-8)\n\n  samples &lt;- ts_samples(ts)\n\n  ts_eigenstrat(ts, \"files/popgen/spatial_pca1\")\n\n454 multiallelic sites (0.278% out of 163229 total) detected and removed\n\n\nEIGENSTRAT object\n=================\ncomponents:\n  ind file: files/popgen/spatial_pca1.ind\n  snp file: files/popgen/spatial_pca1.snp\n  geno file: files/popgen/spatial_pca1.geno\n\n  plot_pca(\"files/popgen/spatial_pca1\", ts, model = \"map\", color_by = \"pop\") \n\nPCA cache for the given EIGENSTRAT data was not found. Generating it now (this might take a moment)...\n\n\nWarning: Visualising population labels on a map requires a higher slendr\nversion\n\n\nWarning: All gene-flow event will be visualized at once. If you wish to visualize\ngene flows at a particular point in time, use the `time` argument.\n\n\nWarning: Non-spatial populations in your model won't be visualized\n\n\n\n\n\n\n\n\n# }\n# dev.off()\n\n\nPer-population Ne values\n\nlibrary(slendr)\ninit_env()\n\nThe interface to all required Python modules has been activated.\n\nlibrary(admixr)\nlibrary(cowplot)\n\nsource(\"files/popgen/popgen_utils.R\")\n\nNe &lt;- list(\n  p1 = 10000,\n  p2 = 10000,\n  p3 = 10000,\n  p4 = 10000,\n  p5 = 100,\n  p6 = 10000,\n  p7 = 10000,\n  p8 = 10000,\n  p9 = 10000,\n  p10 = 10000\n)\n\nmodel &lt;- landscape_model(rate = 0.3, Ne = Ne)\n\nn &lt;- list(\n  p1 = 50,\n  p2 = 50,\n  p3 = 50,\n  p4 = 50,\n  p5 = 5,\n  p6 = 50,\n  p7 = 50,\n  p8 = 50,\n  p9 = 50,\n  p10 = 50\n)\n\nschedule &lt;- landscape_sampling(model, n)\n\nts &lt;- msprime(model, samples = schedule, sequence_length = 20e6, recombination_rate = 1e-8) %&gt;% ts_mutate(1e-8)\n\nts_eigenstrat(ts, \"files/popgen/spatial_pca2\")\n\n1045 multiallelic sites (0.417% out of 250505 total) detected and removed\n\n\nEIGENSTRAT object\n=================\ncomponents:\n  ind file: files/popgen/spatial_pca2.ind\n  snp file: files/popgen/spatial_pca2.snp\n  geno file: files/popgen/spatial_pca2.geno\n\nread_ind(eigenstrat(\"files/popgen/spatial_pca2\"))\n\n# A tibble: 455 √ó 3\n   id    sex   label\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 p1_1  U     p1_1 \n 2 p1_2  U     p1_2 \n 3 p1_3  U     p1_3 \n 4 p1_4  U     p1_4 \n 5 p1_5  U     p1_5 \n 6 p1_6  U     p1_6 \n 7 p1_7  U     p1_7 \n 8 p1_8  U     p1_8 \n 9 p1_9  U     p1_9 \n10 p1_10 U     p1_10\n# ‚Ñπ 445 more rows\n\nts_samples(ts)\n\n# A tibble: 455 √ó 3\n   name   time pop  \n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n 1 p1_1  10000 p1   \n 2 p1_2  10000 p1   \n 3 p1_3  10000 p1   \n 4 p1_4  10000 p1   \n 5 p1_5  10000 p1   \n 6 p1_6  10000 p1   \n 7 p1_7  10000 p1   \n 8 p1_8  10000 p1   \n 9 p1_9  10000 p1   \n10 p1_10 10000 p1   \n# ‚Ñπ 445 more rows\n\nplot_pca(\"files/popgen/spatial_pca2\", ts, model = \"map\", color = \"pop\")\n\nPCA cache for the given EIGENSTRAT data was not found. Generating it now (this might take a moment)...\n\n\nWarning: Visualising population labels on a map requires a higher slendr\nversion\n\n\nWarning: All gene-flow event will be visualized at once. If you wish to visualize\ngene flows at a particular point in time, use the `time` argument.\n\n\nWarning: Non-spatial populations in your model won't be visualized",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Spatial PCA</span>"
    ]
  },
  {
    "objectID": "popgen-tracts-dating.html",
    "href": "popgen-tracts-dating.html",
    "title": "Admixture tracts and dating",
    "section": "",
    "text": "WIP: Extracting ancestry tracts, chromosome painting, and using admixture tracts and LD patterns for dating admixture events.\n\nlibrary(slendr)\ninit_env()\n\nThe interface to all required Python modules has been activated.\n\nlibrary(cowplot)\n\n# helper function for plotting tracts simulated later\nplot_tracts &lt;- function(tracts, ind) {\n  ind_tracts &lt;- filter(tracts, name %in% ind) %&gt;%\n    mutate(haplotype = paste0(name, \"\\nhap. \", haplotype))\n  ind_tracts$haplotype &lt;- factor(ind_tracts$haplotype, levels = unique(ind_tracts$haplotype[order(ind_tracts$node_id)]))\n\n  ggplot(ind_tracts) +\n    geom_rect(aes(xmin = left, xmax = right, ymin = 1, ymax = 2, fill = name), linewidth = 1) +\n    labs(x = \"coordinate along a chromosome [bp]\") +\n    theme_bw() +\n    theme(\n      legend.position = \"none\",\n      axis.text.y = element_blank(),\n      axis.ticks = element_blank(),\n      panel.border = element_blank(),\n      panel.grid = element_blank()\n    ) +\n    facet_grid(haplotype ~ .) +\n    expand_limits(x = 0) +\n    scale_x_continuous(labels = scales::comma)\n}\n\npopZ &lt;- population(\"popZ\", time = 3000, N = 5000)\npopX &lt;- population(\"popX\", time = 1500, N = 5000, parent = popZ)\npopY &lt;- population(\"popY\", time = 1500, N = 5000, parent = popZ)\n\ngf &lt;- gene_flow(from = popX, to = popY, rate = 0.2, start = 800, end = 799)\n\nmodel &lt;- compile_model(list(popZ, popX, popY), generation_time = 1, gene_flow = gf)\n\nschedule &lt;- rbind(\n  schedule_sampling(model, times = seq(1500, 0, by = -100), list(popY, 50)),\n  schedule_sampling(model, times = 0, list(popX, 10), list(popZ, 10))\n)\n\n# Use the function plot_model() to make sure that the model and the sampling schedule\n# are defined correctly (there's no such thing as too many sanity checks when doing research)\nplot_model(model, proportions = TRUE, samples = schedule)\n\n\n\n\n\n\n\nts &lt;- msprime(model, samples = schedule, sequence_length = 100e6, recombination_rate = 1e-8)\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\ntracts &lt;- ts_tracts(ts, census = 800)\n\n\nPopAncestry summary\nNumber of ancestral populations:    3\nNumber of sample chromosomes:       1540\nNumber of ancestors:            56782\nTotal length of genomes:        154000000000.000000\nAncestral coverage:             84000000000.000000\n\ntracts\n\n# A tibble: 55,781 √ó 10\n   name     haplotype  time pop   source_pop    left  right length source_pop_id\n   &lt;chr&gt;        &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt;        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;\n 1 popY_351         1   700 popY  popX        1.50e6 2.11e6 6.07e5             1\n 2 popY_351         1   700 popY  popX        4.23e6 4.23e6 2.75e3             1\n 3 popY_351         1   700 popY  popX        8.03e6 9.01e6 9.87e5             1\n 4 popY_351         1   700 popY  popX        2.34e7 2.52e7 1.79e6             1\n 5 popY_351         1   700 popY  popX        2.54e7 2.58e7 4.40e5             1\n 6 popY_351         1   700 popY  popX        2.60e7 2.73e7 1.26e6             1\n 7 popY_351         1   700 popY  popX        3.15e7 3.39e7 2.35e6             1\n 8 popY_351         1   700 popY  popX        3.50e7 3.57e7 6.63e5             1\n 9 popY_351         1   700 popY  popX        3.83e7 4.02e7 1.88e6             1\n10 popY_351         1   700 popY  popX        5.05e7 5.33e7 2.85e6             1\n# ‚Ñπ 55,771 more rows\n# ‚Ñπ 1 more variable: node_id &lt;dbl&gt;\n\nsample_times &lt;- ts_samples(ts) %&gt;% select(name, time)\n\n# adding haplotype ID and time (automatically done by the dev slendr)\ntracts &lt;- tracts %&gt;% dplyr::group_by(name) %&gt;% dplyr::mutate(haplotype = dplyr::dense_rank(node_id)) %&gt;% dplyr::ungroup() %&gt;% inner_join(sample_times) \n\nJoining with `by = join_by(name, time)`\n\n# Select sampled individuals from different ages (remember, we recorded oldest individuals\n# at 1000 generations ago, the youngest individuals at 0 generations ago). Use the function\n# plot_tracts to visualize their ancestry tracts. What do you see in terms of the number of\n# tracts and the length of tracts across these individuals? Can you eyeball some distinctive\n# pattern?\n\nsubset_inds &lt;- tracts %&gt;% group_by(time) %&gt;% distinct(name) %&gt;% slice_sample(n = 1) %&gt;% pull(name)\nsubset_inds\n\n[1] \"popY_711\" \"popY_685\" \"popY_632\" \"popY_583\" \"popY_547\" \"popY_490\" \"popY_421\"\n[8] \"popY_373\"\n\nplot_tracts(tracts, subset_inds)\n\n\n\n\n\n\n\n# It looks like the older individual is, the closer they lived to the start of the admixture event,\n# and the longer the tracts they carry will be. Compute the average length of a ancestry tracts in each\n# sample age group and visualize the length distribution of these tracts based on their age:\n\ntracts %&gt;%\n  group_by(time) %&gt;%\n  summarise(mean(length))\n\n# A tibble: 8 √ó 2\n   time `mean(length)`\n  &lt;dbl&gt;          &lt;dbl&gt;\n1     0        161733.\n2   100        188345.\n3   200        217594.\n4   300        256769.\n5   400        323533.\n6   500        429779.\n7   600        638513.\n8   700       1235801.\n\nggplot(tracts, aes(length, color = factor(time))) +\n  geom_density() +\n  coord_cartesian(xlim = c(0, 3e6)) +\n  theme_bw()\n\n\n\n\n\n\n\n# Now, try to work backwards. Assuming you have the following distribution of tract lengths...\n\ntracts &lt;- filter(tracts, time == 0, length &lt;= 1e6)\nbins &lt;- hist(tracts$length, breaks = 50, plot = FALSE)\nlength &lt;- bins$mids\ndensity &lt;- bins$density\n\nplot(length, density)\n\nlambda_mle &lt;- 1 / mean(tracts$length)\nlambda_mle / 1e-8\n\n[1] 626.4841\n\ny_mle &lt;- dexp(length, rate = lambda_mle)\nlines(length, y_mle, lty = 2, col = \"darkgreen\", lwd = 2)\n\nnls_res &lt;- nls(density ~ SSasymp(length, Asym, R0, lrc))\nnls_res\n\nNonlinear regression model\n  model: density ~ SSasymp(length, Asym, R0, lrc)\n   data: parent.frame()\n      Asym         R0        lrc \n 8.427e-09  6.238e-06 -1.198e+01 \n residual sum-of-squares: 6.788e-13\n\nNumber of iterations to convergence: 0 \nAchieved convergence tolerance: 9.393e-07\n\nlambda_nls &lt;- exp(unname(coef(nls_res)[\"lrc\"]))\nlambda_nls / 1e-8\n\n[1] 626.6864\n\ny_nls &lt;- predict(nls_res, newdata = data.frame(length = length))\nlines(length, y_nls, lty = 2, col = \"purple\", lwd = 2)\n\nlegend(\"topright\", fill = c(\"darkgreen\", \"purple\"),\n       legend = c(paste(\"MLE, t =\", round(lambda_mle / 1e-8, 1), \"generations ago\"),\n                  paste(\"MLE, t =\", round(lambda_nls / 1e-8, 1), \"generations ago\")))",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Admixture tracts and dating</span>"
    ]
  },
  {
    "objectID": "popgen-selection.html",
    "href": "popgen-selection.html",
    "title": "Natural selection",
    "section": "",
    "text": "Part 1: Simulating a tree sequence and computing Tajima‚Äôs D\nNote: Unfortunately, the most recent SLiM v4.3 is a little broken, largely sabotaging the second half of this exercise in which slendr uses SLiM for non-neutral simulations. That said, the first half of the exercise works perfectly fine and, once SLiM v5.0 comes out (soon), everything from the first half will apply to the selection simulations. Alternatively, if you have the option, use SLiM 4.2.x.\nThe primary motivation for designing slendr was to make demographic modelling in R as trivially easy and fast as possible, focusing exclusively on neutral models. However, as slendr became popular, people have been asking for the possibility of simulating natural selection. After all, a large part of slendr‚Äôs functionality deals with population genetic models across geographical landscapes, which requires SLiM. So why not support selection simulations using slendr as well?\nIn December 2024 I caved in and added support for modifying slendr demographic models with bits of SLiM code, which allows simulating pretty much any arbitrary selection scenario you might be interested in.\nThis exercise is a quick demonstration of how this works and how you might simulate selection using slendr. We will do this using another toy model of ancient human history, which we will first use as a basis for simulating the frequency trajectory of an allele under positive selection, and then implementing a toy selection scan using Tajima‚Äôs D.\nTo speed things up, create a new selection.R script and copy the following code as a starting point for this exercise:\nNext, visualize the demographic model. If you did a bit of work in human population genetics, you might recognize it as a very simplified model of demographic history of Europe over the past 50 thousand years or so. As you can see, we are recording 50 individuals from four populations ‚Äì for Europeans we sample 50 individuals at ‚Äúpresent-day‚Äù, for the remaining populations we‚Äôre recording 50 individuals just before their disappearance. Also note that there‚Äôs quite a bit of gene-flow! This was an important thing we‚Äôve learned about human history in the past 10 years or so ‚Äì everyone is mixed with pretty much everyone, there isn‚Äôt (and never was) anything as a ‚Äúpure population‚Äù.\nAlthough the point of this exercise is to simulate selection, let‚Äôs first simulate a normal neutral model using slendr‚Äôs msprime() engine as a sanity check. Simulate 10 Mb of sequence with a recombination rate 1e-8 and a sampling schedule defined above. Let‚Äôs not worry about adding any mutations, just to change things up a little bit. We‚Äôll be working with branch-based statistics here (which means adding mode = \"branch\" whenever we will be computing a statistic, such as Tajima‚Äôs D).\nInspect the table of all individuals recorded in our tree sequence using the function ts_samples(), making sure we have all the individuals scheduled for tree-sequence recording. (Again, there‚Äôs no such a thing as too many sanity checks when doing research!)\nAs you‚Äôve already learned in an earlier exercise, tskit functions in slendr generally operate on vectors (or lists) of individual names, like those produced by ts_names() above. Get a vector of names of individuals in every population recorded in the tree sequence, then use this to compute Tajima‚Äôs D using the slendr function ts_tajima(). (Use the same approach as you have with ts_diversity() or ts_divergence() above, using the list of names of individuals as the sample_sets = argument for ts_tajima()). Do you see any striking differences in the Tajima‚Äôs D values across populations? Check this for some general guidance.",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Natural selection</span>"
    ]
  },
  {
    "objectID": "popgen-selection.html#part-2-computing-tajimas-d-in-windows",
    "href": "popgen-selection.html#part-2-computing-tajimas-d-in-windows",
    "title": "Natural selection",
    "section": "Part 2: Computing Tajima‚Äôs D in windows",
    "text": "Part 2: Computing Tajima‚Äôs D in windows\nLet‚Äôs take this one step forward. Even if there is a locus under positive selection somewhere along our chromosome, it might be quite unlikely that we would find a Tajima‚Äôs D value significant enough for the entire chromosome (which is basically what we did in Part 1 now). Fortunately, thanks to the flexibility of the tskit module, the slendr function ts_tajima() has an argument windows =, which allows us to specify the coordinates of windows into which a sequence should be broken into, with Tajima‚Äôs D computed separately for each window. Perhaps this will allow us to see the impact of positive selection after we get to adding selection to our model. So let‚Äôs first built some code towards that.\nDefine a variable windows which will contain a vector of coordinates of 100 windows, starting at position 0, and ending at position 10e6 (i.e., the end of our chromosome). Then provide this variable as the windows = argument of ts_tajima() on a new, separate line of your script. Save the result of ts_tajima() into the variable tajima_wins, and inspect its contents in the R console.\nHint: You can use the R function seq() and its argument length.out = 100, to create the coordinates of window boundaries very easily.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# Pre-compute genomic windows for window-based computation of Tajima's D\nwindows &lt;- round(seq(0, ts$sequence_length, length.out = 100))\nwindows\n\n  [1]        0   101010   202020   303030   404040   505051   606061   707071\n  [9]   808081   909091  1010101  1111111  1212121  1313131  1414141  1515152\n [17]  1616162  1717172  1818182  1919192  2020202  2121212  2222222  2323232\n [25]  2424242  2525253  2626263  2727273  2828283  2929293  3030303  3131313\n [33]  3232323  3333333  3434343  3535354  3636364  3737374  3838384  3939394\n [41]  4040404  4141414  4242424  4343434  4444444  4545455  4646465  4747475\n [49]  4848485  4949495  5050505  5151515  5252525  5353535  5454545  5555556\n [57]  5656566  5757576  5858586  5959596  6060606  6161616  6262626  6363636\n [65]  6464646  6565657  6666667  6767677  6868687  6969697  7070707  7171717\n [73]  7272727  7373737  7474747  7575758  7676768  7777778  7878788  7979798\n [81]  8080808  8181818  8282828  8383838  8484848  8585859  8686869  8787879\n [89]  8888889  8989899  9090909  9191919  9292929  9393939  9494949  9595960\n [97]  9696970  9797980  9898990 10000000\n\n# Compute genome-wide Tajima's D for each population in individual windows\ntajima_wins &lt;- ts_tajima(ts, sample_sets = samples, windows = windows, mode = \"branch\")\ntajima_wins\n\n# A tibble: 4 √ó 2\n  set   D           \n  &lt;chr&gt; &lt;named list&gt;\n1 ANA   &lt;dbl [99]&gt;  \n2 EHG   &lt;dbl [99]&gt;  \n3 EUR   &lt;dbl [99]&gt;  \n4 YAM   &lt;dbl [99]&gt;  \n\n# You can see that the format of the result is slightly strange, with the\n# `D` column containing a vector of numbers (this is done for conciseness)\ntajima_wins[1, ]$D\n\n$`1`\n [1]  0.386580088  0.188242408  0.270979324  0.273413335  0.854262820\n [6] -0.439536912 -0.970720748 -0.465313524 -0.383532318 -0.274809017\n[11] -0.731023210 -0.052922734  0.763335962  0.171603219 -0.463769244\n[16]  0.488658538  0.151974975  1.230657926 -0.216449382  0.563368981\n[21]  0.460877820  0.650617691  0.180576222 -0.605274151  0.554971878\n[26] -0.134938979  0.791643504 -0.322512357 -0.027103787 -0.059989639\n[31] -0.935559908  0.294237828  0.524788826  0.359998461 -0.154353959\n[36]  0.438977533 -0.043475684 -1.053159125 -0.277292713  0.811128451\n[41]  0.224478982  0.819835561  0.853132721  0.797963629 -0.140706415\n[46] -0.769387808  0.020780479 -0.839426316 -1.166031223 -0.484253086\n[51]  0.315687664 -0.240782126  0.306280282  0.703717386  0.567730563\n[56] -0.195533103  1.060881020 -0.673599104  0.325603152  0.088753471\n[61]  0.543001022  0.109863906 -0.409196450  0.488401812  0.668344268\n[66]  0.785272626  0.301740771  0.445245536  0.374632047 -0.201480663\n[71]  0.154866671 -0.119204880  0.344034597  0.074220094  0.429496397\n[76]  0.268478663 -0.834014479 -0.868988615 -0.243089399 -0.945275737\n[81] -0.140557728  0.018303213 -0.334540613 -0.002601406  0.152416567\n[86]  0.213530391 -0.382886384 -0.341368957 -0.129206410  0.622479557\n[91]  0.109719904 -0.495108273 -1.225957724  0.227922424 -0.261523732\n[96] -0.244675393  0.100047048  0.901561637 -0.238117208\n\n\n\n\n\nThe default output format of ts_tajima() is not super user-friendly. Process the result using a helper function process_tajima(tajima_wins) that I provided for you (perhaps save it as tajima_df), and visualize it using another of my helper functions plot_tajima(tajima_df).\n\n\nNote: Making the process_tajima() and plot_tajima() function available in your R code is the purpose of the source(here::here(\"files/popgen/popgen_utils.R\")) command at the beginning of your script for this exercise.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# The helper function `process_tajima()` reformats the results into a normal\n# data frame, this time with a new column `window` which indicates the index\n# of the window that each `D` value was computed in\ntajima_df &lt;- process_tajima(tajima_wins)\ntajima_df\n\n# A tibble: 396 √ó 3\n   set        D window\n   &lt;chr&gt;  &lt;dbl&gt;  &lt;int&gt;\n 1 ANA    0.387      1\n 2 ANA    0.188      2\n 3 ANA    0.271      3\n 4 ANA    0.273      4\n 5 ANA    0.854      5\n 6 ANA   -0.440      6\n 7 ANA   -0.971      7\n 8 ANA   -0.465      8\n 9 ANA   -0.384      9\n10 ANA   -0.275     10\n# ‚Ñπ 386 more rows\n\n# Now let's visualize the window-based Tajima's D along the simulated genome\n# using another helper function `plot_tajima()`\nplot_tajima(tajima_df)\n\n\n\n\n\n\n\n\nIt‚Äôs no surprise that we don‚Äôt see any Tajima‚Äôs D outliers in any of our windows, because we‚Äôre still working with a tree sequence produced by our a purely neutral simulation. But we have everything set up for the next part, in which we will add selection acting on a beneficial allele.",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Natural selection</span>"
    ]
  },
  {
    "objectID": "popgen-selection.html#part-3-adding-positive-selection-to-the-base-demographic-model",
    "href": "popgen-selection.html#part-3-adding-positive-selection-to-the-base-demographic-model",
    "title": "Natural selection",
    "section": "Part 3: Adding positive selection to the base demographic model",
    "text": "Part 3: Adding positive selection to the base demographic model\nAlthough primarily designed for neutral demographic models, slendr allows optional simulation of natural selection by providing a ‚ÄúSLiM extension code snippet‚Äù with customization SLiM code as an optional argument extension = of compile_model() (a function you‚Äôre closely familiar with at this point).\nUnfortunately we don‚Äôt have any space to explain SLiM here (and I have no idea, at the time of writing, whether or not you will have worked with SLiM earlier in this workshop). Suffice to say that SLiM is another very popular population genetic simulator software which allows simulation of selection, and which requires you to write custom code in a different programming language called Eidos.\nTake a look at the file slim_extension.txt provided in your working directory (it‚Äôs also part of the GitHub repository here). If you worked with SLiM before, glance through the script casually and see if it makes any sense to you. If you have not worked with SLiM before, look for the strange {elements} in curly brackets in the first ten lines of the script. Those are the parameters of the selection model we will be customizing the standard neutral demographic model we started with in the next step.\nSpecifically, when you inspect the slim_extension.txt file, you can see that this ‚ÄúSLiM extension script‚Äù I provided for you has three parameters:\n\norigin_pop ‚Äì in which population should a beneficial allele appear,\ns ‚Äì what should be the selection coefficient of the beneficial allele, and\nonset_time ‚Äì at which time should the allele appear in the origin_pop.\n\nHowever, at the start, the SLiM extension snippet doesn‚Äôt contain any concrete values of those parameters, but only their {origin_pop}, {s}, and {onset_time} placeholders.\nUse the slendr function substitute_values() to substitute concrete values for those parameters like this:\n\nextension &lt;- substitute_values(\n  template = here::here(\"files/popgen/slim_extension.txt\"),\n  origin_pop = \"EUR\",\n  s = 0.15,\n  onset_time = 12000\n)\nextension\n\n[1] \"/var/folders/h2/qs0z_44x2vn2sskqc0cct7540000gn/T//Rtmp1z0j9W/file16c3017a26d39\"\n\n\nYou can see that substitute_values() returned a path to a file. Take a look at that file in your terminal ‚Äì you should see each of the three {placeholder} parameters replaced with a concrete given value.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nLet‚Äôs take a look at the first 15 lines of the extension file before and after calling substitute_values(). We‚Äôll do this in R for simplicity, but you can use less in plain unix terminal.\nBefore ‚Äì see the {{placeholder}} parameters in their original form:\n\n\n// Define model constants (to be substituted) all in one place\n// (each {{placeholder}} will be replaced by a value passed from R).\n// Note that string constant template patterns are surrounded by \"quotes\"!\ninitialize() {\n    defineConstant(\"s\", {{s}});\n    defineConstant(\"onset_time\", {{onset_time}});\n    defineConstant(\"origin_pop\", \"{{origin_pop}}\");\n\n    // compose a trajectory file based on given parameters\n    defineConstant(\"traj_file\", PATH + \"/\" + \"trajectory.tsv\");\n}\n\n\nAfter ‚Äì see the {{placeholder}} parameters with concrete values!\n\n\n// Define model constants (to be substituted) all in one place\n// (each {{placeholder}} will be replaced by a value passed from R).\n// Note that string constant template patterns are surrounded by \"quotes\"!\ninitialize() {\n    defineConstant(\"s\", 0.15);\n    defineConstant(\"onset_time\", 12000);\n    defineConstant(\"origin_pop\", \"EUR\");\n\n    // compose a trajectory file based on given parameters\n    defineConstant(\"traj_file\", PATH + \"/\" + \"trajectory.tsv\");\n}\n\n\n\n\n\nAnd that‚Äôs all the extra work we need to turn our purely neutral demographic slendr model into a model which includes natural selection! (In this case, only a simple selection acting on a single locus, as you‚Äôll see later, but this can be generalized to any imaginable selection scenario.)\nHow do we use the SLiM extension for our simulation? It‚Äôs very simple ‚Äì we just have to provide the extension variable as an additional argument of good old compile_model(). This will compile a new slendr model which will now include the new functionality for simulating natural selection:\nCompile a new model of the history of populations afr, ooa, ehg, etc., by following the instructions above, providing a new extension = argument to the compile_model() function.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nmodel &lt;- compile_model(\n  populations = list(afr, ooa, ehg, eur, ana, yam),\n  gene_flow = gf, generation_time = 30,\n  extension = extension   # &lt;======== this is missing in the neutral example!\n)",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Natural selection</span>"
    ]
  },
  {
    "objectID": "popgen-selection.html#part-4-running-a-selection-simulation-using-slim",
    "href": "popgen-selection.html#part-4-running-a-selection-simulation-using-slim",
    "title": "Natural selection",
    "section": "Part 4: Running a selection simulation using slim()",
    "text": "Part 4: Running a selection simulation using slim()\nNow we can finally run our selection simulation!\nThere are two modifications to our previous simulation workflows:\n\nBecause we need to run a non-neutral simulation, we have to switch from using the msprime() slendr engine to slim(). The latter can still interpret the same demographic model we programmed in R, just like the msprime() engine can, but will run the model using SLiM (and thus leveraging the new SLiM extension code that we have customized using substitute_values() above). We simply do this by switching from this:\n\n\nts &lt;- msprime(model, sequence_length = 10e6, recombination_rate = 1e-8, samples = schedule)\n\nto this:\n\nts &lt;- slim(model, sequence_length = 10e6, recombination_rate = 1e-8, samples = schedule)\n\nAs you can see, you don‚Äôt have to modify anything in your model code, just switching from msprime to slim in the line of code which produces the simulation result.\n\nThe customized model will not only produce a tree sequence, but will also generate a table of allele frequencies in each population (SLiM experts might have noticed the revelant SLiM code when they were inspecting slim_extension.txt). We need to be able to load both of these files after the simulation and thus need a path to a location we can find those files. We can do this by calling the slim() function as path &lt;- slim(..., path = TRUE) (so with the extra path = argument). This will return a path to where the slim() engine saved all files with our desired results.\n\nRun a simulation from the modified model of selection with the slim() engine as instructed in points number 1. and 2. above, then use the list.files(path) function in R to take a look in the directory. Which files were produced by the simulation?\n\n\n\n\n\n\nClick to see the solution (you have a working SLiM installation)\n\n\n\n\n\n\n# tstart &lt;- Sys.time()\npath &lt;- slim(model, sequence_length = 10e6, recombination_rate = 1e-8, samples = schedule, path = TRUE, random_seed = 59879916)\n# tend &lt;- Sys.time()\n# tend - tstart # Time difference of 38.82014 secs\n\n# We can verify that the path not only contains a tree-sequence file but also\n# the table of allele frequencies.\nlist.files(path)\n\n[1] \"slim.trees\"     \"trajectory.tsv\"\n\n\nWe can see that the slim() simulation generated a tree-sequence file (just like in previous exercises focused on msprime()) but it also created a new file ‚Äì this was done by the SLiM customization snippet we provided to compile_model().\n\n\n\n\n\n\n\n\n\nClick to see the solution (you don‚Äôt have a working SLiM installation or the simulation takes too long)\n\n\n\n\n\n\n# If you don't have SLiM set up, just use the simulated results from my own\n# run of the same simulation\npath &lt;- here::here(\"files/popgen/selection\")\n\n# We can verify that the path not only contains a tree-sequence file but also\n# the table of allele frequencies.\nlist.files(path)\n\n[1] \"slim.trees\"     \"trajectory.tsv\"\n\nts &lt;- ts_read(file.path(path, \"slim.trees\"), model)\n\nWe can see that the slim() simulation generated a tree-sequence file (just like in previous exercises focused on msprime()) but it also created a new file ‚Äì this was done by the SLiM customization snippet we provided to compile_model().",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Natural selection</span>"
    ]
  },
  {
    "objectID": "popgen-selection.html#part-5-investigating-allele-frequency-trajectories",
    "href": "popgen-selection.html#part-5-investigating-allele-frequency-trajectories",
    "title": "Natural selection",
    "section": "Part 5: Investigating allele frequency trajectories",
    "text": "Part 5: Investigating allele frequency trajectories\nUse another helper function read_trajectory(path) which I provided for this exercise to read the simulated frequency trajectories of the positively selected mutation in all of our populations into a variable traj_df. Then run a second helper function plot_trajectory(traj_df) to inspect the trajectories visually.\nRecall that you used the function substitute_values() to parametrize your selection model so that the allele under selection occurs in Europeans 15 thousand years ago, and is programmed to be under very strong selection of \\(s = 0.15\\). Do the trajectories visualized by plot_trajectory() make sense given the demographic model of European prehistory plotted above?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\ntraj_df &lt;- read_trajectory(path)\ntraj_df\n\n# A tibble: 1,604 √ó 4\n    time pop      freq onset\n   &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 11990 EHG    0      12000\n 2 11990 ANA    0      12000\n 3 11990 EUR    0.0001 12000\n 4 11990 YAM   NA      12000\n 5 11960 EHG    0      12000\n 6 11960 ANA    0      12000\n 7 11960 EUR    0.0001 12000\n 8 11960 YAM   NA      12000\n 9 11930 EHG    0      12000\n10 11930 ANA    0      12000\n# ‚Ñπ 1,594 more rows\n\nplot_trajectory(traj_df)\n\nWarning: Removed 554 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n# Comparing the trajectories side-by-side with the demographic model reveals\n# some obvious patterns of both selection and demographic history.\nplot_grid(\n  plot_model(model),\n  plot_trajectory(traj_df),\n  nrow = 1, rel_widths = c(0.7, 1)\n)\n\nWarning: Removed 554 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nWe can see that the beneficial allele which appeared in the European population was under extremely strong selection (look how its allele frequency shoots up immediately after its first appearance!). However, we can also se how the following demographic history with multiple admixture events kept ‚Äúdiluting‚Äù the allele frequency (indicated by the dips in the trajectory).\nThis is the kind of slendr simulation which could be also very useful for simulation-based inference, like we did in the previous exercise. Just imagine having a comparable aDNA time series data with empirical allele frequency trajectory over time and using it in an ABC setting!",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Natural selection</span>"
    ]
  },
  {
    "objectID": "popgen-selection.html#part-6-tajimas-d-genome-wide-and-window-based-from-the-selection-model",
    "href": "popgen-selection.html#part-6-tajimas-d-genome-wide-and-window-based-from-the-selection-model",
    "title": "Natural selection",
    "section": "Part 6: Tajima‚Äôs D (genome-wide and window-based) from the selection model",
    "text": "Part 6: Tajima‚Äôs D (genome-wide and window-based) from the selection model\nRecall that your simulation run saved results in the location stored in the path variable:\n\nlist.files(path)\n\n[1] \"slim.trees\"     \"trajectory.tsv\"\n\n\nFrom this path, we‚Äôve already successfuly investigated the frequency trajectories.\nNow let‚Äôs compute Tajima‚Äôs D on the tree sequence simulated from our selection model. Hopefully we should see an interesting pattern in our selection scan? For instance, we don‚Äôt know yet where in the genome is the putative locus under selection!\nTo read a tree sequence simulated with slim() by our customized selection setup, we need to do a bit of work. To simplify things a bit, here‚Äôs the R code which makes it possible to do. Just copy it in your selection.R script as it is:\n\n# Let's use my own saved simulation results, so that we're all on the\n# same page going forward\npath &lt;- here::here(\"files/popgen/selection\")\n\nts &lt;-\n  file.path(path, \"slim.trees\") %&gt;%  # 1. compose full path to the slim.trees file\n  ts_read(model) %&gt;%                 # 2. read the tree sequence file into R\n  ts_recapitate(Ne = 5000, recombination_rate = 1e-8) # 3. perform recapitation\n\nVery briefly, because our tree sequence was generated by SLiM, it‚Äôs very likely that not all genealogies along the simulated genome will be fully coalesced (i.e., not all tree will have a single root). To explain why this is the case is out of the scope of this session, but read here if you‚Äôre interested in learning more. For the time being, it suffices to say that we can pass the (uncoalesced) tree sequence into the ts_recapitate() function, which then takes a SLiM tree sequence and simulates all necessary ‚Äúancestral history‚Äù that was missing on the uncoalesced trees, thus ensuring that the entire tree sequence is fully coalesced and can be correctly computed on.\nNow that you have a ts tree sequence object resulting from a new selection simulation run, repeat the analyses of genome-wide and window-based Tajima‚Äôs D from Part 1 and Part 2 of this exercise, again using the provided helper functions process_tajima() and plot_tajima(). Can you identify which locus has been the likely focal point of the positive selection? Which population shows evidence of selection? Which doesn‚Äôt and why (look again at the visualization of the demographic model above)?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nsamples &lt;- ts_names(ts, split = \"pop\")\nsamples\n\n$ANA\n [1] \"ANA_1\"  \"ANA_2\"  \"ANA_3\"  \"ANA_4\"  \"ANA_5\"  \"ANA_6\"  \"ANA_7\"  \"ANA_8\" \n [9] \"ANA_9\"  \"ANA_10\" \"ANA_11\" \"ANA_12\" \"ANA_13\" \"ANA_14\" \"ANA_15\" \"ANA_16\"\n[17] \"ANA_17\" \"ANA_18\" \"ANA_19\" \"ANA_20\" \"ANA_21\" \"ANA_22\" \"ANA_23\" \"ANA_24\"\n[25] \"ANA_25\" \"ANA_26\" \"ANA_27\" \"ANA_28\" \"ANA_29\" \"ANA_30\" \"ANA_31\" \"ANA_32\"\n[33] \"ANA_33\" \"ANA_34\" \"ANA_35\" \"ANA_36\" \"ANA_37\" \"ANA_38\" \"ANA_39\" \"ANA_40\"\n[41] \"ANA_41\" \"ANA_42\" \"ANA_43\" \"ANA_44\" \"ANA_45\" \"ANA_46\" \"ANA_47\" \"ANA_48\"\n[49] \"ANA_49\" \"ANA_50\"\n\n$EHG\n [1] \"EHG_1\"  \"EHG_2\"  \"EHG_3\"  \"EHG_4\"  \"EHG_5\"  \"EHG_6\"  \"EHG_7\"  \"EHG_8\" \n [9] \"EHG_9\"  \"EHG_10\" \"EHG_11\" \"EHG_12\" \"EHG_13\" \"EHG_14\" \"EHG_15\" \"EHG_16\"\n[17] \"EHG_17\" \"EHG_18\" \"EHG_19\" \"EHG_20\" \"EHG_21\" \"EHG_22\" \"EHG_23\" \"EHG_24\"\n[25] \"EHG_25\" \"EHG_26\" \"EHG_27\" \"EHG_28\" \"EHG_29\" \"EHG_30\" \"EHG_31\" \"EHG_32\"\n[33] \"EHG_33\" \"EHG_34\" \"EHG_35\" \"EHG_36\" \"EHG_37\" \"EHG_38\" \"EHG_39\" \"EHG_40\"\n[41] \"EHG_41\" \"EHG_42\" \"EHG_43\" \"EHG_44\" \"EHG_45\" \"EHG_46\" \"EHG_47\" \"EHG_48\"\n[49] \"EHG_49\" \"EHG_50\"\n\n$EUR\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\" \"EUR_31\" \"EUR_32\"\n[33] \"EUR_33\" \"EUR_34\" \"EUR_35\" \"EUR_36\" \"EUR_37\" \"EUR_38\" \"EUR_39\" \"EUR_40\"\n[41] \"EUR_41\" \"EUR_42\" \"EUR_43\" \"EUR_44\" \"EUR_45\" \"EUR_46\" \"EUR_47\" \"EUR_48\"\n[49] \"EUR_49\" \"EUR_50\"\n\n$YAM\n [1] \"YAM_1\"  \"YAM_2\"  \"YAM_3\"  \"YAM_4\"  \"YAM_5\"  \"YAM_6\"  \"YAM_7\"  \"YAM_8\" \n [9] \"YAM_9\"  \"YAM_10\" \"YAM_11\" \"YAM_12\" \"YAM_13\" \"YAM_14\" \"YAM_15\" \"YAM_16\"\n[17] \"YAM_17\" \"YAM_18\" \"YAM_19\" \"YAM_20\" \"YAM_21\" \"YAM_22\" \"YAM_23\" \"YAM_24\"\n[25] \"YAM_25\" \"YAM_26\" \"YAM_27\" \"YAM_28\" \"YAM_29\" \"YAM_30\" \"YAM_31\" \"YAM_32\"\n[33] \"YAM_33\" \"YAM_34\" \"YAM_35\" \"YAM_36\" \"YAM_37\" \"YAM_38\" \"YAM_39\" \"YAM_40\"\n[41] \"YAM_41\" \"YAM_42\" \"YAM_43\" \"YAM_44\" \"YAM_45\" \"YAM_46\" \"YAM_47\" \"YAM_48\"\n[49] \"YAM_49\" \"YAM_50\"\n\n# Overall Tajima's D across the 10Mb sequence still doesn't reveal any significant\n# deviations even in case of selection (again, not entirely unsurprising)\nts_tajima(ts, sample_sets = samples, mode = \"branch\")\n\n# A tibble: 4 √ó 2\n  set        D\n  &lt;chr&gt;  &lt;dbl&gt;\n1 ANA    0.124\n2 EHG    0.105\n3 EUR   -0.195\n4 YAM   -0.133\n\n\n\n# So let's look at the window-based computation again...\nwindows &lt;- as.integer(seq(0, ts$sequence_length, length.out = 100))\n\n# compute genome-wide Tajima's D for each population in individual windows\ntajima_wins &lt;- ts_tajima(ts, sample_sets = samples, windows = windows, mode = \"branch\")\ntajima_df &lt;- process_tajima(tajima_wins)\n\nplot_tajima(tajima_df)\n\n\n\n\n\n\n\n\nYou should see a clear dip in Tajima‚Äôs D around the midpoint of the DNA sequence, but only in Europeans. The beneficial allele appeared in the European population, and although the plot of the allele frequency trajectories shows that the selection dynamics has been dramatically affected by gene-flow events (generally causing a repeated ‚Äúdilution‚Äù of the selection signal in Europeans), there has never been gene-flow (at least in our model) from Europeans to other populations, so the beneficial allele never had a chance to ‚Äúmake it‚Äù into those populations.\n\n\n\n\n\n\n\n\n\nBonus exercises\n\n\n\n\nBonus 1: Examine the pattern of ancestry tracts along the simulated genome\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# tracts &lt;- ts_tracts(ts, source = \"ANA\", target = \"EUR\")\n\n\n\n\n\n\nBonus 2: Investigate the impact of recombination around the selected locus\nVary the uniform recombination rate and observe what happens with Tajima‚Äôs D in windows along the genome.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nSolution: just modify the value of the recombination_rate = argument provided to the slim() function above.\n\n\n\n\n\nBonus 3: Simulate origin of the allele in EHG\nSimulate the origin of the beneficial allele in the EHG population ‚Äì what do the trajectories look like now? How does that change the Tajima‚Äôs D distribution along the genome in our European populations?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nUse this extension in the slim() call, and repeat the rest of the selection-based workflow in this exercise.\n\nextension &lt;- substitute_values(\n  template = here::here(\"files/popgen/slim_extension.txt\"),\n  origin_pop = \"EHG\",\n  s = 0.1,\n  onset_time = 12000\n)\n\nmodel &lt;- compile_model(\n  populations = list(afr, ooa, ehg, eur, ana, yam),\n  gene_flow = gf, generation_time = 30,\n  extension = extension\n)\n\n\n\n\n\n\nBonus 4: Other statistics in windows\nAs a practice of your newly acquired tree-sequence computation skills with slendr, calculate some other statistics in the same windows along the simulated genome, visualize them yourself, and compare the results to the window-based Tajima‚Äôs D pattern. For instance, ts_diversity(), ts_divergence(), or ts_segregating() might be quite interesting to look at.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nUse the same tree sequence file you‚Äôve computed Tajima‚Äôs D on, and then apply the functions ts_diversity(), ts_divergence(), and ts_segregating() on that tree sequence.",
    "crumbs": [
      "Modeling fundamentals",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Natural selection</span>"
    ]
  },
  {
    "objectID": "inference-afs.html",
    "href": "inference-afs.html",
    "title": "\\(N_e\\) inference with AFS",
    "section": "",
    "text": "Part 1: A self-contained slendr function of \\(N_e \\rightarrow \\textrm{AFS}\\)\nSo far we‚Äôve learned how slendr provides an easy way to define demographic models in R and simulate (even very large!) tree sequences from them. This allows us to quickly verify our intuition about some popgen problem (things like ‚ÄúHmmm, I wonder what would an \\(f_4\\) statistic look like if my model includes this particular gene-flow event?), in just a few lines of R. There have been instances in which we‚Äôve been able to even answer questions like this directly in a meeting, pretty much on the spot! This makes slendr a very powerful ‚Äúpopgen calculator‚Äù.\nNow let‚Äôs take things one step further. Imagine you gathered some empirical data, like an allele frequency spectrum (AFS) from a population that you study. That data was, in the real world, produced by some (hidden) biological process (demographic history) that we want to learn about. For instance, the population we study had some \\(N_e\\), which we don‚Äôt know the value of (the only thing we have is the observed AFS) but we want to infer that value.\nSimulations can be a great tool to estimate the most likely value of such an unknown parameter. Briefly speaking, in this particular toy example, we can simulate a large number of AFS vectors (each resulting from a different assumed \\(N_e\\) value) and then pick just those \\(N_e\\) values (or just one \\(N_e\\) value) which produced a simulated AFS closest to the observed AFS.\nThis is exactly what you‚Äôll be doing just now in Exercise 3.\nIn a new script afs.R write a custom R function called simulate_afs(), which will take Ne as its only parameter. Use this function to compute (and return) AFS vectors for a couple of Ne values of your choosing, but staying between Ne = 1000 and Ne = 30000 Plot those AFS vectors and observe how (and why?) do they differ based on Ne parameter you used in each respective simulation.\nHint: The function should create a one-population forward-time model (our population starting at time = 1, with the model simulation_length = 100000 and generation_time = 1 in compile_model()), simulate 10Mb tree sequence using msprime() (recombination rate 1e-8) and then overlay neutral mutations on it at mutation_rate = 1e-8), compute AFS for 10 samples and return the AFS vector as result of this custom function.\nHint: If you‚Äôve never programmed before, the concept of a ‚Äúcustom function‚Äù might be very alien to you. Again, if you need help, feel free to start building your afs.R solution based on this ‚Äútemplate‚Äù (just fill in missing relevant bits of slendr code that you should be already familiar with):\nlibrary(slendr)\ninit_env()\n\nsimulate_afs &lt;- function(Ne) {\n  # In here you should write code which will:\n  #   1. create one population with a given Ne (provided as a function argument)\n  #   2. compile a model using `simulation_length =` and `generation_time =`\n  #   3. simulate a tree sequence\n  #   4. select names of 10 samples (doesn't matter which, \"pop_1\", \"po2_\", ...)\n  #   5. compute AFS vector from those 10 individuals using `ts_afs()`\n  \n  # `result` is a variable with your 10-sample AFS vector (we remove the\n  # first element because it's not meaningful for our example)\n  return(result[-1]) \n}\n\nafs_1 &lt;- simulate_afs(Ne = 1000) # simulate AFS from a Ne = 1000 model...\nplot(afs_1, type =\"o\")           # ... and plot it\nHint: If the above still doesn‚Äôt make any sense to you, feel free to copy-paste the function from the solution below into your script and work with that function instead!\nWhen used in R, your custom function should work like this (the simulation is stochastic, so your numbers will be different, of course):\n# This gives us a vector of singletons, doubletons, etc., etc., all the way\n# to the number of fixed mutations in our sample of 10 individuals\nsimulate_afs(Ne = 1000)\n\n [1] 443 235 135  87  89  43  53  37  56  57  42  15  27  22  30  16  27  36  38\n[20]  15",
    "crumbs": [
      "Simulation-based inference",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>$N_e$ inference with AFS</span>"
    ]
  },
  {
    "objectID": "inference-afs.html#part-1-a-self-contained-slendr-function-of-n_e-rightarrow-textrmafs",
    "href": "inference-afs.html#part-1-a-self-contained-slendr-function-of-n_e-rightarrow-textrmafs",
    "title": "\\(N_e\\) inference with AFS",
    "section": "",
    "text": "Note: Remember that you should drop the first element of the AFS vector produced by ts_afs() (for instance with something like result[-1] if result contains the output of ts_afs()) technical reasons related to tskit. You don‚Äôt have to worry about that here, but you can read this for more detail.\n\n\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nA function can be understood as a independent unit of a computer program which executes a block of code inside the {‚Ä¶} brackets given some values of some parameters. In our example, we programmed a function simulate_sfs() which accepts a single parameter, Ne.\n\nsimulate_afs &lt;- function(Ne) {\n  # create a slendr model with a single population of size Ne = N\n  pop &lt;- population(\"pop\", N = Ne, time = 1)\n  model &lt;- compile_model(pop, generation_time = 1, simulation_length = 100000)\n\n  # simulate a tree sequence\n  ts &lt;-\n    msprime(model, sequence_length = 10e6, recombination_rate = 1e-8) %&gt;%\n    ts_mutate(mutation_rate = 1e-8)\n\n  # get a random sample of names of 10 individuals\n  samples &lt;- ts_names(ts) %&gt;% sample(10)\n\n  # compute the AFS vector (dropping the 0-th element added by tskit)\n  afs &lt;- ts_afs(ts, sample_sets = list(samples))[-1]\n\n  afs\n}\n\nOur functions is supposed to produce an AFS vector of counts of alleles observed at a given frequency a the population sample:\nLet‚Äôs use our custom function to simulate AFS vector for Ne = 1k, 10k, and 30k:\n\nafs_1k &lt;- simulate_afs(1000)\nafs_10k &lt;- simulate_afs(10000)\nafs_30k &lt;- simulate_afs(30000)\n\nHere‚Äôs one of those vectors. We can see that the function does, indeed, produce a result of the correct format:\n\nafs_1k\n\n [1] 443 235 130 116  78  71  55  44  45  51  31  29  26  19  11  26  28  17   9\n[20]  31\n\n\nTo see the results of this function in a clearer context, let‚Äôs visualize the vectors in the same plot:\n\nplot(afs_30k, type = \"o\", main = \"AFS, Ne = 30000\", col = \"cyan\",)\nlines(afs_10k, type = \"o\", main = \"AFS, Ne = 10000\", col = \"purple\")\nlines(afs_1k, type = \"o\", main = \"AFS, Ne = 1000\", col = \"blue\")\nlegend(\"topright\", legend = c(\"Ne = 1k\", \"Ne = 10k\", \"Ne = 30k\"),\n       fill = c(\"blue\", \"purple\", \"cyan\"))",
    "crumbs": [
      "Simulation-based inference",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>$N_e$ inference with AFS</span>"
    ]
  },
  {
    "objectID": "inference-afs.html#part-2-estimating-unknown-n_e-from-empirical-afs",
    "href": "inference-afs.html#part-2-estimating-unknown-n_e-from-empirical-afs",
    "title": "\\(N_e\\) inference with AFS",
    "section": "Part 2: Estimating unknown \\(N_e\\) from empirical AFS",
    "text": "Part 2: Estimating unknown \\(N_e\\) from empirical AFS\nImagine you sequenced 10 samples from a population and computed the following AFS vector (which contains, sequentially, the number of singletons, doubletons, etc., in your sample from a population):\n\n\nafs_observed &lt;- c(2520, 1449, 855, 622, 530, 446, 365, 334, 349, 244,\n                  264, 218,  133, 173, 159, 142, 167, 129, 125, 143)\n\nYou know (maybe from some fossil evidence) that the population probably had a constant \\(N_e\\) somewhere between 1000 and 30000 for the past 100,000 generations, and had mutation and recombination rates of 1e-8 (i.e., parameters already implemented by your simulate_afs() function ‚Äì how convenient!).\nUse slendr simulations to guess the true (and hidden!) \\(N_e\\) given the observed AFS by running simulations for a range of \\(N_e\\) values and finding out which \\(N_e\\) produces the closest AFS vector to the afs_observed vector above using one of the following two approaches.\n\nOption 1 [easy]: Plot AFS vectors for various \\(N_e\\) values (i.e.¬†simulate several of them using your function simulate_afs()), then eyeball which looks closest to the observed AFS based on the figures alone. (This is, of course, not how proper statistical inference is done, but it will be good enough for this exercie!)\nOption 2 [hard]: Simulate AFS vectors in steps of possible Ne (maybe lapply()?), and find the \\(N_e\\) which gives the closest AFS to the observed AFS based on Mean squared error.\n\n\n\n\n\n\n\nClick to see the solution to ‚ÄúOption 1‚Äù\n\n\n\n\n\nThis is the observed AFS with which we want to compare our simulated AFS vectors:\n\nafs_observed &lt;- c(2520, 1449, 855, 622, 530, 446, 365, 334, 349, 244,\n                  264, 218,  133, 173, 159, 142, 167, 129, 125, 143)\n\nWe know that the true \\(N_e\\) is supposed to be between 1000 and 30000, so let‚Äôs simulate a bunch of AFS vectors for different \\(N_e\\) values using our new AFS simulation function:\n\nafs_Ne1k &lt;- simulate_afs(Ne = 1000)\nafs_Ne5k &lt;- simulate_afs(Ne = 5000)\nafs_Ne6k &lt;- simulate_afs(Ne = 6000)\nafs_Ne10k &lt;- simulate_afs(Ne = 10000)\nafs_Ne20k &lt;- simulate_afs(Ne = 20000)\nafs_Ne30k &lt;- simulate_afs(Ne = 30000)\n\nNow let‚Äôs plot our simulated AFS vectors together with the observed AFS (highlighting it in black):\n\nplot(afs_observed, type = \"b\", col = \"black\", lwd = 3,\n     xlab = \"allele count bin\", ylab = \"count\", ylim = c(0, 13000))\nlines(afs_Ne1k, lwd = 2, col = \"blue\")\nlines(afs_Ne5k, lwd = 2, col = \"green\")\nlines(afs_Ne6k, lwd = 2, col = \"pink\")\nlines(afs_Ne10k, lwd = 2, col = \"purple\")\nlines(afs_Ne20k, lwd = 2, col = \"orange\")\nlines(afs_Ne30k, lwd = 2, col = \"cyan\")\nlegend(\"topright\",\n       legend = c(\"observed AFS\", \"Ne = 1000\", \"Ne = 5000\",\n                  \"Ne = 6000\", \"Ne = 10000\", \"Ne = 20000\", \"Ne = 30000\"),\n       fill = c(\"black\", \"blue\", \"green\", \"pink\", \"purple\", \"orange\", \"cyan\"))\n\n\n\n\n\n\n\n\nThe true \\(N_e\\) was 6543!\n\n\n\n\n\n\n\n\n\nClick to see the solution to ‚ÄúOption 2‚Äù\n\n\n\n\n\nThis is the observed AFS with which we want to compare our simulated AFS vectors:\n\nafs_observed &lt;- c(2520, 1449, 855, 622, 530, 446, 365, 334, 349, 244,\n                  264, 218,  133, 173, 159, 142, 167, 129, 125, 143)\n\nWe know that the true \\(N_e\\) is supposed to be between 1000 and 30000. Let‚Äôs generate regularly spaced values of potential Ne values whose AFS we want to investigate and compare to the obesrved AFS (our parameter grid):\n\nNe_grid &lt;- seq(from = 1000, to = 30000, by = 500)\nNe_grid\n\n [1]  1000  1500  2000  2500  3000  3500  4000  4500  5000  5500  6000  6500\n[13]  7000  7500  8000  8500  9000  9500 10000 10500 11000 11500 12000 12500\n[25] 13000 13500 14000 14500 15000 15500 16000 16500 17000 17500 18000 18500\n[37] 19000 19500 20000 20500 21000 21500 22000 22500 23000 23500 24000 24500\n[49] 25000 25500 26000 26500 27000 27500 28000 28500 29000 29500 30000\n\n\nWith the parameter grid Ne_grid set up, let‚Äôs simulate an AFS from each \\(N_e\\) model:\n\nlibrary(parallel)\n\nafs_grid &lt;- mclapply(Ne_grid, simulate_afs, mc.cores = detectCores())\nnames(afs_grid) &lt;- Ne_grid\n\n# show the first five simulated AFS vectors, for brevity, just to demonstrate\n# what the output of the grid simulations is supposed to look like\nafs_grid[1:5]\n\n$`1000`\n [1] 429 226 125 100  78  61  40  51  38  27  38  34  29  26  34  26  24  17  14\n[20]  18\n\n$`1500`\n [1] 559 332 177 166 122  96  80  53  56  61  53  39  45  46  41  36  52  38  33\n[20]  24\n\n$`2000`\n [1] 785 400 300 244 140 112 113  78  77  93  71  61  66  55  53  61  71  47  43\n[20]  36\n\n$`2500`\n [1] 1018  506  321  288  168  161  174  113   91   90   94   85   98   64   33\n[16]   66   61   63   41   60\n\n$`3000`\n [1] 1352  598  382  311  252  174  180  135  117  108  109   88   92   82   82\n[16]   72   75   61   73   54\n\n\nPlot the observed AFS and overlay the simulated AFS vectors on top of it:\n\nplot(afs_observed, type = \"b\", col = \"black\", lwd = 3, xlab = \"allele count bin\", ylab = \"count\")\nfor (i in seq_along(Ne_grid)) {\n  lines(afs_grid[[i]], lwd = 0.5)\n}\nlegend(\"topright\", legend = c(\"observed AFS\", \"simulated AFS\"), fill = c(\"black\", \"gray\"))\n\n\n\n\n\n\n\n\nCompute mean-squared error of the AFS produced by each \\(N_e\\) value across the grid:\n\nerrors &lt;- sapply(afs_grid, function(sim_afs) {\n  sum((sim_afs - afs_observed)^2) / length(sim_afs)\n})\n\nplot(Ne_grid, errors, ylab = \"error\")\nabline(v = Ne_grid[which.min(errors)], col = \"red\")\nlegend(\"topright\", legend = paste(\"minimum error Ne =\", Ne_grid[which.min(errors)]), fill = \"red\")\n\n\n\n\n\n\n\n\nPlot the AFS again, but this time highlight the most likely spectrum (i.e.¬†the one which gave the lowest RMSE value):\n\nplot(afs_observed, type = \"b\", col = \"black\", lwd = 3, xlab = \"allele count bin\", ylab = \"count\")\nfor (i in seq_along(Ne_grid)) {\n  color &lt;- if (i == which.min(errors)) \"red\" else \"gray\"\n  width &lt;- if (i == which.min(errors)) 2 else 0.75\n  lines(afs_grid[[i]], lwd = width, col = color)\n}\nlegend(\"topright\", legend = c(\"observed AFS\", paste(\"best fitting Ne =\", Ne_grid[which.min(errors)])),\n       fill = c(\"black\", \"red\"))\n\n\n\n\n\n\n\n\nThe true \\(N_e\\) was 6543!\n\n\n\nCongratulations, you now know how to infer parameters of evolutionary models using simulations! What you just did is really very similar to how simulation-based inference is done in practice (even with methods such as ABC). Hopefully you now also see how easy slendr makes it to do this (normally a rather laborious) process.\nThis kind of approach can be used to infer all sorts of demographic parameters, even using other summary statistics that you‚Äôve also learned to compute‚Ä¶ including selection parameters, which we delve into in another exercise.",
    "crumbs": [
      "Simulation-based inference",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>$N_e$ inference with AFS</span>"
    ]
  },
  {
    "objectID": "handouts.html",
    "href": "handouts.html",
    "title": "Handouts",
    "section": "",
    "text": "This section contains a single-page rendering of slides introducing each chapter in form of handout slides. These are indended for easier reference during practical exercise sessions for each given chapter.",
    "crumbs": [
      "Handouts"
    ]
  },
  {
    "objectID": "handouts_slendr.html",
    "href": "handouts_slendr.html",
    "title": "Introduction to slendr",
    "section": "",
    "text": "Why use simulations?",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#developing-intuition-into-statistics",
    "href": "handouts_slendr.html#developing-intuition-into-statistics",
    "title": "Introduction to slendr",
    "section": "Developing intuition into statistics",
    "text": "Developing intuition into statistics\n\n\n\n\n\nImage from Peter (2016)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#developing-intuition-into-statistics-1",
    "href": "handouts_slendr.html#developing-intuition-into-statistics-1",
    "title": "Introduction to slendr",
    "section": "Developing intuition into statistics",
    "text": "Developing intuition into statistics\n\n\n\n\n\nImage from Lawson et al. (2018)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#estimating-model-parameters-i.e.-abc",
    "href": "handouts_slendr.html#estimating-model-parameters-i.e.-abc",
    "title": "Introduction to slendr",
    "section": "Estimating model parameters (i.e.¬†ABC)",
    "text": "Estimating model parameters (i.e.¬†ABC)\n\n\n\n\n\nImage from Wikipedia on ABC",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#ground-truth-for-method-development",
    "href": "handouts_slendr.html#ground-truth-for-method-development",
    "title": "Introduction to slendr",
    "section": "Ground truth for method development",
    "text": "Ground truth for method development\n\n\n\n\n\nImage from Schiffels and Durbin (2014)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#simulation-software",
    "href": "handouts_slendr.html#simulation-software",
    "title": "Introduction to slendr",
    "section": "Simulation software",
    "text": "Simulation software\nThe most famous and widely used are SLiM and msprime.\n\nThey are very powerful and (nearly) infinitely flexible.\n\n\nHowever, they both require:\n\nquite a bit of code for complex simulations (‚Äúcomplex‚Äù is relative, of course)\nrelatively high confidence in programming\n\n\n\n\n\n\nOur exercises will focus on the slendr simulation toolkit for population genetics in R.\n\n\n\n\n\nBut, as a recap, let‚Äôs look at msprime and SLiM a little bit‚Ä¶",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#section-1",
    "href": "handouts_slendr.html#section-1",
    "title": "Introduction to slendr",
    "section": "",
    "text": "What is msprime?\n\n\nA Python module for writing coalescent simulations\nExtremely fast (genome-scale, population-scale data!)\nYou should know Python fairly well to build complex models\n\n\n\n\n\n\nImage modified from Alexei Drummond",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#simple-simulation-using-msprime",
    "href": "handouts_slendr.html#simple-simulation-using-msprime",
    "title": "Introduction to slendr",
    "section": "Simple simulation using msprime",
    "text": "Simple simulation using msprime\n\n\nimport msprime\n\ndemography = msprime.Demography()\ndemography.add_population(name=\"A\", initial_size=10_000)\ndemography.add_population(name=\"B\", initial_size=5_000)\ndemography.add_population(name=\"C\", initial_size=1_000)\ndemography.add_population_split(time=1000, derived=[\"A\", \"B\"], ancestral=\"C\")\n\nts = msprime.sim_ancestry(\n  sequence_length=10e6,\n  recombination_rate=1e-8,\n  samples={\"A\": 100, \"B\": 100},\n  demography=demography\n)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#section-2",
    "href": "handouts_slendr.html#section-2",
    "title": "Introduction to slendr",
    "section": "",
    "text": "What is SLiM?\n\n\nA forward-time simulator\nHas its own programming language\nMassive library of functions for:\n\ndemographic events\nvarious mating systems\nnatural selection\n\nMore than 700 pages long manual!\n\n\n\n\n\n\nImage modified from Alexei Drummond",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#simple-neutral-simulation-in-slim",
    "href": "handouts_slendr.html#simple-neutral-simulation-in-slim",
    "title": "Introduction to slendr",
    "section": "Simple neutral simulation in SLiM",
    "text": "Simple neutral simulation in SLiM\n\n\ninitialize() {\n    // create a neutral mutation type\n    initializeMutationType(\"m1\", 0.5, \"f\", 0.0);\n\n    // initialize 1Mb segment\n    initializeGenomicElementType(\"g1\", m1, 1.0);\n    initializeGenomicElement(g1, 0, 999999);\n\n    // set mutation rate and recombination rate of the segment\n    initializeMutationRate(1e-8);\n    initializeRecombinationRate(1e-8);\n}\n\n// create an ancestral population p1 of 10000 diploid individuals\n1 early() { sim.addSubpop(\"p1\", 10000); }\n\n// in generation 1000, create two daughter populations p2 and p3\n1000 early() {\n    sim.addSubpopSplit(\"p2\", 5000, p1);\n    sim.addSubpopSplit(\"p3\", 1000, p1);\n}\n\n// in generation 10000, stop the simulation and save 100 individuals\n// from p2 and p3 to a VCF file\n10000 late() {\n    p2_subset = sample(p2.individuals, 100);\n    p3_subset = sample(p3.individuals, 100);\n    c(p2_subset, p3_subset).genomes.outputVCF(\"/tmp/slim_output.vcf.gz\");\n\n    sim.simulationFinished();\n}",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#so-why-slendr",
    "href": "handouts_slendr.html#so-why-slendr",
    "title": "Introduction to slendr",
    "section": "‚Ä¶ so why slendr?",
    "text": "‚Ä¶ so why slendr?\n\n\n\nwww.slendr.net",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#first-motivation-spatial-simulations",
    "href": "handouts_slendr.html#first-motivation-spatial-simulations",
    "title": "Introduction to slendr",
    "section": "First motivation: spatial simulations!",
    "text": "First motivation: spatial simulations!",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#a-broader-motivation-for-slendr",
    "href": "handouts_slendr.html#a-broader-motivation-for-slendr",
    "title": "Introduction to slendr",
    "section": "A broader motivation for slendr",
    "text": "A broader motivation for slendr\n\nMost researchers are not expert programmers\nAll but the most trivial simulations require lots of code\n\n\n\nYet, 90% [citation needed] of simulations are basically the same!\n\ncreate populations (splits and \\(N_e\\) changes)\nspecify admixture rates and admixture times\n\n‚Ä¶ all this means duplication of code across many projects\n\n\n\n\nComputing statistics presents even more hurdles\n\n\n\n\n\nslendr makes this very easy, even for ‚Äúcomplex models‚Äù",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#typical-slendr-workflow",
    "href": "handouts_slendr.html#typical-slendr-workflow",
    "title": "Introduction to slendr",
    "section": "Typical slendr workflow",
    "text": "Typical slendr workflow\nWe will always start our R scripts with this:\n\nlibrary(slendr) # You can safely ignore any potential warnings!\ninit_env()      # This activates the internal Python environmet\n\nFollowed by some combination of the following:\n\ncreating populations\nprogramming \\(N_e\\) size changes\nencoding gene-flow events\nsimulating genomic data\ncomputing popgen statistics",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#creating-populations",
    "href": "handouts_slendr.html#creating-populations",
    "title": "Introduction to slendr",
    "section": "Creating populations",
    "text": "Creating populations\nAt minimum, we need its name, size and ‚Äútime of appearance‚Äù:\n\npop1 &lt;- population(\"pop1\", N = 1000, time = 1)\n\n\nThis creates a normal R object! Typing it out gives a summary:\n\npop1\n\nslendr 'population' object \n-------------------------- \nname: pop1 \nnon-spatial population\nstays until the end of the simulation\n\npopulation history overview:\n  - time 1: created as an ancestral population (N = 1000)\n\n\n\n\n\nNote: Because slendr uses either msprime or SLiM internally for simulation of genomic data, all individuals are assumed to be diploid.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#programming-population-splits",
    "href": "handouts_slendr.html#programming-population-splits",
    "title": "Introduction to slendr",
    "section": "Programming population splits",
    "text": "Programming population splits\nSplits are defined by providing a parent = &lt;pop&gt; argument:\n\npop2 &lt;- population(\"pop2\", N = 100, time = 50, parent = pop1)\n\n\n\nNote: Here pop1 is an R object created above, not a string \"pop1\"!\n\nThe split is again reported in the ‚Äúhistorical summary‚Äù:\n\npop2\n\nslendr 'population' object \n-------------------------- \nname: pop2 \nnon-spatial population\nstays until the end of the simulation\n\npopulation history overview:\n  - time 50: split from pop1 (N = 100)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#scheduling-resize-events",
    "href": "handouts_slendr.html#scheduling-resize-events",
    "title": "Introduction to slendr",
    "section": "Scheduling resize events",
    "text": "Scheduling resize events\n\nStep size decrease:\n\n\npop1 &lt;- population(\"pop1\", N = 1000, time = 1)\npop1_step &lt;- resize(pop1, N = 100, time = 500, how = \"step\")\n\n\n\nExponential increase:\n\n\npop2 &lt;- population(\"pop2\", N = 100, time = 50, parent = pop1)\npop2_exp &lt;- resize(pop2, N = 10000, time = 500, end = 2000, how = \"exponential\")",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#tidyverse-style-pipe-interface",
    "href": "handouts_slendr.html#tidyverse-style-pipe-interface",
    "title": "Introduction to slendr",
    "section": "Tidyverse-style pipe %>% interface",
    "text": "Tidyverse-style pipe %&gt;% interface\nThe following leads to a more concise (and ‚Äúelegant‚Äù) code.\n\nStep size decrease:\n\n\npop1 &lt;-\n  population(\"pop1\", N = 1000, time = 1) %&gt;%\n  resize(N = 100, time = 500, how = \"step\")\n\n\nExponential increase:\n\n\npop2 &lt;-\n  population(\"pop2\", N = 1000, time = 1) %&gt;%\n  resize(N = 10000, time = 500, end = 2000, how = \"exponential\")\n\n\n\nNote: You can read (and understand) a() %&gt;% b() %&gt;% c() as ‚Äútake the result of the function a, pipe it into function b, and then pipe that to function c‚Äù.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#a-more-complex-model",
    "href": "handouts_slendr.html#a-more-complex-model",
    "title": "Introduction to slendr",
    "section": "A more complex model",
    "text": "A more complex model\nUsing just the two functions introduced so far:\n\npop1 &lt;- population(\"pop1\", N = 1000, time = 1)\n\npop2 &lt;-\n  population(\"pop2\", N = 1000, time = 300, parent = pop1) %&gt;%\n  resize(N = 100, how = \"step\", time = 1000)\n\npop3 &lt;-\n  population(\"pop3\", N = 1000, time = 400, parent = pop2) %&gt;%\n  resize(N = 2500, how = \"step\", time = 800)\n\npop4 &lt;-\n  population(\"pop4\", N = 1500, time = 500, parent = pop3) %&gt;%\n  resize(N = 700, how = \"exponential\", time = 1200, end = 2000)\n\npop5 &lt;-\n  population(\"pop5\", N = 100, time = 600, parent = pop4) %&gt;%\n  resize(N = 50, how = \"step\", time = 900) %&gt;%\n  resize(N = 1000, how = \"exponential\", time = 1600, end = 2200)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#again-each-object-carries-its-history",
    "href": "handouts_slendr.html#again-each-object-carries-its-history",
    "title": "Introduction to slendr",
    "section": "Again, each object carries its history!",
    "text": "Again, each object carries its history!\nFor instance, this is the summary you will get from the last population from the previous code chunk:\n\npop5\n\nslendr 'population' object \n-------------------------- \nname: pop5 \nnon-spatial population\nstays until the end of the simulation\n\npopulation history overview:\n  - time 600: split from pop4 (N = 100)\n  - time 900: resize from 100 to 50 individuals\n  - time 1600-2200: exponential resize from 50 to 1000 individuals\n\n\n\nThis way, you can build up complex models step by step, checking things as you go by interacting with the R console.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#gene-flow-admixture",
    "href": "handouts_slendr.html#gene-flow-admixture",
    "title": "Introduction to slendr",
    "section": "Gene flow / admixture",
    "text": "Gene flow / admixture\nWe can schedule gene flow from pop1 into pop2 with:\n\ngf &lt;- gene_flow(from = pop1, to = pop2, start = 2000, end = 2200, rate = 0.13)\n\n\n\nNote: Here rate = 0.13 means 13% migrants over the given time window will come from ‚Äúpop1‚Äù into ‚Äúpop2‚Äù.\n\n\nMultiple gene-flow events can be gathered in a list:\n\ngf &lt;- list(\n  gene_flow(from = pop1, to = pop2, start = 500, end = 600, rate = 0.13),\n  gene_flow(from = ..., to = ..., start = ..., end = ..., rate = ...),\n  ...\n)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#model-compilation",
    "href": "handouts_slendr.html#model-compilation",
    "title": "Introduction to slendr",
    "section": "Model compilation",
    "text": "Model compilation\n\nThis is the final step before we can simulate data.\n\n\nmodel &lt;- compile_model(\n  populations = list(pop1, pop2, pop3, pop4, pop5),\n  generation_time = 1,       # (converts the all times into generations)\n  simulation_length = 3000,  # (number of generations to run the simulation for)\n  direction = \"forward\"      # (not totally necessary but good practice)\n)\n\n\n\ncompile_model() takes a list of components, performs some consistency checks, and returns a single R object",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#model-compilation-1",
    "href": "handouts_slendr.html#model-compilation-1",
    "title": "Introduction to slendr",
    "section": "Model compilation",
    "text": "Model compilation\n\nThis is the final step before we can simulate data.\n\n\nmodel &lt;- compile_model(\n  populations = list(pop1, pop2, pop3, pop4, pop5),\n  gene_flow = gf,      # &lt;----- in case our model includes gene flow(s)\n  generation_time = 1,\n  simulation_length = 3000,\n  direction = \"forward\"\n)\n\n\n\nGene flow(s) can be included via the gene_flow argument.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#model-summary",
    "href": "handouts_slendr.html#model-summary",
    "title": "Introduction to slendr",
    "section": "Model summary",
    "text": "Model summary\nTyping the compiled model into R prints a brief summary:\n\nmodel\n\nslendr 'model' object \n--------------------- \npopulations: pop1, pop2, pop3, pop4, pop5 \ngeneflow events: 1 \ngeneration time: 1 \ntime direction: forward \ntime units: generations \ntotal running length: 3000 time units\nmodel type: non-spatial\n\nconfiguration files in: /private/var/folders/h2/qs0z_44x2vn2sskqc0cct7540000gn/T/Rtmph394wJ/file16d5c1d744862_slendr_model \n\n\nThis can be useful as a quick overview of the model we are working with. However, a better way to check a model is‚Ä¶",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#model-visualization",
    "href": "handouts_slendr.html#model-visualization",
    "title": "Introduction to slendr",
    "section": "Model visualization",
    "text": "Model visualization\n\nplot_model(model)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#forward-time-units",
    "href": "handouts_slendr.html#forward-time-units",
    "title": "Introduction to slendr",
    "section": "‚ÄúForward time units‚Äù",
    "text": "‚ÄúForward time units‚Äù\n\npop1 &lt;- population(\"pop1\", N = 1000, time = 1)\n\npop2 &lt;-\n  population(\"pop2\", N = 1000, time = 300, parent = pop1) %&gt;%\n  resize(N = 100, how = \"step\", time = 1000)\n\npop3 &lt;-\n  population(\"pop3\", N = 1000, time = 400, parent = pop2) %&gt;%\n  resize(N = 2500, how = \"step\", time = 800)\n\npop4 &lt;-\n  population(\"pop4\", N = 1500, time = 500, parent = pop3) %&gt;%\n  resize(N = 700, how = \"exponential\", time = 1200, end = 2000)\n\npop5 &lt;-\n  population(\"pop5\", N = 100, time = 600, parent = pop4) %&gt;%\n  resize(N = 50, how = \"step\", time = 900) %&gt;%\n  resize(N = 1000, how = \"exponential\", time = 1600, end = 2200)\n\nmodel &lt;- compile_model(\n  populations = list(pop1, pop2, pop3, pop4, pop5),\n  generation_time = 1,\n  simulation_length = 3000, # forward-time sims need an explicit end\n  direction = \"forward\"\n)\n\n\n\nWe started with pop1 in generation 1, with later events at an increasing time value.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#forward-time-units-1",
    "href": "handouts_slendr.html#forward-time-units-1",
    "title": "Introduction to slendr",
    "section": "‚ÄúForward time units‚Äù",
    "text": "‚ÄúForward time units‚Äù\n\nplot_model(model) # see time progressing from generation 1 forwards\n\n\n\n\n\n\n\n\n\n\nWe started with pop1 in generation 1, with later events at an increasing time value.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#backward-time-units",
    "href": "handouts_slendr.html#backward-time-units",
    "title": "Introduction to slendr",
    "section": "‚ÄúBackward time units‚Äù",
    "text": "‚ÄúBackward time units‚Äù\n\npop1 &lt;- population(\"pop1\", N = 1000, time = 30000)\n\npop2 &lt;-\n  population(\"pop2\", N = 1000, time = 27000, parent = pop1) %&gt;%\n  resize(N = 100, how = \"step\", time = 20000)\n\npop3 &lt;-\n  population(\"pop3\", N = 1000, time = 26000, parent = pop2) %&gt;%\n  resize(N = 2500, how = \"step\", time = 22000)\n\npop4 &lt;-\n  population(\"pop4\", N = 1500, time = 25000, parent = pop3) %&gt;%\n  resize(N = 700, how = \"exponential\", time = 18000, end = 10000)\n\npop5 &lt;-\n  population(\"pop5\", N = 100, time = 24000, parent = pop4) %&gt;%\n  resize(N = 50, how = \"step\", time = 21000) %&gt;%\n  resize(N = 1000, how = \"exponential\", time = 14000, end = 8000)\n\nmodel &lt;- compile_model(\n  populations = list(pop1, pop2, pop3, pop4, pop5),\n  generation_time = 10 # (10 time units for each generation)\n  # (we don't need to provide `simulation_length =` because\n  # \"backwards\" models end at time 0 by default, i.e. \"present-day\")\n)\n\n\n\nSame model as before, except now expressed in units of ‚Äúyears before present‚Äù.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#backward-time-units-1",
    "href": "handouts_slendr.html#backward-time-units-1",
    "title": "Introduction to slendr",
    "section": "‚ÄúBackward time units‚Äù",
    "text": "‚ÄúBackward time units‚Äù\n\nplot_model(model) # see time progressing from \"year\" 30000 backwards\n\n\n\n\n\n\n\n\n\n\nSame model as before, except now expressed in units of ‚Äúyears before present‚Äù.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#built-in-simulation-engines",
    "href": "handouts_slendr.html#built-in-simulation-engines",
    "title": "Introduction to slendr",
    "section": "Built-in simulation ‚Äúengines‚Äù",
    "text": "Built-in simulation ‚Äúengines‚Äù\nslendr has two simulation ‚Äúengine scripts‚Äù built-in:\n\nmsprime engine (slendr source) ‚Äì R function msprime()\nSLiM engine (slendr source) ‚Äì R function slim()\n\n\nThey are designed to ‚Äúunderstand‚Äù slendr models, meaning that you can simulate data just with this command:\n\nts &lt;- msprime(model, sequence_length = 10e6, recombination_rate = 1e-8)\n\n\n\n\n\n\nNo need to write any msprime or SLiM code!",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#what-is-tree-sequence",
    "href": "handouts_slendr.html#what-is-tree-sequence",
    "title": "Introduction to slendr",
    "section": "What is tree sequence?",
    "text": "What is tree sequence?\n\n\n\n\n\n\na record of full genetic ancestry of a set of samples\nan encoding of DNA sequence carried by those samples\nan efficient analysis framework",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#what-we-usually-have",
    "href": "handouts_slendr.html#what-we-usually-have",
    "title": "Introduction to slendr",
    "section": "What we usually have",
    "text": "What we usually have",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#what-we-usually-want",
    "href": "handouts_slendr.html#what-we-usually-want",
    "title": "Introduction to slendr",
    "section": "What we usually want",
    "text": "What we usually want\nAn understanding of our samples‚Äô evolutionary history:\n\n\n\n\n\n\nThis is exactly what a tree sequence is!\n\n\n\n\n\nImage from the tskit documentation",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#the-magic-of-tree-sequences",
    "href": "handouts_slendr.html#the-magic-of-tree-sequences",
    "title": "Introduction to slendr",
    "section": "The magic of tree sequences",
    "text": "The magic of tree sequences\nThey allow us to compute statistics without genotypes!\n\n\n\nThere is a ‚Äúduality‚Äù between mutations and branch lengths.\n\n\nNote: See an amazing paper by Ralph et al. (2020) for more detail.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#what-if-we-need-mutations-though",
    "href": "handouts_slendr.html#what-if-we-need-mutations-though",
    "title": "Introduction to slendr",
    "section": "What if we need mutations though?",
    "text": "What if we need mutations though?",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#what-if-we-need-mutations-though-1",
    "href": "handouts_slendr.html#what-if-we-need-mutations-though-1",
    "title": "Introduction to slendr",
    "section": "What if we need mutations though?",
    "text": "What if we need mutations though?\nCoalescent and mutation processes can be decoupled!\n\n\n\n\nThis means we can add mutations to ts after the simulation using ts_mutate().",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#lets-go-back-to-our-example-model",
    "href": "handouts_slendr.html#lets-go-back-to-our-example-model",
    "title": "Introduction to slendr",
    "section": "Let‚Äôs go back to our example model‚Ä¶",
    "text": "Let‚Äôs go back to our example model‚Ä¶\n\nplot_model(model)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#simulate-a-tree-sequence",
    "href": "handouts_slendr.html#simulate-a-tree-sequence",
    "title": "Introduction to slendr",
    "section": "‚Ä¶ simulate a tree sequence‚Ä¶",
    "text": "‚Ä¶ simulate a tree sequence‚Ä¶\n\nIn our script we‚Äôll have something like this:\n\nlibrary(slendr)\ninit_env()\n\n# &lt;... population() definitions ...&gt;\n\n# &lt;... gene_flow() definition ...&gt;\n\n# &lt;... compile_model(...) ...&gt;\n  \nts &lt;-\n  msprime(model, sequence_length = 50e6, recombination_rate = 1e-8)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#and-overlay-mutations-on-it",
    "href": "handouts_slendr.html#and-overlay-mutations-on-it",
    "title": "Introduction to slendr",
    "section": "‚Ä¶ and overlay mutations on it",
    "text": "‚Ä¶ and overlay mutations on it\n\nIn our script we‚Äôll have something like this:\n\nlibrary(slendr)\ninit_env()\n\n# &lt;... population() definitions ...&gt;\n\n# &lt;... gene_flow() definition ...&gt;\n\n# &lt;... compile_model(...) ...&gt;\n  \nts &lt;-\n  msprime(model, sequence_length = 50e6, recombination_rate = 1e-8) %&gt;%\n  ts_mutate(mutation_rate = 1e-8)\n\n\n\nNote: In some exercises, mutations won‚Äôt be necessary. Where we will need them, you can use ts_mutate() using the pattern shown here.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#slendrs-r-interface-to-tskit-statistics",
    "href": "handouts_slendr.html#slendrs-r-interface-to-tskit-statistics",
    "title": "Introduction to slendr",
    "section": "slendr‚Äôs R interface to tskit statistics",
    "text": "slendr‚Äôs R interface to tskit statistics\n\n\n\nAllele-frequecy spectrum, \\(\\pi\\), \\(f\\)-statistics, \\(F_{ST}\\), Tajima‚Äôs D, etc.\nFind help at slendr.net/reference or in R under ?ts_fst etc.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#extracting-names-of-recorded-samples",
    "href": "handouts_slendr.html#extracting-names-of-recorded-samples",
    "title": "Introduction to slendr",
    "section": "Extracting names of recorded samples",
    "text": "Extracting names of recorded samples\n\nWe can get individuals recorded in ts with ts_samples():\n\n\nts_samples(ts) %&gt;% head(1) # returns a data frame (one row here, for brevity)\n\n\n\n    name time  pop\n1 pop1_1 3001 pop1\n\n\n\n\nA shortcut ts_names() can also be useful:\n\n\nts_names(ts) %&gt;% head(5) # returns a vector of individuals' names\n\n[1] \"pop1_1\" \"pop1_2\" \"pop1_3\" \"pop1_4\" \"pop1_5\"\n\n\n\n\n\nWe can get a per-population list of individuals like this:\n\n\nts_names(ts, split = \"pop\") # returns a named list of such vectors\n\n\n\n$pop1\n[1] \"pop1_411\" \"pop1_417\" \"pop1_972\" \"pop1_331\" \"pop1_561\"",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#tskit-computation-option-1",
    "href": "handouts_slendr.html#tskit-computation-option-1",
    "title": "Introduction to slendr",
    "section": "tskit computation ‚Äì option #1",
    "text": "tskit computation ‚Äì option #1\nFor a function which operates on one set of individuals, we can first get a vector of names to compute on like this:\n\n# a random selection of names of three individuals in a tree sequence\nsamples &lt;- c(\"popX_1\", \"popX_2\", \"popY_42\")\n\n\n\nThen we can calculate the statistic of interest like this:\n\n# this computes nucleotide diversity in our set of individuals\ndf_result &lt;- ts_diversity(ts, sample_sets = list(samples))\n\n\n\n\nNote: Wherever you see list(&lt;vector of names&gt;), you can think of it as ‚Äúcompute a statistic for the entire group of individuals‚Äù (you get a single number). Without the list(), it would mean ‚Äúcompute the statistic for each individual separately‚Äù (and get a value for each of them individually).",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#tskit-computation-option-2",
    "href": "handouts_slendr.html#tskit-computation-option-2",
    "title": "Introduction to slendr",
    "section": "tskit computation ‚Äì option #2",
    "text": "tskit computation ‚Äì option #2\nFor a function operating on multiple sets of individuals, we want a list of vectors of names (one such vector per group):\n\n# when we compute on multiple groups, it's a good idea to name them\nsamples &lt;- list(\n  popX = c(\"popX_1\", \"popX_2\", \"popX_3\"),\n  popY = c(\"popY_1\", \"popY_2\", \"popY_3\"),\n  popZ = c(\"popZ_1\", \"popZ_2\")\n)\n\n\nThen we use this list of vectors in the same way as before:\n\n# this computes a pairwise divergence between all three groups\ndf_result &lt;- ts_divergence(ts, sample_sets = samples)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#tskit-computation-option-3",
    "href": "handouts_slendr.html#tskit-computation-option-3",
    "title": "Introduction to slendr",
    "section": "tskit computation ‚Äì option #3",
    "text": "tskit computation ‚Äì option #3\nFor something like \\(f\\) statistics, the function arguments must be more precisely specified (here A, B, C, not sample_sets):\n\ndf_result &lt;- ts_f3(\n  ts,\n  A = c(\"popX_1\", \"popX_2\", \"popX_3\"),\n  B = c(\"popY_1\", \"popY_2\", \"popY_3\"),\n  C = c(\"popZ_1\", \"popZ_2\")\n)\n\n\nDoing this manually can be annoying ‚Äî ts_names() helps by preparing the list of names in the correct format:\n\n# get names of individuals in each population as a named list of vectors\nsamples &lt;- ts_names(ts, split = \"pop\")\n\n# use this list directly by specifying which vectors to take out\nts_f3(ts, A = samples$popX, B = samples$popY, C = samples$popZ)",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#example-nucleotide-diversity",
    "href": "handouts_slendr.html#example-nucleotide-diversity",
    "title": "Introduction to slendr",
    "section": "Example: nucleotide diversity",
    "text": "Example: nucleotide diversity\n\n\nGet a list of individuals in each population:\n\nsamples &lt;- ts_names(ts, split = \"pop\")\n\nnames(samples)\n\n[1] \"pop1\" \"pop2\"\n\n\n\n\nWe can index into the list via population name:\n\nsamples$pop1\n\n\n\n[1] \"pop1_1\" \"pop1_2\" \"pop1_3\"\n\n\n\nsamples$pop2\n\n\n\n[1] \"pop2_1\" \"pop2_2\" \"pop2_3\"\n\n\n\n\n¬†\n\n\nCompute nucleotide diversity (note the list samples):\n\nts_diversity(ts, sample_sets = samples)\n\n# A tibble: 2 √ó 2\n  set   diversity\n  &lt;chr&gt;     &lt;dbl&gt;\n1 pop1  0.000392 \n2 pop2  0.0000572\n\n\n\nOur tree sequence had two populations, pop1 and pop2, which is why we get a data frame with diversity in each of them.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#example-allele-frequency-spectrum",
    "href": "handouts_slendr.html#example-allele-frequency-spectrum",
    "title": "Introduction to slendr",
    "section": "Example: allele frequency spectrum",
    "text": "Example: allele frequency spectrum\n\n\nGet names of individuals:\n\nsamples &lt;- ts_names(ts)[1:5]\nsamples\n\n[1] \"pop_1\" \"pop_2\" \"pop_3\" \"pop_4\" \"pop_5\"\n\n\n\nCompute the AFS:\n\nafs &lt;- ts_afs(ts, sample_sets = list(samples))\n\n# we skip the 1st item because it has a special meaning in tskit\nafs[-1]\n\n [1] 3917 2151 1432  941  740  624  607  587  416  385\n\n\n\n\n¬†\n\n\n\nplot(afs[-1], type = \"b\",\n     xlab = \"allele count bin\",\n     ylab = \"frequency\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: One of the rare examples when a slendr / tskit statistical function does not return a data frame (ts_afs() returns a numerical vector, not a data frame).",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#tree-sequence-tables",
    "href": "handouts_slendr.html#tree-sequence-tables",
    "title": "Introduction to slendr",
    "section": "Tree sequence tables",
    "text": "Tree sequence tables\n\nThis simulates 2 \\(\\times\\) 10000 chromosomes of 100 Mb:\n\nlibrary(slendr)\ninit_env(quiet = FALSE)\n\npop &lt;- population(\"pop\", time = 100e6, N = 10000)\nmodel &lt;- compile_model(pop, generation_time = 30, direction = \"backward\")\nts &lt;- msprime(model, sequence_length = 1e6, recombination_rate = 1e-8)\n\n\n\nThe interface to all required Python modules has been activated.\n\n\n\nRuns in less than 30 seconds on my laptop!\nTakes only about 66 Mb of memory!",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#how-is-this-even-possible",
    "href": "handouts_slendr.html#how-is-this-even-possible",
    "title": "Introduction to slendr",
    "section": "How is this even possible?!",
    "text": "How is this even possible?!",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#tree-sequence-tables-1",
    "href": "handouts_slendr.html#tree-sequence-tables-1",
    "title": "Introduction to slendr",
    "section": "Tree-sequence tables",
    "text": "Tree-sequence tables\n\n\n\nA tree can be represented by\n\n\na table of nodes,\na table of edges between nodes,\na table of mutations on edges\n\n\n\n\n\n\n\n\n\n\n\nA collection of such tables is a tree sequence.\n\n\n\nNote: This is a huge oversimplification. Find more information in tskit docs.",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#tree-sequence-tables-in-practice",
    "href": "handouts_slendr.html#tree-sequence-tables-in-practice",
    "title": "Introduction to slendr",
    "section": "Tree-sequence tables in practice",
    "text": "Tree-sequence tables in practice\n\n\n\n\n\n\n\n\n\n\n\n\nNodes:\n\n\n  node     time\n1  360 871895.1\n2  256 475982.3\n3  255 471179.5\n\n\n\n\n\nEdges:\n\n\n  child parent\n1   256    360\n2   255    256\n3    69    256\n\n\n\n\n\nMutations:\n\n\n   id node     time\n1  69   74 125539.4\n2 272   22 242337.9\n3 277   22 129474.1",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "handouts_slendr.html#standard-genotype-formats",
    "href": "handouts_slendr.html#standard-genotype-formats",
    "title": "Introduction to slendr",
    "section": "Standard genotype formats",
    "text": "Standard genotype formats\nIf a tree sequence doesn‚Äôt cut it, you can always‚Ä¶\n\n\nexport genotypes to a VCF file:\n\n\nts_vcf(ts, path = \"path/to/a/file.vcf.gz\")\n\n\n\n\nexport genotypes in the EIGENSTRAT format:\n\n\nts_eigenstrat(ts, prefix = \"path/to/eigenstrat/prefix\")\n\n\n\n\naccess genotypes as a data frame:\n\n\nts_genotypes(ts)\n\n\n\n    pos pop_1_chr1 pop_1_chr2 pop_2_chr1 pop_2_chr2 pop_3_chr1 pop_3_chr2\n1 12977          0          1          0          0          0          0\n2 15467          1          0          1          1          1          1",
    "crumbs": [
      "Handouts",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "acknowledgements.html",
    "href": "acknowledgements.html",
    "title": "Acknowledgements",
    "section": "",
    "text": "This course is being developed as part of a collaboration between University of Tartu and University of Copenhagen (Twinning project ECHO: Expanding Concept and Methodology for Human Past Studies in the Eastern Baltic Region).",
    "crumbs": [
      "Acknowledgements"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Appendix A ‚Äî Installation",
    "section": "",
    "text": "Installation steps\nThis entire workshop is organized around the population genetic simulation R package called slendr and an assortment of other useful R packages for data science, all of which will be automatically installed alongside slendr.\nThe primary goal for the course is to make you comfortable programming complete simulation and modeling scripts from scratch, entirely on your own. Even if you‚Äôve never ‚Äúreally programmed‚Äù before, it‚Äôs not a problem. By the end of this workshop, you will all be programmers!\nPlease don‚Äôt hesitate to get in touch with me over email at contact [snail sign] bodkan.net if you run into any problems with this setup procedure or with anything else related to the workshop! You can also catch me whenever you see me in the teaching venue.\ninstall.packages(\"slendr\")\nSys.setenv(CONDA_PLUGINS_AUTO_ACCEPT_TOS = \"yes\")\n\nslendr::setup_env(agree = TRUE)\nIf everything worked, you should get an optimistic message at the end of the entire procedure saying:\nlibrary(slendr)\ninit_env()\n## The interface to all required Python modules has been activated.\n\nA &lt;- population(\"popA\", time = 8000, N = 1000)\nB &lt;- population(\"popB\", time = 4000, N = 1000, parent = A)\nC &lt;- population(\"popC\", time = 4000, N = 1000, parent = A)\nD &lt;- population(\"popD\", time = 3000, N = 1000, parent = C)\n\ngf &lt;- list(\n  gene_flow(from = B, to = D, start = 1000, end = 800, rate = 0.2),\n  gene_flow(from = C, to = D, start = 1000, end = 800, rate = 0.1)\n)\n\nmodel &lt;- compile_model(\n  populations = list(A, B, C, D),\n  gene_flow = gf, generation_time = 30\n)\n\nts &lt;- msprime(model, sequence_length = 1e6, recombination_rate = 1e-8)\nts\n## ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n## ‚ïëTreeSequence               ‚ïë\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n## ‚ïëTrees          ‚îÇ        850‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëSequence Length‚îÇ  1,000,000‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëTime Units     ‚îÇgenerations‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëSample Nodes   ‚îÇ      8,000‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëTotal Size     ‚îÇ    1.4 MiB‚ïë\n## ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n## ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n## ‚ïëTable      ‚îÇRows  ‚îÇSize     ‚îÇHas Metadata‚ïë\n## ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n## ‚ïëEdges      ‚îÇ20,052‚îÇ626.6 KiB‚îÇ          No‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëIndividuals‚îÇ 4,000‚îÇ109.4 KiB‚îÇ          No‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëMigrations ‚îÇ     0‚îÇ  8 Bytes‚îÇ          No‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëMutations  ‚îÇ     0‚îÇ 16 Bytes‚îÇ          No‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëNodes      ‚îÇ17,498‚îÇ478.5 KiB‚îÇ          No‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëPopulations‚îÇ     4‚îÇ343 Bytes‚îÇ         Yes‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëProvenances‚îÇ     1‚îÇ  2.8 KiB‚îÇ          No‚ïë\n## ‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢\n## ‚ïëSites      ‚îÇ     0‚îÇ 16 Bytes‚îÇ          No‚ïë\n## ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\nThe outcome of this script should approximately match what you see above (minus some statistical noise manifesting in your numbers in the summary being slightly different).\nIn order to be able to run my own solutions to some of the exercises (particularly some more advanced bonus exercises which will be entirely optional, and we very likely won‚Äôt have time to go through during the short span of the worksop), a couple of additional R packages might be useful.\nYou can install those like this:\ninstall.packages(c(\"combinat\", \"cowplot\"))\nIf you‚Äôve made it this far, you‚Äôre good to go!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "setup.html#installation-steps",
    "href": "setup.html#installation-steps",
    "title": "Appendix A ‚Äî Installation",
    "section": "",
    "text": "Note: It will be great if you do this setup on your personal laptop. Getting everything to run locally is often much easier than trying to install things on shared clusters or other HPC environments.\n\nI assume you already have R and RStudio installed on your computer (any version will do).\nOpen RStudio and copy this into the R console to install the slendr package:\n\n\n\n\nNote: If you get an error during the installation, please copy-and-paste the entire output from this command and send it to me via email.\n\nAfter you have slendr successfuly installed, create a dedicated Python environment which it internally uses for simulation and tree-sequence analysis by typing this into the R console again:\n\n\n\n======================================================================\nPython environment for slendr has been successfuly created, and the R\ninterface to msprime, tskit, and pyslim modules has been activated.\n\nIn future sessions, activate this environment by calling init_env().\n=======================================================================\n\n\n\n\n\n\nClick here if running setup_env() fails\n\n\n\n\n\nIf the setup_env() installation procedure above fails, try the following:\n\nDelete the failed installation attempt:\n\n\nslendr::clear_env(force = TRUE, all = TRUE)\n\n\nRestart R by clicking (in RStudio) on Session -&gt; Restart R.\nTry installing it again, this time using pip as a Python installation method (the default is conda which unfortunately fails fairly often):\n\n\nslendr::setup_env(agree = TRUE, pip = TRUE)\n\n\n\n\n\n\nNote: If you still get an error during the installation, please copy-and-paste the entire output from this command and send it to me via email. Or just grab me whenever you see me in person!\n\nPaste this little testing slendr simulation script into the R console to make sure that everything works correctly. Don‚Äôt read too much into the meaning of the code, understanding (and being able to program) all this and more will be the point of our workshop.\n\n\n\nNote: If you managed to successfully run the installation steps 1-3 above, this simulation should finish running without any problems. If it does not work, then there‚Äôs something strange going on. Please copy-and-paste the entire output this script produces in your R console (including the error) and send it to me via email.\n\n\n\nInstalling a couple of bonus R packages",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Appendix B ‚Äî Slides",
    "section": "",
    "text": "Here is a list of links to online version of slides we went through when introducing each chapter before moving to the exercises. This is provided mostly for completeness ‚Äì when working on the exercises, the single-page versions of these slides (available under the Handouts](https://bodkan.net/simgen/handouts.html) heading will be probably more useful.\n\nIntroduction to slendr ‚Äì link",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Slides</span>"
    ]
  }
]