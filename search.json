[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simulation-Based Population Genomics and Inference in R",
    "section": "",
    "text": "Preface\nThis online book contains materials for a work-in-progress course on the fundamentals of population genomics and statistical inference, with a strong focus on good practices of reproducible research.\nIt is being developed as part of the collaboration between University of Tartu and University of Copenhagen (Twinning project ECHO: Expanding Concept and Methodology for Human Past Studies in the Eastern Baltic Region).\nThe git repository containing the sources of all materials for the entire course (which will be developed over the span of 2025-2026) are available on GitHub at https://github.com/bodkan/simgen. Ultimately, the book will provide resources which will become the basis of a 1-2 weeks long course on population genomics and statistical inference using computer simulations, with a particular focus on R packages slendr and demografr. While introducing the fundamentals of population genomics, it will also aim to frame the material with a strong focus on the most important tools for facilitating reproducible research (such as git and renv), as well as demonstrate the most useful applications of a selection of R packages from the tidyverse data science toolkit.\n\nThe work-in-progress rendering of the book is available at https://bodkan.github.io/simgen.\n\n\nCurrently planned outline\n\nR\n\nIntroduction to R\n\nBasic data types, vectors, list, data frames\nPlotting with built-in base R functions\n\nReproducible computing in R\n\nCreating self-contained R command-line scripts\nWhy is renv useful\n\nVersion of control with git and GitHub\nBasics of data science with tidyverse\n\ntibble, dplyr, tidyr, ggplot2\n\n\nslendr\n\nIntroduction to the slendr R package\nBuilding traditional demographic models with slendr\nSimulating genomic data\n\nWhat is a tree sequence?\nVCF files, EIGENSTRAT fileformat\n\n\nFundamentals of population genetics with slendr\n\nComputing tree sequence summary statistics\ndiversity, divergence, AFS\n\\(f\\)-statistics, \\(f_4\\)-ratio statistics\n\\(F_{st}\\)\nPCA\nIdentity-by-descent (IBD)\nAncestry tracts / chromosome painting\nAdmixture dating\n\nNatural selection with slendr\n\nBasic natural selection theory\nSimulating a simple\n\nSimulation-based inference with demografr\n\nToy grid-based inference of \\(N_e\\) with AFS\nGrid-based inference with demografr (\\(f_4\\) and \\(f_4\\)-ratio)\nGrid-based admixture tract dating\nApproximate Bayesian Computation (ABC)\nInference of selection using simulations\n\nIntroducing the workhorses of applied population genetics\n\nMDS / PCA\nADMIXTOOLS - \\(f\\)-statistics, qpAdm\nADMIXTURE / STRUCTURE\nIBD\n\n\n\nAll content is available under the CC BY-SA 4.0 license.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "TODO: Introduction to the course, why it exists, and why it exists in the presented form (R, slendr, demografr, and tidyverse).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "slendr.html",
    "href": "slendr.html",
    "title": "2  Introduction to slendr",
    "section": "",
    "text": "3 Organization of the exercises\nFor each exercise, you will get a brief explanation of the problem at hand and some information about functions that could be useful to solve the exercise. The concrete, specific task will be always written like this in bold. As you work on each part of each exercises, look for these bold lines.\nYour goal for each exercise is to write a complete R script script (in RStudio File -&gt; New file -&gt; R script). I suggest you save the script for each exercise as exercise1.R, exercise2.R, etc., just to keep things tidy and easy to troubleshoot if needed.\nEach exercise is composed of individual parts, which are designed to build one upon the other in the order they are specified. As you progress through sequential parts of each exercise, you will be adding code to your script for that exercise.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-1-computing-nucleotide-diversity",
    "href": "slendr.html#part-1-computing-nucleotide-diversity",
    "title": "2  Introduction to slendr",
    "section": "5.1 Part 1: Computing nucleotide diversity",
    "text": "5.1 Part 1: Computing nucleotide diversity\nThe toy model of ancient human history plotted above makes a fairly clear prediction of what would be the nucleotide diversity expected in the simulated populations. Compute the nucleotide diversity in all populations using the slendr function ts_diversity() in your tree sequence ts. Do you get numbers that (relatively between all populations) match what would expect from the model given the \\(N_e\\) that you programmed for each?\nHint: Nearly every slendr statistic function interfacing with tskit accepts a ts tree-sequence object as its first argument, with further arguments being either a vector of individual names representing a group of samples to compute a statistic on, or a (named) list of such vectors (each element of that list for a group of samples) – these lists are intended to be equivalent to the sample_sets = argument of many tskit Python methods (which you’ve learned about in your activity on tskit), except that they allow symbolic names of individuals, rather then integer indices of nodes in a tree sequence.\nAlthough you can get all the above information by processing the table produced by the ts_samples() function, slendr provides a useful helper function ts_names() which only returns the names of individuals as a vector (or a named list of such vectors, one vector per population as shown below).\nWhen you call it directly, you get a plain vector of individual names:\n\nts_names(ts)\n\n [1] \"NEA_1\"   \"EUR_1\"   \"NEA_2\"   \"EUR_2\"   \"EUR_3\"   \"EUR_4\"   \"EUR_5\"  \n [8] \"EUR_6\"   \"EUR_7\"   \"EUR_8\"   \"EUR_9\"   \"EUR_10\"  \"EUR_11\"  \"EUR_12\" \n[15] \"EUR_13\"  \"EUR_14\"  \"EUR_15\"  \"EUR_16\"  \"EUR_17\"  \"EUR_18\"  \"EUR_19\" \n[22] \"EUR_20\"  \"AFR_1\"   \"AFR_2\"   \"AFR_3\"   \"AFR_4\"   \"AFR_5\"   \"CHIMP_1\"\n[29] \"EUR_21\"  \"EUR_22\"  \"EUR_23\"  \"EUR_24\"  \"EUR_25\"  \"EUR_26\"  \"EUR_27\" \n[36] \"EUR_28\"  \"EUR_29\"  \"EUR_30\" \n\n\nThis is not super helpful, unless we want to compute some statistic for everyone in the tree sequence, regardless of their population assignment. Perhaps a bit more useful is to call the function like this, because it will produce a result which can be immediately used as the sample_sets = argument mentioned in the Hint above:\n\nts_names(ts, split = \"pop\")\n\n$AFR\n[1] \"AFR_1\" \"AFR_2\" \"AFR_3\" \"AFR_4\" \"AFR_5\"\n\n$CHIMP\n[1] \"CHIMP_1\"\n\n$EUR\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\"\n\n$NEA\n[1] \"NEA_1\" \"NEA_2\"\n\n\nAs you can see, this gave us a normal R list, with each element containing a vector of individual names in a population. Note that we can use standard R list indexing to get subsets of individuals:\n\nnames &lt;- ts_names(ts, split = \"pop\")\n\nnames[\"NEA\"]\n\n$NEA\n[1] \"NEA_1\" \"NEA_2\"\n\nnames[c(\"EUR\", \"NEA\")]\n\n$EUR\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\"\n\n$NEA\n[1] \"NEA_1\" \"NEA_2\"\n\n\netc.\nMany of the following exercises will use these kinds of tricks to instruct various slendr / tskit functions to compute statistics on subsets of all individuals sub-sampled in this way.\nAfter you computed nucleotide diversity per-population, compute it for each individual separately using the same function ts_diversity() (which, in this setting, gives you effectively the heterozygosity for each individual). If you are familiar with plotting in R, visualize the individual-based heterozygosities across all populations.\nHint: You can do this by giving a vector of names as sample_sets = (so not an R list of vectors). You could also use the data frame produced by ts_samples(ts) to get the names, just adding the heterozygosities to that data frame as a new column.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nPopulation-based nucleotide diversity:\n\n# Let's first get a named list of individuals in each group we want to be\n# working with (slendr tree-sequence statistic functions generally operate\n# with this kind of structure)\nsample_sets &lt;- ts_names(ts, split = \"pop\")\nsample_sets\n\n$AFR\n[1] \"AFR_1\" \"AFR_2\" \"AFR_3\" \"AFR_4\" \"AFR_5\"\n\n$CHIMP\n[1] \"CHIMP_1\"\n\n$EUR\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\"\n\n$NEA\n[1] \"NEA_1\" \"NEA_2\"\n\n# We can use such `sample_sets` object to compute nucleotide diversity (pi)\\\n# in each population, in a bit of a similar manner to how we would do it\n# with the standard tskit in Python\npi_pop &lt;- ts_diversity(ts, sample_sets = sample_sets)\narrange(pi_pop, diversity)\n\n# A tibble: 4 × 2\n  set   diversity\n  &lt;chr&gt;     &lt;dbl&gt;\n1 NEA   0.0000483\n2 CHIMP 0.000196 \n3 EUR   0.000510 \n4 AFR   0.000600 \n\n\nYou can see that this simple computation fits the extreme differences in long-term \\(N_e\\) encoded by your slendr demografr model.\nPer-individual heterozygosity:\nWe can do this by passing the vector of individual names directory as the sample_sets = argument, rather than in a list of groups as we did above.\n\n# For convenience, we first get a table of all individuals (which of course\n# contains also their names) and in the next step, we'll just add their\n# heterozygosities as a new column.\npi_df &lt;- ts_samples(ts)\npi_df$name\n\n [1] \"NEA_1\"   \"EUR_1\"   \"NEA_2\"   \"EUR_2\"   \"EUR_3\"   \"EUR_4\"   \"EUR_5\"  \n [8] \"EUR_6\"   \"EUR_7\"   \"EUR_8\"   \"EUR_9\"   \"EUR_10\"  \"EUR_11\"  \"EUR_12\" \n[15] \"EUR_13\"  \"EUR_14\"  \"EUR_15\"  \"EUR_16\"  \"EUR_17\"  \"EUR_18\"  \"EUR_19\" \n[22] \"EUR_20\"  \"AFR_1\"   \"AFR_2\"   \"AFR_3\"   \"AFR_4\"   \"AFR_5\"   \"CHIMP_1\"\n[29] \"EUR_21\"  \"EUR_22\"  \"EUR_23\"  \"EUR_24\"  \"EUR_25\"  \"EUR_26\"  \"EUR_27\" \n[36] \"EUR_28\"  \"EUR_29\"  \"EUR_30\" \n\npi_df$diversity &lt;- ts_diversity(ts, sample_sets = pi_df$name)$diversity\npi_df\n\n# A tibble: 38 × 4\n   name   time pop   diversity\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 NEA_1 70000 NEA   0.0000431\n 2 EUR_1 40000 EUR   0.000516 \n 3 NEA_2 40000 NEA   0.0000410\n 4 EUR_2 38000 EUR   0.000520 \n 5 EUR_3 36000 EUR   0.000539 \n 6 EUR_4 34000 EUR   0.000534 \n 7 EUR_5 32000 EUR   0.000533 \n 8 EUR_6 30000 EUR   0.000553 \n 9 EUR_7 28000 EUR   0.000499 \n10 EUR_8 26000 EUR   0.000506 \n# ℹ 28 more rows\n\n# Let's plot the results using the ggplot2 package\n# (because a picture is worth a thousand numbers!)\nlibrary(ggplot2)\n\nggplot(pi_df, aes(pop, diversity, color = pop, group = pop)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter() +\n  theme_bw()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-2-computing-pairwise-divergence",
    "href": "slendr.html#part-2-computing-pairwise-divergence",
    "title": "2  Introduction to slendr",
    "section": "5.2 Part 2: Computing pairwise divergence",
    "text": "5.2 Part 2: Computing pairwise divergence\nUse the function ts_divergence() to compute genetic divergence between all pairs of populations. Again, do you get results compatible with our demographic model in terms of expectation given the split times between populations as you programmed them for your model?\nHint: Again, you can use the same concept of sample_sets = we discussed in the previous part. In this case, the function computes pairwise divergence between each element of the list given as sample_sets = (i.e., for each vector of individual names).\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nsample_sets &lt;- ts_names(ts, split = \"pop\")\n\ndiv_df &lt;- ts_divergence(ts, sample_sets)\narrange(div_df, divergence)\n\n# A tibble: 6 × 3\n  x     y     divergence\n  &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 AFR   EUR     0.000649\n2 EUR   NEA     0.000955\n3 AFR   NEA     0.000983\n4 CHIMP NEA     0.00416 \n5 CHIMP EUR     0.00417 \n6 AFR   CHIMP   0.00418 \n\n\nWe can see that the pairwise nucleotide divergences between populations recapitulate the known population/species relationships we would expect from our model.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-3-detecting-neanderthal-admixture-in-europeans",
    "href": "slendr.html#part-3-detecting-neanderthal-admixture-in-europeans",
    "title": "2  Introduction to slendr",
    "section": "5.3 Part 3: Detecting Neanderthal admixture in Europeans",
    "text": "5.3 Part 3: Detecting Neanderthal admixture in Europeans\nLet’s now pretend its about 2008, we’ve sequenced the first Neanderthal genome, and we are working on a project that will change human evolution research forever. We also have the genomes of a couple of people from Africa and Europe, which we want to use to answer the most burning question of all evolutionary anthropology: “Do some people living today carry Neanderthal ancestry?”\nEarlier you’ve learned about \\(f\\)-statistics of various kinds. You have also heard that an \\(f_4\\) statistic (or its equivalent \\(D\\) statistic) can be used as a test of “treeness”. Simply speaking, for some “quartet” of individuals or population samples, they can be used as a hypothesis test of whether the history of those samples is compatible with there not having been an introgression.\nCompute the \\(f_4\\) test of Neanderthal introgression in EUR individuals using the slendr function ts_f4(). When you’re running it, you will have to provide individuals to compute the statistic using a slightly different format. Take a look at the help page available as ?ts_f4 for more information. When you’re computing the \\(f_4\\), make sure to set mode = \"branch\" argument of the ts_f4() function (we will get to why a bit later).\n\n\nNote: By default, each slendr / tskit statistic function operates on mutations, and this will switch them to use branch length (as you might know, \\(f\\)-statistics are mathematically defined using branch lengths in trees and mode = \"branch\" does exactly that).\nHint: If you haven’t learned this in your \\(f\\)-statistics lecture, you want to compute (and compare) the values of these two statistics using the slendr function ts_f4():\n\n\\(f_4\\)(&lt;some African&gt;, &lt;another African&gt;; &lt;Neanderthal&gt;, &lt;Chimp&gt;)\n\\(f_4\\)(&lt;some African&gt;, &lt;a test European&gt;; &lt;Neanderthal&gt;, &lt;Chimp&gt;),\n\nhere &lt;individual&gt; can be the name of any individual recorded in your tree sequence, such as names you saw as name column in the table returned by ts_samples(ts) (i.e. \"NEA_1\" could be used as a “representative” &lt;Neanderthal&gt; in those equations, similarly for \"CHIMP_1\" as the fourth sample in the \\(f_4\\) quarted representing the outgroup).\nTo simplify things a lot, we can understand the above equations as comparing the counts of so-called BABA and ABBA allele patterns between the quarted of samples specified in the statistics:\n\\[\nf_4(AFR, X; NEA, CHIMP) = \\frac{\\#BABA - \\#ABBA}{\\#SNPs}\n\\]\nThe first \\(f_4\\) statistic above is not expected to give values “too different” from 0 (even in case of Neanderthal introgression into Europeans) because we don’t expect two African individuals to differ “significantly” in terms of how much alleles they share with a Neanderthal (because their ancestors never met Neanderthals!). The other should – if there was a Neanderthal introgression into Europeans some time in their history – be “significantly negative”.\nIs the second of those two statistics “much more negative” than the first, as expected assuming introgression from Neanderthals into Europeans?\nWhy am I putting “significantly” and “much more negative” in quotes in the previous sentence? What are we missing here for this being a true hypothesis test as you might be accustomed to from computing \\(f\\)-statistics using a tool such as ADMIXTOOLS? (We will get to this again in the following part of this exercise.)\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# Compute the difference in the amount of allele sharing between two African\n# individuals and a Neanderthal\nf4_null &lt;- ts_f4(ts, W = \"AFR_1\", X = \"AFR_2\", Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\nf4_null\n\n# A tibble: 1 × 5\n  W     X     Y     Z          f4\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 AFR_1 AFR_2 NEA_1 CHIMP_1  43.4\n\n# Compute the difference in the amount of allele sharing between an African\n# individual vs European individual and a Neanderthal\nf4_alt &lt;- ts_f4(ts, W = \"AFR_1\", X = \"EUR_1\", Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\nf4_alt\n\n# A tibble: 1 × 5\n  W     X     Y     Z          f4\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 AFR_1 EUR_1 NEA_1 CHIMP_1 -853.\n\n# We can see that the second test resulted in an f4 value about ~20 times more\n# negative than the first test, indicating that a European in our test carries\n# \"significantly more\" Neanderthal alleles compared to the baseline expectation\n# of no introgression established by the comparison to an African ...\nabs(f4_alt$f4 / f4_null$f4)\n\n[1] 19.65719\n\n# ... although this is not a real test of significance (we have no Z-score or\n# standard error which would give us something like a p-value for the hypothesis\n# test, as we get by jackknife procedure in ADMIXTOOLS)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-4-detecting-neanderthal-admixture-in-europeans-v2.0",
    "href": "slendr.html#part-4-detecting-neanderthal-admixture-in-europeans-v2.0",
    "title": "2  Introduction to slendr",
    "section": "5.4 Part 4: Detecting Neanderthal admixture in Europeans v2.0",
    "text": "5.4 Part 4: Detecting Neanderthal admixture in Europeans v2.0\nThe fact that we don’t get something equivalent to a p-value in these kinds of simulations is generally not a problem, because we’re often interested in establishing a trend of a statistic under various conditions, and understanding when and how its expected value behaves in a certain way. If statistical noise is a problem, we work around this by computing a statistic on multiple simulation replicates or even increasing the sample sizes.\n\n\nNote: To see this in practice, you can check out a paper in which I used this approach quite successfully on a related problem.\nOn top of that, p-value of something like an \\(f\\)-statistic (whether it’s significantly different from zero) is also strongly affected by quality of the data, sequencing errors, coverage, etc. (which can certainly be examined using simulations!). However, these are aspects of modeling which are quite orthogonal to the problem of investigating the expectations and trends of statistics given some underlying evolutionary model, which is what we’re after in these exercises.\nThat said, even in perfect simulated data, what exactly does “significantly different from zero compared to some baseline expectation” mean can be blurred by noise with simple single-individual comparisons that we did above. Let’s increase the sample size a bit to see if a statistical pattern expected in \\(f_4\\) statistic from our Neanderthal introgression model becomes more apparent.\nCompute the first \\(f_4\\) statistic (the baseline expectation between a pair of Africans) and the second \\(f_4\\) statistic (comparing an African and a European), but this time on all recorded Africans and all recorded Europeans, respectively. Plot the distributions of those two sets of statistics. This should remove lots of the uncertainty and make a statistical trend stand out much more clearly.\nHint: Whenever you need to compute something for many things in sequence, looping is very useful. One way to do compute, say, an \\(f_4\\) statistic over many individuals is by using this kind of pattern using R’s looping function lapply():\n\n# Loop over vector of individual names (variable x) and apply a given ts_f4()\n# expression on each individual (note the ts_f4(..., X = x, ...) in the code)\nlist_f4 &lt;- lapply(\n  c(\"ind_1\", \"ind_2\", ...),\n  function(x) ts_f4(ts, W = \"AFR_1\", X = x, Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\n)\n\n# The above gives us a list of data frames, so we need to bind them all into a\n# single table for easier interpretation and visualization\ndf_f4 &lt;- do.call(rbind, list_f4)\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# This gives us list of vectors of the names of all individuals in each\n# population...\nsample_sets &lt;- ts_names(ts, split = \"pop\")\n# ... which we can then access like this\nsample_sets$AFR # all Africans\n\n[1] \"AFR_1\" \"AFR_2\" \"AFR_3\" \"AFR_4\" \"AFR_5\"\n\nsample_sets$EUR # all Europeans\n\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\"\n\n# Let's compute the f4 statistic for all Africans... \nf4_afr_list &lt;- lapply(\n  sample_sets$AFR,\n  function(x) ts_f4(ts, W = \"AFR_1\", X = x, Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\n)\n# ... and Europeans\nf4_eur_list &lt;- lapply(\n  sample_sets$EUR,\n  function(x) ts_f4(ts, W = \"AFR_1\", X = x, Y = \"NEA_1\", Z = \"CHIMP_1\", mode = \"branch\")\n)\n\n# Bind each list of data frames into a single data frame\nf4_afr &lt;- do.call(rbind, f4_afr_list)\nf4_eur &lt;- do.call(rbind, f4_eur_list)\n\n# Let's add population columns to each of the two results for easier plotting\nf4_afr$pop &lt;- \"AFR\"\nf4_eur$pop &lt;- \"EUR\"\n\n# Bind both tables together\nf4_results &lt;- rbind(f4_afr, f4_eur)\n\n# Visualize the results\nf4_results %&gt;%\n  ggplot(aes(pop, f4, color = pop)) +\n  geom_boxplot() +\n  geom_jitter() +\n  geom_hline(yintercept = 0, linetype = 2) +\n  ggtitle(\"f4(AFR, EUR; NEA, CHIMP)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can see that the \\(f_4\\) statistic test of Neanderthal introgression in Europeans indeed does give a much more negative distribution of values compared to the baseline expectation which compares two Africans to each other.\n\n\n\n\n\n\n\n\n\nBonus exercises\n\n\n\n\n\n\n5.4.1 Bonus 1: mode = \"branch\" vs mode = \"site\"\nRepeat the previous part of the exercise by setting mode = \"site\" in the ts_f4() function calls (this is actually the default behavior of all slendr tree-sequence based tskit functions). This will switch the tskit computation to using mutation counts along each branch of the tree sequence, rather than using branch length themselves. Why might the branch-based computation be a bit better if what we’re after is investigating the expected values of statistics under some model?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nSee this tutorial (and particularly the directly linked section) for explanation.\n\n\n\n\n\n5.4.2 Bonus 2: Outgroup \\(f_3\\) statistic\nUse the function ts_f3() to compute the outgroup \\(f_3\\) statistic between pairs of African-European, African-Neanderthal, and European-Neanderthal and a Chimpanzee outgroup.\nHint: The \\(f_3\\) statistic is traditionally expressed as \\(f_3(A, B; C)\\), where C represents the outgroup. Unfortunately, in tskit the outgroup is named A, with B and C being the pair of samples from which we trace the length of branches towards the outgroup, so the statistic is interpreted as \\(f_3(B, C; A)\\).\nHow do the outgroup f3 results compare to your expectation based on simple population relationships (and to the divergence computation above)?\nDo you see any impact of introgression on the \\(f_3\\) value when a Neanderthal is included in the computation?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# f3(A, B; C) = E[ (A - C) * (B - C) ]\n# This means that in tskit, C is the outgroup (different from ADMIXTOOLS!)\n\n# We can compute f3 for individuals...\nts_f3(ts, B = \"AFR_1\", C = \"EUR_1\", A = \"CHIMP_1\")\n\n# A tibble: 1 × 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 AFR_1 EUR_1 0.00375\n\n# ... but also whole populations (or population samples)\nts_f3(ts, B = sample_sets[\"AFR\"], C = sample_sets[\"EUR\"], A = \"CHIMP_1\")\n\n# A tibble: 1 × 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 AFR   EUR   0.00375\n\nts_f3(ts, B = sample_sets[\"AFR\"], C = sample_sets[\"NEA\"], A = \"CHIMP_1\")\n\n# A tibble: 1 × 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 AFR   NEA   0.00358\n\nts_f3(ts, B = sample_sets[\"EUR\"], C = sample_sets[\"NEA\"], A = \"CHIMP_1\")\n\n# A tibble: 1 × 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 EUR   NEA   0.00359\n\n\n\n\n\n\n\n5.4.3 Bonus 3: Outgroup \\(f_3\\) statistic as a linear combination of \\(f_2\\) statistics\nYou might have learned that any complex \\(f\\)-statistic can be expressed as a linear combination of multiple \\(f_2\\) statistics (which represent simple branch length separating two lineages). Verify that this is the case by looking up equation (20b) in this amazing paper and compute an \\(f_3\\) statistic for any arbitrary trio of individuals of your choosing using this linear combination of \\(f_2\\) statistics.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# standard f3\nts_f3(ts, B = \"AFR_1\", C = \"AFR_2\", A = \"CHIMP_1\")\n\n# A tibble: 1 × 4\n  A       B     C          f3\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 CHIMP_1 AFR_1 AFR_2 0.00378\n\n# a \"homemade\" f3 statistic as a linear combination of f2 statistics\n# f3(A, B; C) = f2(A, C) + f2(B, C) - f2(A, B) / 2\nhomemade_f3 &lt;- (\n  ts_f2(ts, A = \"AFR_1\", B = \"CHIMP_1\")$f2 +\n  ts_f2(ts, A = \"AFR_2\", B = \"CHIMP_1\")$f2 -\n  ts_f2(ts, A = \"AFR_1\", B = \"AFR_2\")$f2\n) / 2\nhomemade_f3\n\n[1] 0.003778796\n\n\n\n\n\n\n\n5.4.4 Bonus 4: Trajectory of Neanderthal ancestry in Europe over time\nThere used to be a lot of controversy about the question of whether or not did Neanderthal ancestry proportion in Europeans decline or not over the past 40 thousand years (see figure 1 in this paper figure 2 in this paper).\nYour simulated tree sequence contains a time-series of European individuals over time. Use the slendr function ts_f4ratio() to compute (and then plot) the proportion (commonly designated as alpha) of Neanderthal ancestry in Europe over time. Use \\(f_4\\)-ratio statistic of the following form:\n\nts_f4ratio(ts, X = &lt;vector of ind. names&gt;, A = \"NEA_1\", B = \"NEA_2\", C = \"AFR_1\", O = \"CHIMP_1\")\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# Extract table with names and times of sampled Europeans (ancient and present day)\neur_inds &lt;- ts_samples(ts) %&gt;% filter(pop == \"EUR\")\neur_inds\n\n# A tibble: 30 × 3\n   name    time pop  \n   &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;\n 1 EUR_1  40000 EUR  \n 2 EUR_2  38000 EUR  \n 3 EUR_3  36000 EUR  \n 4 EUR_4  34000 EUR  \n 5 EUR_5  32000 EUR  \n 6 EUR_6  30000 EUR  \n 7 EUR_7  28000 EUR  \n 8 EUR_8  26000 EUR  \n 9 EUR_9  24000 EUR  \n10 EUR_10 22000 EUR  \n# ℹ 20 more rows\n\n# Compute f4-ration statistic (this will take ~30s) -- note that we can provide\n# a vector of names for the X sample set to the `ts_f4ratio()` function\nnea_ancestry &lt;- ts_f4ratio(ts, X = eur_inds$name, A = \"NEA_1\", B = \"NEA_2\", C = \"AFR_1\", O = \"CHIMP_1\")\n\n# Add the age of each sample to the table of proportions\nnea_ancestry$time &lt;- eur_inds$time\nnea_ancestry\n\n# A tibble: 30 × 7\n   X      A     B     C     O        alpha  time\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 EUR_1  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0153 40000\n 2 EUR_2  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0170 38000\n 3 EUR_3  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0117 36000\n 4 EUR_4  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0201 34000\n 5 EUR_5  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0261 32000\n 6 EUR_6  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0132 30000\n 7 EUR_7  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0151 28000\n 8 EUR_8  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0243 26000\n 9 EUR_9  NEA_1 NEA_2 AFR_1 CHIMP_1 0.0195 24000\n10 EUR_10 NEA_1 NEA_2 AFR_1 CHIMP_1 0.0243 22000\n# ℹ 20 more rows\n\nnea_ancestry %&gt;%\n  ggplot(aes(time, alpha)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", linetype = 2, color = \"red\", linewidth = 0.5) +\n  xlim(40000, 0) +\n  coord_cartesian(ylim = c(0, 0.1)) +\n  labs(x = \"time [years ago]\", y = \"Neanderthal ancestry proportion\") +\n  theme_bw() +\n  ggtitle(\"Neanderthal ancestry proportion in Europeans over time\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# For good measure, let's test the significance of the decline using a linear model\nsummary(lm(alpha ~ time, data = nea_ancestry))\n\n\nCall:\nlm(formula = alpha ~ time, data = nea_ancestry)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0102725 -0.0029417  0.0001505  0.0040630  0.0073792 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.205e-02  1.214e-03  18.173   &lt;2e-16 ***\ntime        -1.031e-07  6.204e-08  -1.662    0.108    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.004642 on 28 degrees of freedom\nMultiple R-squared:  0.08979,   Adjusted R-squared:  0.05728 \nF-statistic: 2.762 on 1 and 28 DF,  p-value: 0.1077\n\n\n\n\n\n\n\n5.4.5 Bonus 5: How many unique f4 quartets are there?\nIn your lecture about \\(f\\)-statistics, you’ve probably learned about various symmetries in \\(f_4\\) (but also other \\(f\\)-statistics) depending on the arrangement of the “quartet”. As a trivial example, an \\(f_3(A; B, C)\\) and \\(f_3(A; C, B)\\) will give you exactly the same value, and the same thing applies even to more complex \\(f\\)-statistics like \\(f_4\\).\nUse simulations to compute how manu unique \\(f_4\\) values involving a single quartet are there.\nHint: Draw some trees to figure out why could that be true. Also, when computing ts_f4(), set mode = \"branch\" to avoid the effect of statistical noise due to mutations.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# # install a combinatorics R package\n# install.packages(\"combinat\")\n\nlibrary(combinat)\n\n\nAttaching package: 'combinat'\n\n\nThe following object is masked from 'package:utils':\n\n    combn\n\n# These are the four samples we can create quartet combinations from\nquartet &lt;- c(\"AFR_1\", \"EUR_1\", \"NEA_1\", \"CHIMP_1\")\nquartets &lt;- permn(quartet)\nquartets\n\n[[1]]\n[1] \"AFR_1\"   \"EUR_1\"   \"NEA_1\"   \"CHIMP_1\"\n\n[[2]]\n[1] \"AFR_1\"   \"EUR_1\"   \"CHIMP_1\" \"NEA_1\"  \n\n[[3]]\n[1] \"AFR_1\"   \"CHIMP_1\" \"EUR_1\"   \"NEA_1\"  \n\n[[4]]\n[1] \"CHIMP_1\" \"AFR_1\"   \"EUR_1\"   \"NEA_1\"  \n\n[[5]]\n[1] \"CHIMP_1\" \"AFR_1\"   \"NEA_1\"   \"EUR_1\"  \n\n[[6]]\n[1] \"AFR_1\"   \"CHIMP_1\" \"NEA_1\"   \"EUR_1\"  \n\n[[7]]\n[1] \"AFR_1\"   \"NEA_1\"   \"CHIMP_1\" \"EUR_1\"  \n\n[[8]]\n[1] \"AFR_1\"   \"NEA_1\"   \"EUR_1\"   \"CHIMP_1\"\n\n[[9]]\n[1] \"NEA_1\"   \"AFR_1\"   \"EUR_1\"   \"CHIMP_1\"\n\n[[10]]\n[1] \"NEA_1\"   \"AFR_1\"   \"CHIMP_1\" \"EUR_1\"  \n\n[[11]]\n[1] \"NEA_1\"   \"CHIMP_1\" \"AFR_1\"   \"EUR_1\"  \n\n[[12]]\n[1] \"CHIMP_1\" \"NEA_1\"   \"AFR_1\"   \"EUR_1\"  \n\n[[13]]\n[1] \"CHIMP_1\" \"NEA_1\"   \"EUR_1\"   \"AFR_1\"  \n\n[[14]]\n[1] \"NEA_1\"   \"CHIMP_1\" \"EUR_1\"   \"AFR_1\"  \n\n[[15]]\n[1] \"NEA_1\"   \"EUR_1\"   \"CHIMP_1\" \"AFR_1\"  \n\n[[16]]\n[1] \"NEA_1\"   \"EUR_1\"   \"AFR_1\"   \"CHIMP_1\"\n\n[[17]]\n[1] \"EUR_1\"   \"NEA_1\"   \"AFR_1\"   \"CHIMP_1\"\n\n[[18]]\n[1] \"EUR_1\"   \"NEA_1\"   \"CHIMP_1\" \"AFR_1\"  \n\n[[19]]\n[1] \"EUR_1\"   \"CHIMP_1\" \"NEA_1\"   \"AFR_1\"  \n\n[[20]]\n[1] \"CHIMP_1\" \"EUR_1\"   \"NEA_1\"   \"AFR_1\"  \n\n[[21]]\n[1] \"CHIMP_1\" \"EUR_1\"   \"AFR_1\"   \"NEA_1\"  \n\n[[22]]\n[1] \"EUR_1\"   \"CHIMP_1\" \"AFR_1\"   \"NEA_1\"  \n\n[[23]]\n[1] \"EUR_1\"   \"AFR_1\"   \"CHIMP_1\" \"NEA_1\"  \n\n[[24]]\n[1] \"EUR_1\"   \"AFR_1\"   \"NEA_1\"   \"CHIMP_1\"\n\n# How many permutations there are in total?\n#   4! = 4 * 3 * 2 * 1 = 24\nfactorial(4)\n\n[1] 24\n\n# We should therefore have 24 different quartet combinations of samples\nlength(quartets)\n\n[1] 24\n\n# Loop across all quartets, computing the corresponding f4 statistic (we want\n# to do this using branch lengths, not mutations, as the mutation-based computation\n# would involve statistical noise)\nall_f4s &lt;- lapply(quartets, function(q) ts_f4(ts, q[1], q[2], q[3], q[4], mode = \"branch\"))\n\n# Bind the list of f4 results into a single data frame and inspect the results\nall_f4s &lt;- bind_rows(all_f4s) %&gt;% arrange(abs(f4))\nprint(all_f4s, n = Inf)\n\n# A tibble: 24 × 5\n   W       X       Y       Z            f4\n   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n 1 AFR_1   EUR_1   NEA_1   CHIMP_1   -853.\n 2 AFR_1   EUR_1   CHIMP_1 NEA_1      853.\n 3 NEA_1   CHIMP_1 AFR_1   EUR_1     -853.\n 4 CHIMP_1 NEA_1   AFR_1   EUR_1      853.\n 5 CHIMP_1 NEA_1   EUR_1   AFR_1     -853.\n 6 NEA_1   CHIMP_1 EUR_1   AFR_1      853.\n 7 EUR_1   AFR_1   CHIMP_1 NEA_1     -853.\n 8 EUR_1   AFR_1   NEA_1   CHIMP_1    853.\n 9 AFR_1   NEA_1   CHIMP_1 EUR_1   -16428.\n10 AFR_1   NEA_1   EUR_1   CHIMP_1  16428.\n11 NEA_1   AFR_1   EUR_1   CHIMP_1 -16428.\n12 NEA_1   AFR_1   CHIMP_1 EUR_1    16428.\n13 EUR_1   CHIMP_1 NEA_1   AFR_1   -16428.\n14 CHIMP_1 EUR_1   NEA_1   AFR_1    16428.\n15 CHIMP_1 EUR_1   AFR_1   NEA_1   -16428.\n16 EUR_1   CHIMP_1 AFR_1   NEA_1    16428.\n17 AFR_1   CHIMP_1 EUR_1   NEA_1    17281.\n18 CHIMP_1 AFR_1   EUR_1   NEA_1   -17281.\n19 CHIMP_1 AFR_1   NEA_1   EUR_1    17281.\n20 AFR_1   CHIMP_1 NEA_1   EUR_1   -17281.\n21 NEA_1   EUR_1   CHIMP_1 AFR_1    17281.\n22 NEA_1   EUR_1   AFR_1   CHIMP_1 -17281.\n23 EUR_1   NEA_1   AFR_1   CHIMP_1  17281.\n24 EUR_1   NEA_1   CHIMP_1 AFR_1   -17281.\n\n# Narrow down the results to only unique f4 values\ndistinct(all_f4s, f4, .keep_all = TRUE)\n\n# A tibble: 6 × 5\n  W       X       Y       Z            f4\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 AFR_1   EUR_1   NEA_1   CHIMP_1   -853.\n2 AFR_1   EUR_1   CHIMP_1 NEA_1      853.\n3 AFR_1   NEA_1   CHIMP_1 EUR_1   -16428.\n4 AFR_1   NEA_1   EUR_1   CHIMP_1  16428.\n5 AFR_1   CHIMP_1 EUR_1   NEA_1    17281.\n6 CHIMP_1 AFR_1   EUR_1   NEA_1   -17281.\n\ndistinct(all_f4s, abs(f4), .keep_all = TRUE)\n\n# A tibble: 3 × 6\n  W     X       Y       Z            f4 `abs(f4)`\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 AFR_1 EUR_1   NEA_1   CHIMP_1   -853.      853.\n2 AFR_1 NEA_1   CHIMP_1 EUR_1   -16428.    16428.\n3 AFR_1 CHIMP_1 EUR_1   NEA_1    17281.    17281.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-1-a-self-contained-slendr-function-of-n_e-rightarrow-textrmafs",
    "href": "slendr.html#part-1-a-self-contained-slendr-function-of-n_e-rightarrow-textrmafs",
    "title": "2  Introduction to slendr",
    "section": "6.1 Part 1: A self-contained slendr function of \\(N_e \\rightarrow \\textrm{AFS}\\)",
    "text": "6.1 Part 1: A self-contained slendr function of \\(N_e \\rightarrow \\textrm{AFS}\\)\nIn a new script exercise3.R write a custom R function called simulate_afs(), which will take Ne as its only parameter. Use this function to compute (and return) AFS vectors for a couple of Ne values of your choosing, but staying between Ne = 1000 and Ne = 30000 Plot those AFS vectors and observe how (and why?) do they differ based on Ne parameter you used in each respective simulation.\nHint: The function should create a one-population forward-time model (our population starting at time = 1, with the model simulation_length = 100000 and generation_time = 1 in compile_model()), simulate 10Mb tree sequence using msprime() (recombination rate 1e-8) and then overlay neutral mutations on it at mutation_rate = 1e-8), compute AFS for 10 samples and return the AFS vector as result of this custom function.\nHint: If you’ve never programmed before, the concept of a “custom function” might be very alien to you. Again, if you need help, feel free to start building your exercise3.R solution based on this “template” (just fill in missing relevant bits of slendr code that you should be already familiar with):\n\nlibrary(slendr)\ninit_env()\n\nsimulate_afs &lt;- function(Ne) {\n  # In here you should write code which will:\n  #   1. create one population with a given Ne (provided as a function argument)\n  #   2. compile a model using `simulation_length =` and `generation_time =`\n  #   3. simulate a tree sequence\n  #   4. select names of 10 samples (doesn't matter which, \"pop_1\", \"po2_\", ...)\n  #   5. compute AFS vector from those 10 individuals using `ts_afs()`\n  \n  # `result` is a variable with your 10-sample AFS vector (we remove the\n  # first element because it's not meaningful for our example)\n  return(result[-1]) \n}\n\nafs_1 &lt;- simulate_afs(Ne = 1000) # simulate AFS from a Ne = 1000 model...\nplot(afs_1, type =\"o\")           # ... and plot it\n\n\n\nNote: Remember that you should drop the first element of the AFS vector produced by ts_afs() (for instance with something like result[-1] if result contains the output of ts_afs()) technical reasons related to tskit. You don’t have to worry about that here, but you can read this for more detail.\nHint: If the above still doesn’t make any sense to you, feel free to copy-paste the function from the solution below into your script and work with that function instead!\nWhen used in R, your custom function should work like this (the simulation is stochastic, so your numbers will be different, of course):\n\n# This gives us a vector of singletons, doubletons, etc., etc., all the way\n# to the number of fixed mutations in our sample of 10 individuals\nsimulate_afs(Ne = 1000)\n\n [1] 469 239 145  72  90  55  79  33  56  39  34  36  33  26  29  23  31  22  22\n[20]   7\n\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# An R function can be understood as a block of a computer program which executes\n# a block of code inside the {...} brackets given a certain value of a parameter\n# (here 'Ne' just after the word 'function')\nsimulate_afs &lt;- function(Ne) {\n  # create a slendr model with a single population of size Ne = N\n  pop &lt;- population(\"pop\", N = Ne, time = 1)\n  model &lt;- compile_model(pop, generation_time = 1, simulation_length = 100000)\n\n  # simulate a tree sequence\n  ts &lt;-\n    msprime(model, sequence_length = 10e6, recombination_rate = 1e-8) %&gt;%\n    ts_mutate(mutation_rate = 1e-8)\n\n  # get a random sample of names of 10 individuals\n  samples &lt;- ts_names(ts) %&gt;% sample(10)\n\n  # compute the AFS vector (dropping the 0-th element added by tskit)\n  afs &lt;- ts_afs(ts, sample_sets = list(samples))[-1]\n\n  afs\n}\n\n# Let's use our custom function to simulate AFS vector for Ne = 1k, 10k, and 30k\nafs_1k &lt;- simulate_afs(1000)\nafs_10k &lt;- simulate_afs(10000)\nafs_30k &lt;- simulate_afs(30000)\n\n# Plot the three simulated AFS using base R plotting functionality\nplot(afs_30k, type = \"o\", main = \"AFS, Ne = 30000\", col = \"cyan\",)\nlines(afs_10k, type = \"o\", main = \"AFS, Ne = 10000\", col = \"purple\")\nlines(afs_1k, type = \"o\", main = \"AFS, Ne = 1000\", col = \"blue\")\nlegend(\"topright\", legend = c(\"Ne = 1k\", \"Ne = 10k\", \"Ne = 30k\"),\n       fill = c(\"blue\", \"purple\", \"cyan\"))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-2-estimating-unknown-n_e-from-empirical-afs",
    "href": "slendr.html#part-2-estimating-unknown-n_e-from-empirical-afs",
    "title": "2  Introduction to slendr",
    "section": "6.2 Part 2: Estimating unknown \\(N_e\\) from empirical AFS",
    "text": "6.2 Part 2: Estimating unknown \\(N_e\\) from empirical AFS\nImagine you sequenced 10 samples from a population and computed the following AFS vector (which contains, sequentially, the number of singletons, doubletons, etc., in your sample from a population):\n\n\nafs_observed &lt;- c(2520, 1449, 855, 622, 530, 446, 365, 334, 349, 244,\n                  264, 218,  133, 173, 159, 142, 167, 129, 125, 143)\n\nYou know (maybe from some fossil evidence) that the population probably had a constant \\(N_e\\) somewhere between 1000 and 30000 for the past 100,000 generations, and had mutation and recombination rates of 1e-8 (i.e., parameters already implemented by your simulate_afs() function – how convenient!).\nUse slendr simulations to guess the true (and hidden!) \\(N_e\\) given the observed AFS by running simulations for a range of \\(N_e\\) values and finding out which \\(N_e\\) produces the closest AFS vector to the afs_observed vector above using one of the following two approaches.\n\nOption 1 [easy]: Plot AFS vectors for various \\(N_e\\) values (i.e. simulate several of them using your function simulate_afs()), then eyeball which looks closest to the observed AFS based on the figures alone. (This is, of course, not how proper statistical inference is done, but it will be good enough for this exercie!)\nOption 2 [hard]: Simulate AFS vectors in steps of possible Ne (maybe lapply()?), and find the \\(N_e\\) which gives the closest AFS to the observed AFS based on Mean squared error.\n\n\n\n\n\n\n\nClick to see the solution to “Option 1”\n\n\n\n\n\n\n# This is our starting observed AFS which we want to compare simulated AFS vectors to\nafs_observed &lt;- c(2520, 1449, 855, 622, 530, 446, 365, 334, 349, 244,\n                  264, 218,  133, 173, 159, 142, 167, 129, 125, 143)\n\n# We know that the Ne is between 1000 and 30000, so let's simulate\n# a bunch of AFS vectors for different Ne values using our custom\n# AFS simulation function\nafs_Ne1k &lt;- simulate_afs(Ne = 1000)\nafs_Ne5k &lt;- simulate_afs(Ne = 5000)\nafs_Ne6k &lt;- simulate_afs(Ne = 6000)\nafs_Ne10k &lt;- simulate_afs(Ne = 10000)\nafs_Ne20k &lt;- simulate_afs(Ne = 20000)\nafs_Ne30k &lt;- simulate_afs(Ne = 30000)\n\n# Plot all simulated AFS vectors, highlighting the observed AFS in black\nplot(afs_observed, type = \"b\", col = \"black\", lwd = 3,\n     xlab = \"allele count bin\", ylab = \"count\", ylim = c(0, 13000))\nlines(afs_Ne1k, lwd = 2, col = \"blue\")\nlines(afs_Ne5k, lwd = 2, col = \"green\")\nlines(afs_Ne6k, lwd = 2, col = \"pink\")\nlines(afs_Ne10k, lwd = 2, col = \"purple\")\nlines(afs_Ne20k, lwd = 2, col = \"orange\")\nlines(afs_Ne30k, lwd = 2, col = \"cyan\")\nlegend(\"topright\",\n       legend = c(\"observed AFS\", \"Ne = 1000\", \"Ne = 5000\",\n                  \"Ne = 6000\", \"Ne = 10000\", \"Ne = 20000\", \"Ne = 30000\"),\n       fill = c(\"black\", \"blue\", \"green\", \"pink\", \"purple\", \"orange\", \"cyan\"))\n\n\n\n\n\n\n\n# !!!!! SPOILER ALERT BEFORE REVEALING THE CORRECT ANSWER !!!!!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n# true Ne was 6543!\n\n\n\n\n\n\n\n\n\n\nClick to see the solution to “Option 2”\n\n\n\n\n\n\n# This is our starting observed AFS which we want to compare simulated AFS vectors to\nafs_observed &lt;- c(2520, 1449, 855, 622, 530, 446, 365, 334, 349, 244,\n                  264, 218,  133, 173, 159, 142, 167, 129, 125, 143)\n\n# Generate regularly spaced values of potential Ne values (our parameter grid)\nNe_grid &lt;- seq(from = 1000, to = 30000, by = 500)\nNe_grid\n\n [1]  1000  1500  2000  2500  3000  3500  4000  4500  5000  5500  6000  6500\n[13]  7000  7500  8000  8500  9000  9500 10000 10500 11000 11500 12000 12500\n[25] 13000 13500 14000 14500 15000 15500 16000 16500 17000 17500 18000 18500\n[37] 19000 19500 20000 20500 21000 21500 22000 22500 23000 23500 24000 24500\n[49] 25000 25500 26000 26500 27000 27500 28000 28500 29000 29500 30000\n\n# I'm not entirely sure if your workshop cloud instances support big\n# parallelization runs -- if not, you can modify the `mc.cores =` argument\n# a couple of lines below to a smaller number (`mc.cores = 1` would make\n# the simulation run on a single processor, i.e. no parallelization).\nlibrary(parallel)\n\n# Compute AFS (in parallel, to make things faster) across the entire grid of possible Ne values\nafs_grid &lt;- mclapply(Ne_grid, simulate_afs, mc.cores = detectCores())\nnames(afs_grid) &lt;- Ne_grid\n\n# Show the first five simulated AFS vectors, for brevity\nafs_grid[1:5]\n\n$`1000`\n [1] 400 201 142  94  83  43  46  51  50  27  78  47  24  27  42  12  29  20  10\n[20]  23\n\n$`1500`\n [1] 582 277 209 128  85 107  99  59  62  71  56  52  50  40  36  29  49  30  31\n[20]  35\n\n$`2000`\n [1] 901 403 241 227 148 149 115 122 108  79  84  77  70  65  52  56  37  46  25\n[20]  18\n\n$`2500`\n [1] 900 486 349 293 184 157 135 153 118  91 111 111  78  72  94  69  80  59  46\n[20]  78\n\n$`3000`\n [1] 1144  531  409  331  243  188  171  128  170  122  133  102   87  122  105\n[16]   96   70   50   55   53\n\n# Plot the observed AFS...\nplot(afs_observed, type = \"b\", col = \"black\", lwd = 3, xlab = \"allele count bin\", ylab = \"count\")\n# ... and overlay the simulated AFS vectors on top of it\nfor (i in seq_along(Ne_grid)) {\n  lines(afs_grid[[i]], lwd = 0.5)\n}\nlegend(\"topright\", legend = c(\"observed AFS\", \"simulated AFS\"), fill = c(\"black\", \"gray\"))\n\n\n\n\n\n\n\n# Compute mean-squared error of the AFS produced by each Ne value across the grid\nerrors &lt;- sapply(afs_grid, function(sim_afs) {\n  sum((sim_afs - afs_observed)^2) / length(sim_afs)\n})\n\nplot(Ne_grid, errors, ylab = \"error\")\nabline(v = Ne_grid[which.min(errors)], col = \"red\")\nlegend(\"topright\", legend = paste(\"minimum error Ne =\", Ne_grid[which.min(errors)]), fill = \"red\")\n\n\n\n\n\n\n\n# Plot the AFS again, but this time highlight the most likely spectrum\n# (i.e. the one which gave the lowest RMSE value)\nplot(afs_observed, type = \"b\", col = \"black\", lwd = 3, xlab = \"allele count bin\", ylab = \"count\")\nfor (i in seq_along(Ne_grid)) {\n  color &lt;- if (i == which.min(errors)) \"red\" else \"gray\"\n  width &lt;- if (i == which.min(errors)) 2 else 0.75\n  lines(afs_grid[[i]], lwd = width, col = color)\n}\nlegend(\"topright\", legend = c(\"observed AFS\", paste(\"best fitting Ne =\", Ne_grid[which.min(errors)])),\n       fill = c(\"black\", \"red\"))\n\n\n\n\n\n\n\n# !!!!! SPOILER ALERT BEFORE REVEALING THE CORRECT ANSWER !!!!!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n# true Ne was 6543!\n\n\n\n\nCongratulations, you now know how to infer parameters of evolutionary models using simulations! What you just did is really very similar to how simulation-based inference is done in practice (even with methods such as ABC). Hopefully you can also see how easy does slendr make it.\nThis kind of approach can be used to infer all sorts of demographic parameters, even using other summary statistics that you’ve also learned to compute… including selection parameters, which we delve into in the next exercise.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-2-computing-tajimas-d-in-windows",
    "href": "slendr.html#part-2-computing-tajimas-d-in-windows",
    "title": "2  Introduction to slendr",
    "section": "7.1 Part 2: Computing Tajima’s D in windows",
    "text": "7.1 Part 2: Computing Tajima’s D in windows\nLet’s take this one step forward. Even if there is a locus under positive selection somewhere along our chromosome, it might be quite unlikely that we would find a Tajima’s D value significant enough for the entire chromosome (which is basically what we did in Part 1 now). Fortunately, thanks to the flexibility of the tskit module, the slendr function ts_tajima() has an argument windows =, which allows us to specify the coordinates of windows into which a sequence should be broken into, with Tajima’s D computed separately for each window. Perhaps this will allow us to see the impact of positive selection after we get to adding selection to our model. So let’s first built some code towards that.\nDefine a variable windows which will contain a vector of coordinates of 100 windows, starting at position 0, and ending at position 10e6 (i.e., the end of our chromosome). Then provide this variable as the windows = argument of ts_tajima() on a new, separate line of your script. Save the result of ts_tajima() into the variable tajima_wins, and inspect its contents in the R console.\nHint: You can use the R function seq() and its argument length.out = 100, to create the coordinates of window boundaries very easily.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# Pre-compute genomic windows for window-based computation of Tajima's D\nwindows &lt;- round(seq(0, ts$sequence_length, length.out = 100))\nwindows\n\n  [1]        0   101010   202020   303030   404040   505051   606061   707071\n  [9]   808081   909091  1010101  1111111  1212121  1313131  1414141  1515152\n [17]  1616162  1717172  1818182  1919192  2020202  2121212  2222222  2323232\n [25]  2424242  2525253  2626263  2727273  2828283  2929293  3030303  3131313\n [33]  3232323  3333333  3434343  3535354  3636364  3737374  3838384  3939394\n [41]  4040404  4141414  4242424  4343434  4444444  4545455  4646465  4747475\n [49]  4848485  4949495  5050505  5151515  5252525  5353535  5454545  5555556\n [57]  5656566  5757576  5858586  5959596  6060606  6161616  6262626  6363636\n [65]  6464646  6565657  6666667  6767677  6868687  6969697  7070707  7171717\n [73]  7272727  7373737  7474747  7575758  7676768  7777778  7878788  7979798\n [81]  8080808  8181818  8282828  8383838  8484848  8585859  8686869  8787879\n [89]  8888889  8989899  9090909  9191919  9292929  9393939  9494949  9595960\n [97]  9696970  9797980  9898990 10000000\n\n# Compute genome-wide Tajima's D for each population in individual windows\ntajima_wins &lt;- ts_tajima(ts, sample_sets = samples, windows = windows, mode = \"branch\")\ntajima_wins\n\n# A tibble: 4 × 2\n  set   D           \n  &lt;chr&gt; &lt;named list&gt;\n1 ANA   &lt;dbl [99]&gt;  \n2 EHG   &lt;dbl [99]&gt;  \n3 EUR   &lt;dbl [99]&gt;  \n4 YAM   &lt;dbl [99]&gt;  \n\n# You can see that the format of the result is slightly strange, with the\n# `D` column containing a vector of numbers (this is done for conciseness)\ntajima_wins[1, ]$D\n\n$`1`\n [1] -0.354052781 -0.342234459 -0.320076563 -0.208345083 -0.214277121\n [6] -0.017410189  0.153475629  0.387428485 -0.604691355 -0.542330657\n[11] -1.145804785 -0.929691760 -0.261087283 -0.893985513 -0.564595982\n[16] -0.497985165  0.817020892  0.019905178  0.206515500 -0.070682044\n[21]  0.013106622  0.675539095  0.995186061  0.262902685  0.353138615\n[26]  0.509580056  0.639291336  0.506034938  0.519200168  0.539439339\n[31]  0.079918322 -0.496792922  0.037375468  0.356119867  0.187179758\n[36] -0.119735709  0.577887619 -0.167904757  0.522701233  0.994999304\n[41] -0.703582478  0.054484727  0.436895752  0.028084661  0.079644267\n[46]  0.261625680  0.354236197 -0.355852685 -0.307391927 -0.078129710\n[51]  0.414472155  0.299468217  0.007732445 -0.138999763 -0.832174012\n[56] -0.569876014  0.530202607  0.552641582  1.081278415 -0.609719673\n[61]  0.251031212 -0.160821936  0.499212041  0.367495799  0.048099542\n[66] -0.524380857 -0.272383846 -0.424152611  0.263468151  0.331509596\n[71] -0.393069200 -0.353212137 -0.027107870  0.262984836 -0.015731247\n[76] -0.379056255  0.437148230 -0.575120130 -0.215921271  0.273532090\n[81]  0.295956346 -0.270489281 -0.312602435  0.117673002  0.046238996\n[86] -0.005016429  0.242742858  0.855901479 -0.242284392  0.254459114\n[91] -0.015718550 -0.448790199  0.748019967  0.334046719  0.308808659\n[96] -0.025052504  0.289518111 -0.600932450 -0.112794704\n\n\n\n\n\nThe default output format of ts_tajima() is not super user-friendly. Process the result using a helper function process_tajima(tajima_wins) that I provided for you (perhaps save it as tajima_df), and visualize it using another of my helper functions plot_tajima(tajima_df).\n\n\nNote: Making the process_tajima() and plot_tajima() function available in your R code is the purpose of the source(here::here(\"utils.R\")) command at the beginning of your script for this exercise.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# The helper function `process_tajima()` reformats the results into a normal\n# data frame, this time with a new column `window` which indicates the index\n# of the window that each `D` value was computed in\ntajima_df &lt;- process_tajima(tajima_wins)\ntajima_df\n\n# A tibble: 396 × 3\n   set         D window\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;int&gt;\n 1 ANA   -0.354       1\n 2 ANA   -0.342       2\n 3 ANA   -0.320       3\n 4 ANA   -0.208       4\n 5 ANA   -0.214       5\n 6 ANA   -0.0174      6\n 7 ANA    0.153       7\n 8 ANA    0.387       8\n 9 ANA   -0.605       9\n10 ANA   -0.542      10\n# ℹ 386 more rows\n\n# Now let's visualize the window-based Tajima's D along the simulated genome\n# using another helper function `plot_tajima()`\nplot_tajima(tajima_df)\n\n\n\n\n\n\n\n\nIt’s no surprise that we don’t see any Tajima’s D outliers in any of our windows, because we’re still working with a tree sequence produced by our a purely neutral simulation. But we have everything set up for the next part, in which we will add selection acting on a beneficial allele.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-3-adding-positive-selection-to-the-base-demographic-model",
    "href": "slendr.html#part-3-adding-positive-selection-to-the-base-demographic-model",
    "title": "2  Introduction to slendr",
    "section": "7.2 Part 3: Adding positive selection to the base demographic model",
    "text": "7.2 Part 3: Adding positive selection to the base demographic model\nAlthough primarily designed for neutral demographic models, slendr allows optional simulation of natural selection by providing a “SLiM extension code snippet” with customization SLiM code as an optional argument extension = of compile_model() (a function you’re closely familiar with at this point).\nUnfortunately we don’t have any space to explain SLiM here (and I have no idea, at the time of writing, whether or not you will have worked with SLiM earlier in this workshop). Suffice to say that SLiM is another very popular population genetic simulator software which allows simulation of selection, and which requires you to write custom code in a different programming language called Eidos.\nTake a look at the file slim_extension.txt provided in your working directory (it’s also part of the GitHub repository here). If you worked with SLiM before, glance through the script casually and see if it makes any sense to you. If you have not worked with SLiM before, look for the strange {elements} in curly brackets in the first ten lines of the script. Those are the parameters of the selection model we will be customizing the standard neutral demographic model we started with in the next step.\nSpecifically, when you inspect the slim_extension.txt file, you can see that this “SLiM extension script” I provided for you has three parameters:\n\norigin_pop – in which population should a beneficial allele appear,\ns – what should be the selection coefficient of the beneficial allele, and\nonset_time – at which time should the allele appear in the origin_pop.\n\nHowever, at the start, the SLiM extension snippet doesn’t contain any concrete values of those parameters, but only their {origin_pop}, {s}, and {onset_time} placeholders.\nUse the slendr function substitute_values() to substitute concrete values for those parameters like this:\n\nextension &lt;- substitute_values(\n  template = here::here(\"slim_extension.txt\"),\n  origin_pop = \"EUR\",\n  s = 0.15,\n  onset_time = 12000\n)\nextension\n\n[1] \"/var/folders/70/b_q2zdh116b9pfg29p03sx600000gn/T//RtmpWLi9I5/filed445c8804a8\"\n\n\nYou can see that substitute_values() returned a path to a file. Take a look at that file in your terminal – you should see each of the three {placeholder} parameters replaced with a concrete given value.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nLet’s take a look at the first 15 lines of the extension file before and after calling substitute_values(). We’ll do this in R for simplicity, but you can use less in plain unix terminal.\nBefore – see the {{placeholder}} parameters in their original form:\n\n\n// Define model constants (to be substituted) all in one place\n// (each {{placeholder}} will be replaced by a value passed from R).\n// Note that string constant template patterns are surrounded by \"quotes\"!\ninitialize() {\n    defineConstant(\"s\", {{s}});\n    defineConstant(\"onset_time\", {{onset_time}});\n    defineConstant(\"origin_pop\", \"{{origin_pop}}\");\n\n    // compose a trajectory file based on given parameters\n    defineConstant(\"traj_file\", PATH + \"/\" + \"trajectory.tsv\");\n}\n\n\nAfter – see the {{placeholder}} parameters with concrete values!\n\n\n// Define model constants (to be substituted) all in one place\n// (each {{placeholder}} will be replaced by a value passed from R).\n// Note that string constant template patterns are surrounded by \"quotes\"!\ninitialize() {\n    defineConstant(\"s\", 0.15);\n    defineConstant(\"onset_time\", 12000);\n    defineConstant(\"origin_pop\", \"EUR\");\n\n    // compose a trajectory file based on given parameters\n    defineConstant(\"traj_file\", PATH + \"/\" + \"trajectory.tsv\");\n}\n\n\n\n\n\nAnd that’s all the extra work we need to turn our purely neutral demographic slendr model into a model which includes natural selection! (In this case, only a simple selection acting on a single locus, as you’ll see later, but this can be generalized to any imaginable selection scenario.)\nHow do we use the SLiM extension for our simulation? It’s very simple – we just have to provide the extension variable as an additional argument of good old compile_model(). This will compile a new slendr model which will now include the new functionality for simulating natural selection:\nCompile a new model of the history of populations afr, ooa, ehg, etc., by following the instructions above, providing a new extension = argument to the compile_model() function.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nmodel &lt;- compile_model(\n  populations = list(afr, ooa, ehg, eur, ana, yam),\n  gene_flow = gf, generation_time = 30,\n  extension = extension   # &lt;======== this is missing in the neutral example!\n)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-4-running-a-selection-simulation-using-slim",
    "href": "slendr.html#part-4-running-a-selection-simulation-using-slim",
    "title": "2  Introduction to slendr",
    "section": "7.3 Part 4: Running a selection simulation using slim()",
    "text": "7.3 Part 4: Running a selection simulation using slim()\nNow we can finally run our selection simulation!\nThere are two modifications to our previous simulation workflows:\n\nBecause we need to run a non-neutral simulation, we have to switch from using the msprime() slendr engine to slim(). The latter can still interpret the same demographic model we programmed in R, just like the msprime() engine can, but will run the model using SLiM (and thus leveraging the new SLiM extension code that we have customized using substitute_values() above). We simply do this by switching from this:\n\n\nts &lt;- msprime(model, sequence_length = 10e6, recombination_rate = 1e-8, samples = schedule)\n\nto this:\n\nts &lt;- slim(model, sequence_length = 10e6, recombination_rate = 1e-8, samples = schedule)\n\nAs you can see, you don’t have to modify anything in your model code, just switching from msprime to slim in the line of code which produces the simulation result.\n\nThe customized model will not only produce a tree sequence, but will also generate a table of allele frequencies in each population (SLiM experts might have noticed the revelant SLiM code when they were inspecting slim_extension.txt). We need to be able to load both of these files after the simulation and thus need a path to a location we can find those files. We can do this by calling the slim() function as path &lt;- slim(..., path = TRUE) (so with the extra path = argument). This will return a path to where the slim() engine saved all files with our desired results.\n\nRun a simulation from the modified model of selection with the slim() engine as instructed in points number 1. and 2. above, then use the list.files(path) function in R to take a look in the directory. Which files were produced by the simulation?\n\n\n\n\n\n\nClick to see the solution (you have a working SLiM installation)\n\n\n\n\n\n\n# tstart &lt;- Sys.time()\npath &lt;- slim(model, sequence_length = 10e6, recombination_rate = 1e-8, samples = schedule, path = TRUE, random_seed = 59879916)\n# tend &lt;- Sys.time()\n# tend - tstart # Time difference of 38.82014 secs\n\n# We can verify that the path not only contains a tree-sequence file but also\n# the table of allele frequencies.\nlist.files(path)\n\n[1] \"slim.trees\"     \"trajectory.tsv\"\n\n\nWe can see that the slim() simulation generated a tree-sequence file (just like in previous exercises focused on msprime()) but it also created a new file – this was done by the SLiM customization snippet we provided to compile_model().\n\n\n\n\n\n\n\n\n\nClick to see the solution (you don’t have a working SLiM installation or the simulation takes too long)\n\n\n\n\n\n\n# If you don't have SLiM set up, just use the simulated results from my own\n# run of the same simulation\npath &lt;- here::here(\"data/selection\")\n\n# We can verify that the path not only contains a tree-sequence file but also\n# the table of allele frequencies.\nlist.files(path)\n\n[1] \"slim.trees\"     \"trajectory.tsv\"\n\n\nWe can see that the slim() simulation generated a tree-sequence file (just like in previous exercises focused on msprime()) but it also created a new file – this was done by the SLiM customization snippet we provided to compile_model().",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-5-investigating-allele-frequency-trajectories",
    "href": "slendr.html#part-5-investigating-allele-frequency-trajectories",
    "title": "2  Introduction to slendr",
    "section": "7.4 Part 5: Investigating allele frequency trajectories",
    "text": "7.4 Part 5: Investigating allele frequency trajectories\nUse another helper function read_trajectory(path) which I provided for this exercise to read the simulated frequency trajectories of the positively selected mutation in all of our populations into a variable traj_df. Then run a second helper function plot_trajectory(traj_df) to inspect the trajectories visually.\nRecall that you used the function substitute_values() to parametrize your selection model so that the allele under selection occurs in Europeans 15 thousand years ago, and is programmed to be under very strong selection of \\(s = 0.15\\). Do the trajectories visualized by plot_trajectory() make sense given the demographic model of European prehistory plotted above?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\ntraj_df &lt;- read_trajectory(path)\ntraj_df\n\n# A tibble: 1,604 × 4\n    time pop      freq onset\n   &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 11990 EHG    0      12000\n 2 11990 ANA    0      12000\n 3 11990 EUR    0.0001 12000\n 4 11990 YAM   NA      12000\n 5 11960 EHG    0      12000\n 6 11960 ANA    0      12000\n 7 11960 EUR    0.0001 12000\n 8 11960 YAM   NA      12000\n 9 11930 EHG    0      12000\n10 11930 ANA    0      12000\n# ℹ 1,594 more rows\n\nplot_trajectory(traj_df)\n\nWarning: Removed 554 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n# Comparing the trajectories side-by-side with the demographic model reveals\n# some obvious patterns of both selection and demographic history.\nplot_grid(\n  plot_model(model),\n  plot_trajectory(traj_df),\n  nrow = 1, rel_widths = c(0.7, 1)\n)\n\nWarning: Removed 554 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nWe can see that the beneficial allele which appeared in the European population was under extremely strong selection (look how its allele frequency shoots up immediately after its first appearance!). However, we can also se how the following demographic history with multiple admixture events kept “diluting” the allele frequency (indicated by the dips in the trajectory).\nThis is the kind of slendr simulation which could be also very useful for simulation-based inference, like we did in the previous exercise. Just imagine having a comparable aDNA time series data with empirical allele frequency trajectory over time and using it in an ABC setting!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-6-tajimas-d-genome-wide-and-window-based-from-the-selection-model",
    "href": "slendr.html#part-6-tajimas-d-genome-wide-and-window-based-from-the-selection-model",
    "title": "2  Introduction to slendr",
    "section": "7.5 Part 6: Tajima’s D (genome-wide and window-based) from the selection model",
    "text": "7.5 Part 6: Tajima’s D (genome-wide and window-based) from the selection model\nRecall that your simulation run saved results in the location stored in the path variable:\n\nlist.files(path)\n\n[1] \"slim.trees\"     \"trajectory.tsv\"\n\n\nFrom this path, we’ve already successfuly investigated the frequency trajectories.\nNow let’s compute Tajima’s D on the tree sequence simulated from our selection model. Hopefully we should see an interesting pattern in our selection scan? For instance, we don’t know yet where in the genome is the putative locus under selection!\nTo read a tree sequence simulated with slim() by our customized selection setup, we need to do a bit of work. To simplify things a bit, here’s the R code which makes it possible to do. Just copy it in your exercise4.R script as it is:\n\n# Let's use my own saved simulation results, so that we're all on the\n# same page going forward\npath &lt;- here::here(\"data/selection\")\n\nts &lt;-\n  file.path(path, \"slim.trees\") %&gt;%  # 1. compose full path to the slim.trees file\n  ts_read(model) %&gt;%                 # 2. read the tree sequence file into R\n  ts_recapitate(Ne = 5000, recombination_rate = 1e-8) # 3. perform recapitation\n\nVery briefly, because our tree sequence was generated by SLiM, it’s very likely that not all genealogies along the simulated genome will be fully coalesced (i.e., not all tree will have a single root). To explain why this is the case is out of the scope of this session, but read here if you’re interested in learning more. For the time being, it suffices to say that we can pass the (uncoalesced) tree sequence into the ts_recapitate() function, which then takes a SLiM tree sequence and simulates all necessary “ancestral history” that was missing on the uncoalesced trees, thus ensuring that the entire tree sequence is fully coalesced and can be correctly computed on.\nNow that you have a ts tree sequence object resulting from a new selection simulation run, repeat the analyses of genome-wide and window-based Tajima’s D from Part 1 and Part 2 of this exercise, again using the provided helper functions process_tajima() and plot_tajima(). Can you identify which locus has been the likely focal point of the positive selection? Which population shows evidence of selection? Which doesn’t and why (look again at the visualization of the demographic model above)?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nsamples &lt;- ts_names(ts, split = \"pop\")\nsamples\n\n$ANA\n [1] \"ANA_1\"  \"ANA_2\"  \"ANA_3\"  \"ANA_4\"  \"ANA_5\"  \"ANA_6\"  \"ANA_7\"  \"ANA_8\" \n [9] \"ANA_9\"  \"ANA_10\" \"ANA_11\" \"ANA_12\" \"ANA_13\" \"ANA_14\" \"ANA_15\" \"ANA_16\"\n[17] \"ANA_17\" \"ANA_18\" \"ANA_19\" \"ANA_20\" \"ANA_21\" \"ANA_22\" \"ANA_23\" \"ANA_24\"\n[25] \"ANA_25\" \"ANA_26\" \"ANA_27\" \"ANA_28\" \"ANA_29\" \"ANA_30\" \"ANA_31\" \"ANA_32\"\n[33] \"ANA_33\" \"ANA_34\" \"ANA_35\" \"ANA_36\" \"ANA_37\" \"ANA_38\" \"ANA_39\" \"ANA_40\"\n[41] \"ANA_41\" \"ANA_42\" \"ANA_43\" \"ANA_44\" \"ANA_45\" \"ANA_46\" \"ANA_47\" \"ANA_48\"\n[49] \"ANA_49\" \"ANA_50\"\n\n$EHG\n [1] \"EHG_1\"  \"EHG_2\"  \"EHG_3\"  \"EHG_4\"  \"EHG_5\"  \"EHG_6\"  \"EHG_7\"  \"EHG_8\" \n [9] \"EHG_9\"  \"EHG_10\" \"EHG_11\" \"EHG_12\" \"EHG_13\" \"EHG_14\" \"EHG_15\" \"EHG_16\"\n[17] \"EHG_17\" \"EHG_18\" \"EHG_19\" \"EHG_20\" \"EHG_21\" \"EHG_22\" \"EHG_23\" \"EHG_24\"\n[25] \"EHG_25\" \"EHG_26\" \"EHG_27\" \"EHG_28\" \"EHG_29\" \"EHG_30\" \"EHG_31\" \"EHG_32\"\n[33] \"EHG_33\" \"EHG_34\" \"EHG_35\" \"EHG_36\" \"EHG_37\" \"EHG_38\" \"EHG_39\" \"EHG_40\"\n[41] \"EHG_41\" \"EHG_42\" \"EHG_43\" \"EHG_44\" \"EHG_45\" \"EHG_46\" \"EHG_47\" \"EHG_48\"\n[49] \"EHG_49\" \"EHG_50\"\n\n$EUR\n [1] \"EUR_1\"  \"EUR_2\"  \"EUR_3\"  \"EUR_4\"  \"EUR_5\"  \"EUR_6\"  \"EUR_7\"  \"EUR_8\" \n [9] \"EUR_9\"  \"EUR_10\" \"EUR_11\" \"EUR_12\" \"EUR_13\" \"EUR_14\" \"EUR_15\" \"EUR_16\"\n[17] \"EUR_17\" \"EUR_18\" \"EUR_19\" \"EUR_20\" \"EUR_21\" \"EUR_22\" \"EUR_23\" \"EUR_24\"\n[25] \"EUR_25\" \"EUR_26\" \"EUR_27\" \"EUR_28\" \"EUR_29\" \"EUR_30\" \"EUR_31\" \"EUR_32\"\n[33] \"EUR_33\" \"EUR_34\" \"EUR_35\" \"EUR_36\" \"EUR_37\" \"EUR_38\" \"EUR_39\" \"EUR_40\"\n[41] \"EUR_41\" \"EUR_42\" \"EUR_43\" \"EUR_44\" \"EUR_45\" \"EUR_46\" \"EUR_47\" \"EUR_48\"\n[49] \"EUR_49\" \"EUR_50\"\n\n$YAM\n [1] \"YAM_1\"  \"YAM_2\"  \"YAM_3\"  \"YAM_4\"  \"YAM_5\"  \"YAM_6\"  \"YAM_7\"  \"YAM_8\" \n [9] \"YAM_9\"  \"YAM_10\" \"YAM_11\" \"YAM_12\" \"YAM_13\" \"YAM_14\" \"YAM_15\" \"YAM_16\"\n[17] \"YAM_17\" \"YAM_18\" \"YAM_19\" \"YAM_20\" \"YAM_21\" \"YAM_22\" \"YAM_23\" \"YAM_24\"\n[25] \"YAM_25\" \"YAM_26\" \"YAM_27\" \"YAM_28\" \"YAM_29\" \"YAM_30\" \"YAM_31\" \"YAM_32\"\n[33] \"YAM_33\" \"YAM_34\" \"YAM_35\" \"YAM_36\" \"YAM_37\" \"YAM_38\" \"YAM_39\" \"YAM_40\"\n[41] \"YAM_41\" \"YAM_42\" \"YAM_43\" \"YAM_44\" \"YAM_45\" \"YAM_46\" \"YAM_47\" \"YAM_48\"\n[49] \"YAM_49\" \"YAM_50\"\n\n# Overall Tajima's D across the 10Mb sequence still doesn't reveal any significant\n# deviations even in case of selection (again, not entirely unsurprising)\nts_tajima(ts, sample_sets = samples, mode = \"branch\")\n\n# A tibble: 4 × 2\n  set          D\n  &lt;chr&gt;    &lt;dbl&gt;\n1 ANA   -0.00757\n2 EHG    0.0273 \n3 EUR   -0.360  \n4 YAM   -0.377  \n\n\n\n# So let's look at the window-based computation again...\nwindows &lt;- as.integer(seq(0, ts$sequence_length, length.out = 100))\n\n# compute genome-wide Tajima's D for each population in individual windows\ntajima_wins &lt;- ts_tajima(ts, sample_sets = samples, windows = windows, mode = \"branch\")\ntajima_df &lt;- process_tajima(tajima_wins)\n\nplot_tajima(tajima_df)\n\n\n\n\n\n\n\n\nYou should see a clear dip in Tajima’s D around the midpoint of the DNA sequence, but only in Europeans. The beneficial allele appeared in the European population, and although the plot of the allele frequency trajectories shows that the selection dynamics has been dramatically affected by gene-flow events (generally causing a repeated “dilution” of the selection signal in Europeans), there has never been gene-flow (at least in our model) from Europeans to other populations, so the beneficial allele never had a chance to “make it” into those populations.\n\n\n\n\n\n\n\n\n\nBonus exercises\n\n\n\n\n\n\n7.5.0.1 Bonus 1: Investigate the impact of recombination around the selected locus\nVary the uniform recombination rate and observe what happens with Tajima’s D in windows along the genome.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nSolution: just modify the value of the recombination_rate = argument provided to the slim() function above.\n\n\n\n\n\n7.5.0.2 Bonus 2: Simulate origin of the allele in EHG\nSimulate the origin of the beneficial allele in the EHG population – what do the trajectories look like now? How does that change the Tajima’s D distribution along the genome in our European populations?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nUse this extension in the slim() call, and repeat the rest of the selection-based workflow in this exercise.\n\nextension &lt;- substitute_values(\n  template = \"slim_extension.txt\",\n  origin_pop = \"EHG\",\n  s = 0.1,\n  onset_time = 12000\n)\nmodel &lt;- compile_model(\n  populations = list(afr, ooa, ehg, eur, ana, yam),\n  gene_flow = gf, generation_time = 30,\n  extension = extension\n)\n\n\n\n\n\n\n7.5.0.3 Bonus 3: Other statistics in windows\nAs a practice of your newly acquired tree-sequence computation skills with slendr, calculate some other statistics in the same windows along the simulated genome, visualize them yourself, and compare the results to the window-based Tajima’s D pattern. For instance, ts_diversity(), ts_divergence(), or ts_segregating() might be quite interesting to look at.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\nUse the same tree sequence file you’ve computed Tajima’s D on, and then apply the functions ts_diversity(), ts_divergence(), and ts_segregating() on that tree sequence.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-1-create-a-model",
    "href": "slendr.html#part-1-create-a-model",
    "title": "2  Introduction to slendr",
    "section": "8.1 Part 1: Create a model",
    "text": "8.1 Part 1: Create a model\nStart a new script named exercise5.R with the following setup of another toy demographic model:\n\nlibrary(slendr)\ninit_env(quiet = TRUE)\n\nsource(here::here(\"utils.R\"))\n\npopA &lt;- population(\"popA\", time = 3000, N = 5000)\npopB &lt;- population(\"popB\", time = 1500, N = 5000, parent = popA)\npopC &lt;- population(\"popC\", time = 1500, N = 5000, parent = popA)\n\nmodel &lt;- compile_model(list(popA, popB, popC), generation_time = 1)\n\nschedule &lt;- schedule_sampling(model, times = seq(3000, 0, by = -200),\n                              list(popA, 10), list(popB, 10), list(popC, 10))\n\nplot_model(model, proportions = TRUE, samples = schedule)\n\n\n\n\n\n\n\n\nAs you can see, this model describes the demographic history of three populations: one ancestral population “popA” starting at 3000 generations ago, which splits into two populations “popB” and “popC” the same time at 1500 generations ago. We den instruct slendr to record 10 individuals from each of the three populations starting from 3000 generations ago all the way to 0 generations ago (i.e. the “present”), every 200 generations (remeber the seq() R function!).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-2-simulate-a-mutated-tree-sequence",
    "href": "slendr.html#part-2-simulate-a-mutated-tree-sequence",
    "title": "2  Introduction to slendr",
    "section": "8.2 Part 2: Simulate a (mutated!) tree sequence",
    "text": "8.2 Part 2: Simulate a (mutated!) tree sequence\nTo be able to run PCA using the smartsnp R package (below), we will need to simulate data in the EIGENSTRAT file format. And to do that, we need our tree sequence with mutations.\nRecall that all of our previous exercises managed to do away with mutations completely, owing to the amazing nature of the succint tree sequence data structure invented by the people behind the tskit project. However, all traditional popgen software and tools still rely on genotype data, which is why we now have to simulate mutations as well. Luckily, this is very easy – instead of the traditional\n\nts &lt;- msprime(model, sequence_length = ..., recombination_rate = ..., samples = ...)\n\nwe will run this:\n\n# First run a normal msprime simulation creating a tree-sequence object, then\n# directly pipe it into a function which adds (neutral!) mutations to it\nts &lt;- msprime(model, sequence_length = ..., recombination_rate = ..., samples = ...) %&gt;%\n  ts_mutate(mutation_rate = ...)\n\nwhich is equivalent to running this without the %&gt;% “pipe operator”:\n\n# First run a normal msprime simulation creating a tree-sequence object...\nts_nomuts &lt;- msprime(model, sequence_length = ..., recombination_rate = ..., samples = ...)\n# ... then add (neutral!) mutations to it\nts &lt;- ts_mutate(ts_nomuts, mutation_rate = ...)\n\nWith that out of the way, simulate a tree sequence from the popA/popB/popC model above, which will be 50 Mb (50e6) long, with a recombination rate 1e-8, and overlay mutations on it at a rate 1e-8. Check that it has mutations either by typing out ts in the console and looking for a “Mutations” section of the summary, or by using the function ts_table(ts, \"mutations\"). Then count how many individuals you have recorded for each population using the table produced by ts_samples().\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n# First run a normal msprime simulation creating a tree-sequence object, then\n# directly pipe it into a function which adds (neutral!) mutations to it\nts_nomuts &lt;- msprime(model, samples = schedule, sequence_length = 50e6, recombination_rate = 1e-8, random_seed = 1702182272)\n\n# Notice we have no mutations on the tree sequence, just as before...\nts_nomuts\n\n╔═══════════════════════════╗\n║TreeSequence               ║\n╠═══════════════╤═══════════╣\n║Trees          │     160114║\n╟───────────────┼───────────╢\n║Sequence Length│   50000000║\n╟───────────────┼───────────╢\n║Time Units     │generations║\n╟───────────────┼───────────╢\n║Sample Nodes   │        620║\n╟───────────────┼───────────╢\n║Total Size     │   26.1 MiB║\n╚═══════════════╧═══════════╝\n╔═══════════╤══════╤═════════╤════════════╗\n║Table      │Rows  │Size     │Has Metadata║\n╠═══════════╪══════╪═════════╪════════════╣\n║Edges      │619886│ 18.9 MiB│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Individuals│   310│  8.5 KiB│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Migrations │     0│  8 Bytes│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Mutations  │     0│ 16 Bytes│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Nodes      │ 92209│  2.5 MiB│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Populations│     3│303 Bytes│         Yes║\n╟───────────┼──────┼─────────┼────────────╢\n║Provenances│     1│  5.2 KiB│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Sites      │     0│ 16 Bytes│          No║\n╚═══════════╧══════╧═════════╧════════════╝\n\nts &lt;- ts_mutate(ts_nomuts, mutation_rate = 1e-8)\n\n# ... but we have them now!\nts\n\n╔═══════════════════════════╗\n║TreeSequence               ║\n╠═══════════════╤═══════════╣\n║Trees          │     160114║\n╟───────────────┼───────────╢\n║Sequence Length│   50000000║\n╟───────────────┼───────────╢\n║Time Units     │generations║\n╟───────────────┼───────────╢\n║Sample Nodes   │        620║\n╟───────────────┼───────────╢\n║Total Size     │   36.1 MiB║\n╚═══════════════╧═══════════╝\n╔═══════════╤══════╤═════════╤════════════╗\n║Table      │Rows  │Size     │Has Metadata║\n╠═══════════╪══════╪═════════╪════════════╣\n║Edges      │619886│ 18.9 MiB│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Individuals│   310│  8.5 KiB│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Migrations │     0│  8 Bytes│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Mutations  │168780│  6.0 MiB│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Nodes      │ 92209│  2.5 MiB│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Populations│     3│303 Bytes│         Yes║\n╟───────────┼──────┼─────────┼────────────╢\n║Provenances│     2│  6.0 KiB│          No║\n╟───────────┼──────┼─────────┼────────────╢\n║Sites      │168492│  4.0 MiB│          No║\n╚═══════════╧══════╧═════════╧════════════╝\n\n# Get the table of individuals (and process it a bit for tidier plotting later)\nsamples &lt;- ts_samples(ts) %&gt;% mutate(pop = factor(pop, levels = c(\"popA\", \"popB\", \"popC\")))\n\n# Count how many individuals do we have for each population\nsamples %&gt;% group_by(pop) %&gt;% count()\n\n# A tibble: 3 × 2\n# Groups:   pop [3]\n  pop       n\n  &lt;fct&gt; &lt;int&gt;\n1 popA    150\n2 popB     80\n3 popC     80",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-3-converting-a-tree-sequence-into-eigenstrat",
    "href": "slendr.html#part-3-converting-a-tree-sequence-into-eigenstrat",
    "title": "2  Introduction to slendr",
    "section": "8.3 Part 3: Converting a tree sequence into EIGENSTRAT",
    "text": "8.3 Part 3: Converting a tree sequence into EIGENSTRAT\nThe function to use for converting a tree-sequence object we have in R (in our exercises the thing we usually had in the ts variable) to disk in form of genotypes in the EIGENSTRAT format is called ts_eigenstrat(). The standard way to call it (but see ?ts_eigenstrat for more options) is like this:\n\nts_eigenstrat(ts, prefix = \"path/to/a/desired/EIGENSTRAT/prefix\")\n\nWhich creates three files .ind, .snp, and .geno as: - path/to/a/desired/EIGENSTRAT/prefix.ind, - path/to/a/desired/EIGENSTRAT/prefix.snp, and - path/to/a/desired/EIGENSTRAT/prefix.geno,\njust as you would expect for any EIGENSTRAT file.\nTake your tree sequence ts just just simulated, and convert it to EIGENSTRAT format under the prefix data/ABC_all.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nts_eigenstrat(ts, \"data/ABC_all\")\n\n182 multiallelic sites (0.108% out of 168492 total) detected and removed\n\n\nEIGENSTRAT object\n=================\ncomponents:\n  ind file: data/ABC_all.ind\n  snp file: data/ABC_all.snp\n  geno file: data/ABC_all.geno\n\n\n\n\n\nCheck that the EIGENSTRAT files really appeared at the path that you specified (in the terminal).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-4-inspect-the-eigenstrat-data-produced-by-slendr",
    "href": "slendr.html#part-4-inspect-the-eigenstrat-data-produced-by-slendr",
    "title": "2  Introduction to slendr",
    "section": "8.4 Part 4: Inspect the EIGENSTRAT data produced by slendr",
    "text": "8.4 Part 4: Inspect the EIGENSTRAT data produced by slendr\nYears ago I developed a small R package to help me with \\(f\\)-statistics based projects using the ADMIXTOOLS software (which operates on data in the EIGENSTRAT file format), called admixr\nUse the following code to examine one of the EIGENSTRAT data sets you’ve just created. Just look at the results and see if they make sense in terms of what you’ve learned about this in earlier lectures.\n\nlibrary(admixr)\n\neigen &lt;- eigenstrat(\"&lt;prefix of a trio of EIGENSTRAT .ind/.snp/.geno files\")\n\n# Print out a summary of the EIGENSTRAT data\neigen\n\n# Read the .ind file as a table into R\nread_ind(eigen)\n# Read the .snp file as a table into R\nread_snp(eigen)\n# Read the .geno file as a table into R\nread_geno(eigen)\n\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nlibrary(admixr)\n\neigen &lt;- eigenstrat(\"data/ABC_all\")\n\n# Print out a summary of the EIGENSTRAT data\neigen\n\n# Read the .ind file as a table into R\nread_ind(eigen)\n# Read the .snp file as a table into R\nread_snp(eigen)\n# Read the .geno file as a table into R\nread_geno(eigen)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  },
  {
    "objectID": "slendr.html#part-5-principal-component-analysis-on-the-entire-simulated-data-set",
    "href": "slendr.html#part-5-principal-component-analysis-on-the-entire-simulated-data-set",
    "title": "2  Introduction to slendr",
    "section": "8.5 Part 5: Principal Component Analysis on the entire simulated data set",
    "text": "8.5 Part 5: Principal Component Analysis on the entire simulated data set\nNow, at long last, we have everything we need to be able to run ABC on the data generated by our slendr model. To avoid making this exercise even longer, I provided a helper function for you called plot_pca(). But this function isn’t doing anything magical – it uses the smartsnp R package to compute the principal components and visualize the results using ggplot2. This is something many of you could do given enough time but we want to focus on simulations and PCA, not pure R coding. If you’re interested, take a look at my implementation of plot_pca() here.\nHere’s how you can use this function (remeber that you need to put source(here::here(\"utils.R\")) into your script!):\n\nPlot PCA while coloring each individual by their population assignment:\n\n\nplot_pca(\"path/to/prefix\", &lt;tree sequence used to create EIGENSTRAT&gt;, color_by = \"pop\")\n\n\nPlot PCA while coloring each individual by their time of sampling:\n\n\nplot_pca(\"path/to/prefix\", &lt;tree sequence used to create EIGENSTRAT&gt;, color_by = \"time\")\n\n\nBy default, the function plots PC 1 vs PC 2, but you can customize things by providing an optional argument pc = like this:\n\n\nplot_pca(\"path/to/prefix\", &lt;tree sequence used to create EIGENSTRAT&gt;, color_by = \"pop\", pc = c(2, 3))\n\nUse the provided plot_pca() function to run PCA based on genotypes for all recorded individuals that you just converted as EIGENSTRAT \"data/ABC_all\" from the ts tree sequence. Visualize PC 1 vs PC 2 by first ccolor each individual by their population label (color_by = \"pop\") then by the time of their sampling (color_by = \"time\").\nDoes the PCA of PC 1 vs PC 2 capture the relationship between all individuals across the populations and across time?\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nplot_pca(\"data/ABC_all\", ts, color_by = \"pop\", pc = c(1, 2))\n\nPCA cache for the given EIGENSTRAT data was not found. Generating it now (this might take a moment)...\n\n\n\n\n\n\n\n\nplot_pca(\"data/ABC_all\", ts, color_by = \"time\", pc = c(1, 2))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\n\nIt looks like the PCA from PC 1 vs 2 cannot “partition out” the drift along the ancestral “popA” lineage prior to the population splits!\n\n\n\nUse plot_pca() to compute the PCAon this exact same data, but examine how does the shape of the PCA scatterplot change when you switch the pairs of PCs plotted (i.e., PC 2 vs PC 3, PC 3 vs PC 4, PC 4 vs PC 6, etc.). Which pair of PCs does the best job at recapitulating the demographic model?\n\n\nNote: We’re doing this purely for educational purposes and for fun, using an extremely idealistic demographic model which is perfectly known (by definition, because we simulated it) and perfect sampling scheme. The point is to explore what does doing a PCA mean in practice, visually, and to built intuition into it.\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n#  We can see that the overall shape of the demographic model tree is now nicely\n# reflected in the PCA shape\nplot_pca(\"data/ABC_all\", ts, color_by = \"pop\", pc = c(2, 3))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"data/ABC_all\", ts, color_by = \"time\", pc = c(2, 3))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"data/ABC_all\", ts, color_by = \"pop\", pc = c(3, 4))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"data/ABC_all\", ts, color_by = \"time\", pc = c(3, 4))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\n# Things are getting progressively wilder! \nplot_pca(\"data/ABC_all\", ts, color_by = \"pop\", pc = c(4, 5))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"data/ABC_all\", ts, color_by = \"time\", pc = c(4, 5))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\n# ...\nplot_pca(\"data/ABC_all\", ts, color_by = \"pop\", pc = c(5, 6))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\nplot_pca(\"data/ABC_all\", ts, color_by = \"time\", pc = c(5, 6))\n\nPCA cache for the given EIGENSTRAT data was found. Loading it to save computational time...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBonus exercises\n\n\n\n\n\n\n8.5.1 Bonus 1: Tree-sequence simplification and EIGENSTRAT conversion\nOne of our goals in this exercise was to investigate how does the shape of a PCA look like based on the sampling of individuals across populations and also across time – all of that from the same demographic history. In order to do that, we need to be able to select only a defined subset of individuals from a given tree sequence. Which brings us to the last tree-sequence processing function in slendr callsed ts_simplify(). Implemented on top of the simplify() method in tskit, it has a very simple interface:\n\nts_small &lt;- ts_simplify(ts_big, simplify_to = c(&lt;subset of individuals as a vector&gt;))\n\nThis function call creates a new tree sequence, which is smaller and only contains a those individuals whose names were specified in simplify_to = (again, we’re talking about the “symbolic names” of individuals, such as “NEA_1”, “AFR_42”, etc., not integer numbers of tskit nodes).\nWhenever you want to create smaller subsets of a large tree sequence, it is often helpful to work with the table of all individuals in the original tree sequence, because it contains every individual’s name, pop assignment and the time in which it lived, so let’s save it for further use now:\n\nsamples &lt;- ts_samples(ts)\n\nnrow(samples)\n\n[1] 310\n\n\nFor instance, we can get only individuals from “popB” and “popC” sampled at the present using this code:\n\nsubset &lt;- filter(samples, pop %in% c(\"popB\", \"popC\"), time == 0)\n\nnrow(subset)\n\n[1] 20\n\n\nYou know that the table of samples contains the name of each individual, which you can access as subset$name. Use the ts_simplify() function to create a new tree sequence called ts_BC0 which contains only this subset of individuals. Check that it really does contain only the defined subset of individuals using ts_samples(ts_BC0).\n\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\nts_BC0 &lt;- ts_simplify(ts, simplify_to = subset$name)\n\nts_samples(ts_BC0)\n\n# A tibble: 20 × 3\n   name     time pop  \n   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;\n 1 popB_71     0 popB \n 2 popB_72     0 popB \n 3 popB_73     0 popB \n 4 popB_74     0 popB \n 5 popB_75     0 popB \n 6 popB_76     0 popB \n 7 popB_77     0 popB \n 8 popB_78     0 popB \n 9 popB_79     0 popB \n10 popB_80     0 popB \n11 popC_71     0 popC \n12 popC_72     0 popC \n13 popC_73     0 popC \n14 popC_74     0 popC \n15 popC_75     0 popC \n16 popC_76     0 popC \n17 popC_77     0 popC \n18 popC_78     0 popC \n19 popC_79     0 popC \n20 popC_80     0 popC \n\n\n\n\n\nWhen you have a smaller tree sequence like this, you can convert it to an EIGENSTRAT file format using ts_eigenstrat() just like we did above.\n\n\n8.5.2 Part 2: PCA visualization on subsets of individuals\nTODO: Try to replicate some features of the results discovered for EUR/ASIAN/AFR/Indian populations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to _slendr_</span>"
    ]
  }
]