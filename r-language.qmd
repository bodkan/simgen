# R programming language

‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
**This chapter is a work-in-progress!**
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

In a wider programming world, R sometimes has a slightly unfortunate reputation
as a badly designed "calculator language". A computing environment which is
(maybe!) good for working with data frames and creating figures, but that's about
it. However, while certainly very useful for data science, R is a full-blown
programming language which is actually quite powerful even from a purely
computer science perspective.

But still, this is a book about population genomics and data science in R.
Why does this matter how much "real coding" we do in it?

Well, although this entire workshop will primarily focus on R primarily as 
as a statistical and visualization environment, neglecting the aspects of R
which make it a "proper" programming language (or even considering data science
as "not real programming") is a huge problem.

First, even when "just" doing data science and statistics, we still use typical
programming constructs, we need to be aware of underlying data types behind
our data (mostly contents of tables), and we need to think algorithmically.
Neglecting these things makes it easy to introduce bugs into our code, make
it hard to find those bugs, and make our programs less efficient even when
they do work.

This chapter will help you get familiar with some of the less obvious aspects
of the R language or programming in general, certainly the parts which are often
skipped in undergratuate courses in the life sciences in favor of just teaching
plotting and running statistical tests. The good thing is, there isn't that much
you need to learn. And what you do learn will continue paying dividents for the
rest of your research career!

Let's say it again, because people with non-computational backgrounds often feel
inadequate when it comes to computational aspects of their work: **Even when you're
"just" writing data analysis scripts, even when you're "just" plotting results,
you're still writing programs. You're a programmer.** How exciting, right?
Exercises in this chapter are designed to make you comfortable with programming
and algorithmic thinking.

## Part 1: Atomic data types

**Create the following variables in your R script and then evaluate this code
in your R console:**

```{r}
w1 <- 3.14
x1 <- 42
y1 <- "hello"
z1 <- TRUE
```

```{r}
w1
x1
y1
z1
```

What are the data "types" you get when you apply function `mode()` on each of
these variables?

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution

```{r}
mode(w1)
mode(x1)
mode(y1)
mode(z1)
```
:::

You can test whether or not a specific variable is of a specific type using
functions such as `is.numeric()`, `is.integer()`, `is.character()`, `is.logical()`. **See what results you get when you apply these on these
four variables `w1`, `x1`, `y1`, `z1`. Pay particular attention to the difference
(or lack thereof?) between applying `is.numeric()` and `is.integer()`.**

::: {.aside}
**Note: This might seem incredibly boring and useless but trust me. In your
real data, you will be see, in data frames (discussed below) with thousands of
rows, sometimes millions. Being able to make sure that the values you get
in your data-frame columns are of the expected type is something you will be
doing often.
:::

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution

```{r}
is.numeric(w1)
is.integer(w1)

is.numeric(x1)
is.integer(x1)

is.character(y1)

is.logical(z1)
is.numeric(z1)
is.integer(z1)
```

:::



## Part 2: Vectors

Vectors are, roughly speaking, collections of values. We could also say "a list",
but that's not entirely precise in the context of R as we'll see below.

We can create a vector by calling the `c()` function ("c" stands for
"concatenate", or "joining together"). **Create the following variables containing
these vectors. Then inspect their data types using `mode()` again.**

```{r}
w2 <- c(1.0, 2.72, 3.14)
x2 <- c(1, 13, 42)
y2 <- c("hello", "folks", "!")
z2 <- c(TRUE, FALSE)
```

```{r}
w2
x2
y2
z2
```

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution
```{r}
mode(w2)
mode(x2)
mode(y2)
mode(z2)
```
:::

**We can use the function `is.vector()` to test that a given object really is a
vector. Try this on your vector variables.**

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution
```{r}
is.vector(w2)
is.vector(x2)
is.vector(y2)
is.vector(z2)
```
:::

**What happens when you call `is.vector()` on the variables `x1`, `y1,` etc. from
the previous part (i.e., those which contain single values)?**

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution

```{r}
is.vector(42)
```

Yes, even scalars (i.e., singular values) are formally vectors!

This is why we see the [1] index when we type a single number:

```{r}
1
```


In fact, even when we create a vector of length 1, we still get a scalar result:

```{r}
c(1)
```

The conclusion is, R doesn't actually distinguish between scalars and vectors!
A scalar (a single value) is simply a vector of length 1. Think of it this way:
in a strange mathematically-focused way, even a single tree is a forest. üôÉ
:::

**Do elements of vectors need to be homogeneous (i.e., of the same data type)?
Try creating a vector with values `1`, `"42"`, and `"hello"`. Can you do it?
What happens when you try? Inspect the result in the R console (take a close look
at how the result is presented in text and the quotes that you will see), or
use the `mode()` function again.**

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution

```{r}
mixed_vector <- c(1, "42", "hello")
mixed_vector
```

```{r}
mode(mixed_vector)
```
:::

As you could see, vectors must carry values of just one type. If they don't, they
are converted by a straightforward cascade of so-called "coercions". A vector
defined with a mixture of different values (i.e., the four atomic types we
discussed in the first part) will be _coreced_ to be only one of those types,
given certain rules.

**Try to figure out some of these coercion rules. Make a couple of vectors
with mixed values of different types using the function `c()`, and observe
what type of vector you get in return.**

**Hint:** Try creating a vector which has integers and strings, integers and
floats, integers and logicals, floats and logicals, floats and strings, and
logicals and strings. Observe the format of the result that you get, and
build your intuition by calling `mode()` on each vector object to verify this.

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution
```{r}
v1 <- c(1, "42", "hello")
v1
mode(v1)

v2 <- c(1, 42.13, 123)
v2
mode(v2)

v3 <- c(1, 42, TRUE)
v3
mode(v3)

v4 <- c(1.12, 42.13, FALSE)
v4
mode(v4)

v5 <- c(42.13, "hello")
v5
mode(v5)

v6 <- c(TRUE, "hello")
v6
mode(v6)
```
:::

**Out of all these data type exploration, this part is probably the most crucial
for any kind of data science work. Why?**

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution
Imagine what kinds of trouble can happen if you just load a table data from
somewhere, if the values are not properly formatted. For instance, if a "numeric"
column of your table has accidentally some characters (which can very easily
happen when manually entering data in Excel, etc.). This will be much clearer
when we get to data frames below.
:::

**You can create vector of consecutive values of certain forms using everal
approaches. Try these options:**

1. **Create a sequence of values from `i` to `j` as `i:j`. Create a vector of
numbers 1:20**

2. **Do the same using the function `seq()`. Read `?seq` to find out what
parameters you should specify (and how) to get the same result as the `i:j`
shortcut.

3. **Modify the arguments given to `seq()` so that you create a vector of
numbers from 20 to 1.**

4. **Use the `by =` argument of `seq()` to create a vector of only odd
values starting from 1.**

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution

```{r}
# 1
1:20
# another option is this ("give me sequence of the length N)
seq_len(20)

# 2
seq(from = 1, to = 20)

# 3
seq(from = 20, to = 1)

# 4
seq(1, 20, by = 2)
```

This might look boring, but these functions are super useful to generate
indices for data, adding indices as columns to tabular data, etc.**
:::

**Another very useful built-in helper function (especially when we get to
the iteration part below) is `seq_along()`. What does it give you when you run
it on this vector, for instance?**

```{r}
v <- c(1, "42", "hello", 3.1416)
```

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution

```{r}
seq_along(v)
```

This function allows you to quickly iterate over elements of a vector (or a list)
using indices into that vector (or a list).
:::

## Part 3: Lists

Lists are a little similar to vectors but very different in a couple of important
respects. Remember how we tested what happens when we put different types of
values in a vector (reminder: vectors must be "homogeneous" in terms of the
data types of their elements!)? **What happens when you create lists with
different types of values using the code in the following chunk? Use `mode()`
on the resulting objects and compare your results to those you got on "mixed
value" vectors above.**

```{r}
w3 <- list(1.0, "2.72", 3.14)
x3 <- list(1, 13, 42, "billion")
y3 <- list("hello", "folks", "!", 123, "wow a number follows again", 42)
z3 <- list(TRUE, FALSE, 13, "string")
```

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution

When we type the list variable in the R console, we no longer see the "coercion"
we observed for vectors (numbers remain numbers even though the list contains
strings):

```{r}
y3
```

**Calling `mode()` will (disappointingly) not tell us much about the data types
of each individual element. Why is that?**

```{r}
mode(y3)
```
:::

**Try also a different function called for `str()` (for "structure") and apply
it on one of those lists. Is `mode()` or `str()` more useful to inspect what
kind of data is stored in a list (`str` will be very useful when we get to data
frames for -- spoiler alert! -- exactly this reason). Why?**

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution

```{r}
str(y3)
```
:::

```{r}
is.list(w3)
```

**Use `is.vector()` and `is.list()` on one of the lists above (like `w3` perhaps).
Why do you get the result that you got? Then run both functions on one of the
vectors you created above (like `w2`). What does this mean?**

::: {.callout-note collapse="true" icon=false}
#### Click to see the solution

- Let's take this list:

```{r}
w3
```

Lists are vectors!

```{r}
is.vector(w3)
```

Lists are lists (obviously!):

```{r}
is.list(w3)
```

- Now let's take this vector:

```{r}
w2
```

Vectors are not lists!

```{r}
is.list(w2)
```

So:

1. Every list is also a vector.
2. But vectors are not lists.

This makes sense because lists can (but don't have to) contain values
:::



## Part 4: Indexing

To extract an i-th element of a vector `xyz`, we can use the `[]` operator like
this: `xyz[i]`. For instance, we can take the 13-th element of this vector
as `xyz[13]`.

**Familiarize yourselves with the `[]` operator by taking out some specific
values from this vector, like the 5-th element.**

```{r}
vector <- c(1, 10, 100, 1000, 10000, 100000, 1000000)
```


## Part 5: Data frames

```{r}
df <- data.frame(
  w = c(1.0, 2.72, 3.14),
  x = c(1, 13, 42),
  y = c("hello", "folks", "!"),
  z = c(TRUE, FALSE, FALSE)
)

df
```

Data frames are lists!

```{r}
is.list(df)
```

Two ways of extracting a data-frame column:

- `$` operator (column name as a symbol):

```{r}
df$w
```

- `[[` operator (column name as a string):

```{r}
df[["w"]]
```

Note that the operator must be `[[`, because `[` does something slightly different

## Part 6: Inspecting column types

Let's go back to our example data frame:

```{r}
df1 <- data.frame(
  w = c(1.0, 2.72, 3.14),
  x = c(1, 13, 42),
  y = c("hello", "folks", "!"),
  z = c(TRUE, FALSE, FALSE)
)

df1
```

**Use the function `str()` and by calling `str(df1)`, inspect the types of
columns in the table.**

```{r}
str(df1)
```

Sometimes (usually when we read data from disk, like from another software),
a data point sneaks in which makes a column apparently non numeric. Consider
this new table called `df2`:

```{r}
df2 <- data.frame(
  w = c(1.0, 2.72, 3.14),
  x = c(1, "13", 42),
  y = c("hello", "folks", "!"),
  z = c(TRUE, FALSE, FALSE)
)

df2
```

Just by looking at this, the table looks the same as `df1` above. **Use `str()`
again to see where the problem is.**

```{r}
str(df2)
```



## Part 7: Functions

The motto of this part could be summarized by an ancient motto of programming:
[Don't repeat yourself (DRY)](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself):
_"[...] a modification of any single element of a system does not require
a change in other logically unrelated elements."_.

Let's say you have the following numeric vector:

```{r}
vec <- c(-0.32, 0.78, -0.68, 0.28, -1.96, 0.21, -0.07, -1.01, 0.06, 0.74,
         -0.37, -0.6, -0.08, 1.81, -0.65, -1.23, -1.28, 0.11, -1.74,  -1.68)
```

With numeric vectors (which could be base qualities, genotype qualities, 
$f$-statistics, etc.), we often need to compute a couple of summary
statistics (mean, median, quartile, minimum, maximum, etc.).

::: {.aside}
In R, we have a very useful built-in function `summary()`, which does exactly that.
But let's ignore this for the moment, for learning purposes.
:::

Here is how you can compute those summary statistics individually:

```{r}
min(vec)
quantile(vec, probs = 0.25)
median(vec)
mean(vec)
quantile(vec, probs = 0.75)
max(vec)
```

Now, you can imagine that you have many more of such vectors (results for different
sequenced samples, different computed population genetic metrics, etc.). Having
to type out all of these commands for every single one of those vectors would
very quickly get extremely tiresome. Worse still, when we would do this, we would
certainly resort to copy-pasting, which is guaranteed to lead to errors.

**Write a custom function called `my_summary`, which will accept a single input
named `values`, and returns a list which binds all the six summary statistics together.
Name the elements of that list as `"min"`, `"quartile_1"`, `"median"`, `"mean"`,
`"quartile_3"`, and `"max"`.**

```{r}
my_summary <- function(values) {
  a <- min(vec)
  b <- quantile(vec, probs = 0.25)
  c <- median(vec)
  d <- mean(vec)
  e <- quantile(vec, probs = 0.75)
  f <- max(vec)
  
  result <- list(min = a, quartile_1 = b, median = c, mean = d, quartile_3 = e, max = f)
  
  return(result)
}
```

Note that yes, we had to write the code anyway, but it is now "encapsulated" in
a fully self-contained form and can be called repeatably, without any copy-pasting.

In other words, if we imagine having these three vectors of numeric values:

```{r}
vec1 <- runif(10)
vec2 <- runif(10)
vec3 <- runif(10)
```

We can now compute our summary statistics by calling our function `my_summary()`:

```{r}
my_summary(vec1)
my_summary(vec2)
my_summary(vec3)
```

And, surprise! This is what the incredibly useful built-in function `summary()`
provided with every R installation does!

```{r}
summary(vec1)
summary(vec2)
summary(vec3)
```




## Part 8: Iteration and loops

Functions help us take pieces of code and _generalize_ them to reduce the amount
of code needed to do similar things, repeatedly, multiple times. You could think
of _iteration_ as generalizing those repetitions.

This is very vague and abstract



# Take home message

It's worth acknowledging that developing code as proper functions, using iteration,
and generally think about solving problems using "proper" program approaches
like that is a lot of work. It might seem that "just copying a bit of code
a couple of times" is easier. In the moment, it actually is.

Except we rarely, if ever, do things only once. We have to come back to old
scripts, update them, or add new steps. Doing this for every single bit of
copy pasted code (sometimes in multiple scripts) is awful, and almost always
results in bugs. Even missing one edit in one copy of a piece of code will
make our results wrong.

**It's always worth investing a bit extra time into extracting repeated
pieces of code into individual functions. It will always result in _less work_
in the long run.**
